{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30a3799e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import mne\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# from importlib import reload\n",
    "# import feature_extraction\n",
    "# reload(feature_extraction)\n",
    "from plotting import (\n",
    "    plot_series,\n",
    "    plot_eeg_topomap_one_block,\n",
    "    plot_eeg_topomap_all_blocks,\n",
    "    plot_k_chaneels_by_r_value,\n",
    "    plot_eeg_pearson_correlation_table,\n",
    "    get_eeg_pearson_correlation_series_all_blocks,\n",
    "    plot_time_series_by_epoch,\n",
    "    plot_pearson_correlation_table_by_channel,\n",
    ")\n",
    "from biomarkers import (\n",
    "    EEG,\n",
    "    EMG,\n",
    "    BP,\n",
    "    EOG,\n",
    "    ECG,\n",
    "    TREV,\n",
    "    GSR,\n",
    ")\n",
    "from feature_extraction import (\n",
    "    Feature,\n",
    "    EEG_BANDS,\n",
    "    FEATURE_TO_FUNC,\n",
    ")\n",
    "from data_utils import (\n",
    "    load_data_from_dir,\n",
    "    get_all_behaviors_labels,\n",
    "    get_all_features_by_marker,\n",
    ")\n",
    "from calculate_correlation import (\n",
    "    STAT_FEATURES,\n",
    "    get_all_behaviors_feature_to_pc_by_markers,\n",
    "    get_all_trials_average_rp_values,\n",
    ")\n",
    "\n",
    "# Train machine learning models\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.model_selection import (\n",
    "    GroupKFold,\n",
    "    GridSearchCV,\n",
    "    cross_val_score,\n",
    "    cross_validate,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1f4b9f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "ALL_DIRS = [\"../2000_CleanData\", \"../2001_CleanData\", \"../1004_CleanData\"]\n",
    "\n",
    "dir_to_data = {}\n",
    "for dir_name in ALL_DIRS:\n",
    "    all_data = load_data_from_dir(dir_name)\n",
    "    dir_to_data[dir_name] = all_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2152ef4",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_channels = 4\n",
    "num_blocks = 0\n",
    "\n",
    "dir_name_to_ctf = {}\n",
    "features = STAT_FEATURES\n",
    "marker = ECG.__name__\n",
    "\n",
    "for dir_name, all_data in dir_to_data.items():\n",
    "    dir_name_to_ctf[dir_name] = get_all_behaviors_feature_to_pc_by_markers(\n",
    "        all_data, marker, features, num_channels, num_blocks\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad4ebf5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_condition_to_features = get_all_trials_average_rp_values(\n",
    "    dir_name_to_ctf, features, \"pearson\"\n",
    ")\n",
    "spearman_corr = get_all_trials_average_rp_values(dir_name_to_ctf, features, \"spearman\")\n",
    "for b, feature_to_pc in avg_condition_to_features.items():\n",
    "    for f, pc in feature_to_pc.items():\n",
    "        avg_condition_to_features[b][f] = np.hstack((pc, spearman_corr[b][f]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cad5c2ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data = dir_to_data[\"../2000_CleanData\"]\n",
    "channel_names = [\n",
    "    \"HF\",\n",
    "    \"LF\",\n",
    "    \"LFHFratio\",\n",
    "    \"avgHR\",\n",
    "]  # all_data[\"audio_hvla\"].get_chanlocs(marker)\n",
    "\n",
    "\"\"\" plot the time series given the marker and block\n",
    "\"\"\"\n",
    "# plot_time_series_by_epoch(all_data['audio_hvla'], 'EMG', 'audio_hvla', 0)\n",
    "\n",
    "\n",
    "\"\"\" plot the single channel correlation table\n",
    "\"\"\"\n",
    "# channel = 3\n",
    "# for condition, feature_to_pc in avg_condition_to_features.items():\n",
    "#     label = f\"{channel_names[channel]} {condition}\"\n",
    "#     plot_correlation_table_by_channel(\n",
    "#         label, feature_to_pc, [\"pearson r\", \"pearson p\", \"spearman r\", \"spearman p\"], features, channel, True\n",
    "#     )\n",
    "\n",
    "\"\"\" plot the top channel correlation table given r values\n",
    "\"\"\"\n",
    "# for condition, feature_to_pc in avg_condition_to_features.items():\n",
    "#     plot_k_chaneels_by_r_value(feature_to_pc, channel_names, features, condition, True, 2)\n",
    "#     plot_k_chaneels_by_r_value(feature_to_pc, channel_names, features, condition, False, 2)\n",
    "\n",
    "\n",
    "\"\"\" plot the top channel correlation table with different blocks\n",
    "\"\"\"\n",
    "# all_block_names = list(all_data.keys())\n",
    "# all_block_names.sort()\n",
    "# for condition, feature_to_pc in avg_condition_to_features.items():\n",
    "#     plot_eeg_pearson_correlation_table(condition, feature_to_pc, all_block_names, 1)\n",
    "\n",
    "\"\"\" plot the series for the top k channels\n",
    "\"\"\"\n",
    "# define number of rows and columns for subplots\n",
    "# nrow = 3\n",
    "# ncol = 2\n",
    "# for condition, feature_to_pc in avg_condition_to_features.items():\n",
    "#     print(f\"{condition}\")\n",
    "#     ser_list = get_eeg_pearson_correlation_series_all_blocks(feature_to_pc, channel_names, k=20)\n",
    "#     plot_series(nrow, ncol, ser_list)\n",
    "\n",
    "\"\"\" plot the topography for eeg\n",
    "\"\"\"\n",
    "# for condition, feature_to_pc in avg_condition_to_features.items():\n",
    "#     plot_eeg_topomap_all_blocks(condition, feature_to_pc)\n",
    "#     for f in list(EEG_BANDS.keys()):\n",
    "#         plot_eeg_topomap_one_block(condition, f, feature_to_pc, all_block_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "010d750e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_name_to_features = {}\n",
    "dir_name_to_labels = {}\n",
    "features = STAT_FEATURES\n",
    "marker = BP.__name__\n",
    "channel_num = 1\n",
    "for dir_name, all_data in dir_to_data.items():\n",
    "    feature_to_value = get_all_features_by_marker(\n",
    "        all_data, marker, features, channel_num\n",
    "    )\n",
    "\n",
    "    dir_name_to_features[dir_name] = feature_to_value\n",
    "    dir_name_to_labels[dir_name] = get_all_behaviors_labels(all_data)\n",
    "\n",
    "features_to_trials = defaultdict()\n",
    "for dir_name, fv in dir_name_to_features.items():\n",
    "    for f, v in fv.items():\n",
    "        if f not in features_to_trials:\n",
    "            features_to_trials[f] = defaultdict()\n",
    "        if dir_name not in features_to_trials[f]:\n",
    "            features_to_trials[f][dir_name] = defaultdict()\n",
    "\n",
    "        features_to_trials[f][dir_name] = v\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1cfc36b",
   "metadata": {},
   "outputs": [],
   "source": [
    "colors = [\"b\", \"c\", \"y\", \"m\", \"r\"]\n",
    "for b in [\"valence\", \"arousal\", \"attention\"]:\n",
    "    fig, axes = plt.subplots(nrows=2, ncols=5, figsize=(20, 7))\n",
    "    fig.suptitle(\n",
    "        f\"{marker} {channel_to_fn[channel_num]} features vs {b}\", fontsize=14, y=1\n",
    "    )\n",
    "\n",
    "    fidx = 0\n",
    "    r, c = 0, 0\n",
    "    for f, trials in features_to_trials.items():\n",
    "        cidx = 0\n",
    "        r = int(fidx % 2)\n",
    "        c = int(fidx / 2)\n",
    "        for trial, val in trials.items():\n",
    "            trial_name = trial.strip(\"../_CleanData\")\n",
    "            labels = dir_name_to_labels[trial][b]\n",
    "            axes[r][c].scatter(\n",
    "                val, labels, c=colors[cidx], label=trial_name, alpha=0.3\n",
    "            )  # norm=mpl.colors.Normalize(vmin=0, vmax=2)\n",
    "            axes[r][c].set_xlabel(f.name, fontsize=10)\n",
    "            cidx += 1\n",
    "\n",
    "        axes[r][c].legend()\n",
    "        fidx += 1\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "782e4879",
   "metadata": {},
   "outputs": [],
   "source": [
    "groups_list = [[i] for i, j in enumerate(valence_label)]\n",
    "group_array = np.hstack(groups_list)\n",
    "\n",
    "print(group_array)\n",
    "print(all_features.shape, valence_label.shape, group_array.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27b3de93",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_label(all_labels, low, high):\n",
    "    y_transformed = []\n",
    "    c0, c1, c2 = 0, 0, 0\n",
    "    for label in all_labels:\n",
    "        if label < low:\n",
    "            y_transformed.append(0)\n",
    "            c0 += 1\n",
    "        elif label >= low and label < high:\n",
    "            y_transformed.append(1)\n",
    "            c1 += 1\n",
    "        else:\n",
    "            y_transformed.append(2)\n",
    "            c2 += 1\n",
    "\n",
    "    print(f\"0 label: {c0}, 1 label: {c1}, 2 label {c2}\")\n",
    "    return y_transformed\n",
    "\n",
    "\n",
    "def binary_label(all_labels, threshold=0.5):\n",
    "    y_transformed = []\n",
    "    c0, c1 = 0, 0\n",
    "    for label in all_labels:\n",
    "        if label < threshold:\n",
    "            y_transformed.append(0)\n",
    "            c0 += 1\n",
    "        else:\n",
    "            y_transformed.append(1)\n",
    "            c1 += 1\n",
    "\n",
    "    print(f\"0 label: {c0}, 1 label: {c1}\")\n",
    "    return y_transformed\n",
    "\n",
    "\n",
    "def get_tranformed_labels():\n",
    "    name_to_transformed = dict()\n",
    "    name_to_transformed[\"valence\"] = binary_label(valence_label)  # 0.6, 0.8\n",
    "    name_to_transformed[\"arousal\"] = binary_label(arousal_label)  # 0.4, 0.7\n",
    "    name_to_transformed[\"attention\"] = binary_label(attention_label, 0.85)  # 0.82, 0.92\n",
    "    return name_to_transformed\n",
    "\n",
    "\n",
    "# convert y values to categorical values\n",
    "name_to_transformed = get_tranformed_labels()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51c04220",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_name = \"attention\"\n",
    "y_transformed = name_to_transformed[label_name]\n",
    "clf = LogisticRegression(max_iter=200)\n",
    "gkf = GroupKFold(n_splits=5)\n",
    "param_grid = {\"classifier__C\": [1e-5, 1e-4, 1e-3, 1e-2, 1e-1, 1, 10, 100]}\n",
    "pipe = Pipeline([(\"scaler\", StandardScaler()), (\"classifier\", clf)])\n",
    "gscv = GridSearchCV(pipe, param_grid, cv=gkf, n_jobs=16)\n",
    "gscv.fit(all_features, y_transformed, groups=group_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "764e71c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = gscv.best_estimator_\n",
    "print(f\"best model: {best_model}\")\n",
    "print(gscv.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a90a695b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# BP feature shape (13, 11)\n",
    "# ECG feature shape (13, 11) 22\n",
    "# EEG feature shape (13, 1408) 1430\n",
    "# EGG feature shape (13, 11) 1441\n",
    "# EMG feature shape (13, 22) 1463\n",
    "# EOG feature shape (13, 22) 1485\n",
    "# GSR feature shape (13, 11) 1496\n",
    "# Resp feature shape (13, 11) 1507\n",
    "# TREV feature shape (13, 11) 1518\n",
    "# features = (mean(data),std(data),ptp(data),var(data),minim(data),maxim(data),\n",
    "#                           mean_square(data),rms(data),abs_diffs_signal(data),\n",
    "#                           skewness(data),kurtosis(data))\n",
    "# EEG spetral features shape (13, 768) 2286-768=\n",
    "\n",
    "STATS_NAME = [\n",
    "    \"mean\",\n",
    "    \"std\",\n",
    "    \"ptp\",\n",
    "    \"var\",\n",
    "    \"minim\",\n",
    "    \"maxim\",\n",
    "    \"mean_square\",\n",
    "    \"rms\",\n",
    "    \"abs_diffs_signal\",\n",
    "    \"skewness\",\n",
    "    \"kurtosis\",\n",
    "]\n",
    "EEG_BANDS = [\"Delta\", \"Theta\", \"Alpha\", \"Beta1\", \"Beta2\", \"Gamma\"]\n",
    "\n",
    "\n",
    "def get_stats_name(i) -> str:\n",
    "    pos = i % 11\n",
    "    return STATS_NAME[pos]\n",
    "\n",
    "\n",
    "def get_feature_names(features):\n",
    "    index = []\n",
    "    for i, j in enumerate(features):\n",
    "        stat_name = get_stats_name(i)\n",
    "        if i < 11:\n",
    "            name = \"BP\"\n",
    "        elif i < 22:\n",
    "            name = \"ECG\"\n",
    "        elif i < 1430:\n",
    "            channel = int((i - 22) / 11) + 1\n",
    "            name = f\"EEG {channel}\"\n",
    "        elif i < 1441:\n",
    "            name = \"EGG\"\n",
    "        elif i < 1463:\n",
    "            channel = int((i - 1441) / 11) + 1\n",
    "            name = f\"EMG {channel}\"\n",
    "        elif i < 1485:\n",
    "            channel = int((i - 1463) / 11) + 1\n",
    "            name = f\"EOG {channel}\"\n",
    "        elif i < 1496:\n",
    "            name = \"GSR\"\n",
    "        elif i < 1507:\n",
    "            name = \"Resp\"\n",
    "        elif i < 1518:\n",
    "            name = \"TREV\"\n",
    "        else:\n",
    "            channel = int((i - 1518) / 6) + 1\n",
    "            name = f\"EEG {channel}\"\n",
    "            stat_name = EEG_BANDS[(i - 1518) % 6]\n",
    "\n",
    "        index.append(f\"{name} {stat_name}\")\n",
    "    return index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dcadd95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# assume bigger coefficents has more contribution to the model\n",
    "# but have to be sure that the features has THE SAME SCALE otherwise this assumption is not correct.\n",
    "importance = best_model[\"classifier\"].coef_[0]\n",
    "\n",
    "feat_importances = pd.Series(importance, index=get_feature_names(importance))\n",
    "feat_importances.nlargest(10).plot(\n",
    "    kind=\"barh\", title=f\"{label_name} Feature Importance\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "149650e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# using Randoom forest (not suitable as the data is too small and the model will overfit easily)\n",
    "# from sklearn.ensemble import RandomForestClassifier\n",
    "# import matplotlib\n",
    "\n",
    "# clf = RandomForestClassifier()\n",
    "# clf = clf.fit(all_features,y_transformed)\n",
    "# clf.feature_importances_\n",
    "# feat_importances = pd.Series(clf.feature_importances_, index=get_feature_names(clf.feature_importances_))\n",
    "# feat_importances.nlargest(20).plot(kind='barh',title = 'Feature Importance')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "a61a162a2d9e3da5a6990904193197d11ef3e5d95aabe700de904d0b7a2b7b7b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
