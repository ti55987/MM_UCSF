{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30a3799e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# from importlib import reload\n",
    "# import feature_extraction\n",
    "# reload(feature_extraction)\n",
    "from biomarkers import (\n",
    "    EEG,\n",
    "    EMG,\n",
    "    BP,\n",
    "    EOG,\n",
    "    ECG,\n",
    "    TREV,\n",
    "    GSR,\n",
    "    Resp,\n",
    "    EGG,\n",
    "    MARKER_TO_CHANNEL_NAMES,\n",
    ")\n",
    "from feature_extraction import (\n",
    "    Feature,\n",
    "    EEG_BANDS,\n",
    "    STAT_FEATURES,\n",
    ")\n",
    "from data_utils import (\n",
    "    extract_features,\n",
    "    extract_labels,\n",
    "    load_data_from_dir,\n",
    "    get_all_behaviors_labels,\n",
    "    get_all_features_by_marker,\n",
    "    extract_features_by_channel,\n",
    "    concatenate_all_data,\n",
    ")\n",
    "from calculate_correlation import (\n",
    "    EEG_BANDS_LIST,\n",
    "    get_all_behaviors_feature_to_pc_by_markers,\n",
    "    get_all_trials_average_rp_values,\n",
    ")\n",
    "\n",
    "from labels import get_categorical_labels, print_label_count\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c7230fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    load features from csv\n",
    "\"\"\"\n",
    "from dataframe.csv_utils import (\n",
    "    load_data_from_csv,\n",
    "    get_labels_from_result,\n",
    "    get_features_from_result,\n",
    ")\n",
    "\n",
    "dir_name = \"extracted_features_v1\"\n",
    "result = load_data_from_csv(dir_name)\n",
    "all_label_array, label_list = get_labels_from_result(result)\n",
    "all_feature_array, feature_names = get_features_from_result(result)\n",
    "all_feature_array = all_feature_array.drop([\"index\"], axis=1)\n",
    "feature_names = all_feature_array.columns\n",
    "print(all_feature_array.shape, len(feature_names), len(label_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1f4b9f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "ALL_DIRS = [\n",
    "    \"../CleandDataV1/2017\",\n",
    "    \"../CleandDataV1/2018\",\n",
    "    \"../CleandDataV1/2020\",\n",
    "    \"../CleandDataV1/2024\",\n",
    "    \"../CleandDataV1/2025\",\n",
    "]\n",
    "\n",
    "dir_to_data = {}\n",
    "for dir_name in ALL_DIRS:\n",
    "    all_data = load_data_from_dir(dir_name)\n",
    "    dir_to_data[dir_name] = all_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1ff65df",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataframe.extraction import (\n",
    "    extract_features_by_markers,\n",
    ")\n",
    "\n",
    "\"\"\"\n",
    "  extract features from physiological signals\n",
    "\"\"\"\n",
    "# (TODO) GSR, Resp, TREV  BP.__name__, EGG.__name__\n",
    "markers = [EEG.__name__]\n",
    "for s in ALL_DIRS:\n",
    "    # extract features\n",
    "    df = extract_features_by_markers(markers, dir_to_data, [s])\n",
    "#     print(s, df.shape)\n",
    "#     subject_features = result[result[\"Subject\"] == s]\n",
    "#     subject_features = subject_features.reset_index()\n",
    "\n",
    "    all_features = df #pd.concat([df, subject_features], axis=1)\n",
    "    # save features to csv\n",
    "    subject_name = s.replace(\"../CleandDataV1/\", \"\")\n",
    "\n",
    "\n",
    "    \"\"\" \n",
    "      extract labels from behavior data\n",
    "    \"\"\"\n",
    "    all_label_array = extract_labels(dir_to_data, all_dir=[s])\n",
    "    all_features[\"Valence\"] = all_label_array[\"valence\"]\n",
    "    all_features[\"Arousal\"] = all_label_array[\"arousal\"]\n",
    "    all_features[\"Attention\"] = all_label_array[\"attention\"]\n",
    "    all_features[\"Subject\"] = [s]*130\n",
    "    all_features.to_csv(\n",
    "        f\"extracted_features_v1/{subject_name}_features.csv\", index=False\n",
    "    )    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c90267ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    calculate correlation\n",
    "\"\"\"\n",
    "from dataframe.correlation import (\n",
    "    get_feature_to_corr_by_behavior,\n",
    "    get_behavior_to_average_corr,\n",
    ")\n",
    "\n",
    "marker = EEG.__name__\n",
    "behavior_to_rp = {}\n",
    "for b in [\"Valence\", \"Arousal\", \"Attention\"]:\n",
    "    behavior_to_rp[b] = get_feature_to_corr_by_behavior(\n",
    "        result, b, feature_names, marker, \"pearsonr\"\n",
    "    )\n",
    "\n",
    "avg_condition_to_features = get_behavior_to_average_corr(behavior_to_rp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cad5c2ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "from plotting import (\n",
    "    plot_correlation_table_by_channel,\n",
    "    plot_k_chaneels_by_r_value,\n",
    "    plot_eeg_topomap_all_blocks,\n",
    ")\n",
    "\n",
    "\"\"\" plot the single channel correlation table\n",
    "\"\"\"\n",
    "# channel = 1\n",
    "# features = STAT_FEATURES\n",
    "channel_names = MARKER_TO_CHANNEL_NAMES[marker]\n",
    "# for condition, feature_to_pc in avg_condition_to_features.items():\n",
    "#     label = f\"{channel_names[channel]} {condition}\"\n",
    "#     plot_correlation_table_by_channel(\n",
    "#         label,\n",
    "#         feature_to_pc,\n",
    "#         [\"pearson r\", \"pearson p\", \"spearman r\", \"spearman p\"],\n",
    "#         features,\n",
    "#         channel,\n",
    "#         True,\n",
    "#     )\n",
    "\n",
    "\"\"\" plot the top channel correlation table given r values\n",
    "\"\"\"\n",
    "# for condition, feature_to_pc in avg_condition_to_features.items():\n",
    "#     features = feature_to_pc.keys()\n",
    "#     plot_k_chaneels_by_r_value(feature_to_pc, channel_names, features, condition, True, 10)\n",
    "#     plot_k_chaneels_by_r_value(feature_to_pc, channel_names, features, condition, False, 10)\n",
    "\n",
    "\"\"\" \n",
    "    plot the topography for eeg\n",
    "\"\"\"\n",
    "# for condition, feature_to_pc in avg_condition_to_features.items():\n",
    "#     plot_eeg_topomap_all_blocks(condition, feature_to_pc)\n",
    "#     features = feature_to_pc.keys()\n",
    "#     for f in features:\n",
    "#         plot_eeg_topomap_one_block(condition, f, feature_to_pc, all_block_names)\n",
    "\n",
    "\n",
    "\"\"\" plot the top channel correlation table with different blocks\n",
    "\"\"\"\n",
    "# all_block_names = list(all_data.keys())\n",
    "# all_block_names.sort()\n",
    "# for condition, feature_to_pc in avg_condition_to_features.items():\n",
    "#     plot_eeg_pearson_correlation_table(condition, feature_to_pc, all_block_names, 1)\n",
    "\n",
    "\"\"\" plot the series for the top k channels\n",
    "\"\"\"\n",
    "# define number of rows and columns for subplots\n",
    "# nrow = 3\n",
    "# ncol = 2\n",
    "# for condition, feature_to_pc in avg_condition_to_features.items():\n",
    "#     print(f\"{condition}\")\n",
    "#     ser_list = get_eeg_pearson_correlation_series_all_blocks(feature_to_pc, channel_names, k=20)\n",
    "#     plot_series(nrow, ncol, ser_list)\n",
    "\n",
    "\n",
    "\"\"\" \n",
    "    plot the time series given the marker and block\n",
    "\"\"\"\n",
    "# plot_time_series_by_epoch(all_data['audio_hvla'], 'EMG', 'audio_hvla', 0)\n",
    "\n",
    "\"\"\" \n",
    "    plot the scattor for physiological signals\n",
    "\"\"\"\n",
    "# plot_pd_scatter_by_marker(\"LEOG\", result, ['../2007', '../2002', '../2006'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e3f5204",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" \n",
    "    discard high correlated features\n",
    "\"\"\"\n",
    "corr = all_feature_array.corr()\n",
    "updated = corr[(((corr < 0.9) & (corr > -0.9)) | (corr == 1)).all(axis=1)]\n",
    "all_feature_array = all_feature_array[list(updated.index.values)]\n",
    "feature_names = all_feature_array.columns\n",
    "\n",
    "print(all_feature_array.shape, len(feature_names), len(label_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac2b93ad",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "\"\"\"\n",
    "    plot the correlation heatmap\n",
    "\"\"\"\n",
    "corr = all_feature_array.corr()\n",
    "sorted_corr = corr.sort_index().sort_index(axis=1)\n",
    "truncated_corr = sorted_corr.truncate(\n",
    "    before=\"D7_ALPHA\", after=\"VEOG_VAR\", axis=\"rows\"\n",
    ").truncate(before=\"D7_ALPHA\", after=\"VEOG_VAR\", axis=\"columns\")\n",
    "\n",
    "plt.figure(figsize=(14, 12))\n",
    "sns.heatmap(truncated_corr, vmin=-1, vmax=1, annot=False, cmap=\"RdBu_r\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "333daf49",
   "metadata": {},
   "outputs": [],
   "source": [
    "from labels import get_tranformed_labels, binary_label, print_label_count\n",
    "transformed = get_tranformed_labels(all_label_array)\n",
    "label_list = get_categorical_labels(all_label_array, valence_threshold=0.6)\n",
    "valence_lables = binary_label(all_label_array['valence'], 0.6)\n",
    "print_label_count( label_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eaa25ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GroupKFold\n",
    "import shap\n",
    "\n",
    "colors = [\"c\", \"y\", \"m\", \"r\"]\n",
    "\n",
    "NUM_LABEL_PER_SUBJECT = 130\n",
    "accuracy = []\n",
    "gkf = GroupKFold()\n",
    "label_array = np.array(label_list)\n",
    "groups_list = [[i/NUM_LABEL_PER_SUBJECT] for i, j in enumerate(label_list)]\n",
    "group_array = np.hstack(groups_list)\n",
    "\n",
    "# normalize\n",
    "scaler = StandardScaler()\n",
    "normalized_all_feature_array = pd.DataFrame(\n",
    "    scaler.fit_transform(all_feature_array), columns=all_feature_array.columns\n",
    ")\n",
    "\n",
    "list_shap_values = list()\n",
    "list_test_sets = list()\n",
    "for train_index, val_index in gkf.split(\n",
    "    normalized_all_feature_array, label_array, groups=group_array\n",
    "):\n",
    "    train_features, train_labels = (\n",
    "        normalized_all_feature_array.iloc[train_index],\n",
    "        label_array[train_index],\n",
    "    )\n",
    "    val_features, val_labels = (\n",
    "        normalized_all_feature_array.iloc[val_index],\n",
    "        label_array[val_index],\n",
    "    )\n",
    "\n",
    "    # create model instance\n",
    "    model = XGBClassifier(n_estimators=2)\n",
    "    # fit model\n",
    "    model.fit(train_features, train_labels)\n",
    "    # Print accuracy.\n",
    "    acc = model.score(val_features, val_labels)\n",
    "    print(\"Accuracy: %.2f%%\" % (acc * 100.0))\n",
    "    accuracy.append(acc)\n",
    "\n",
    "    # Summary plot\n",
    "    shap_values = shap.TreeExplainer(model).shap_values(val_features)\n",
    "     #for each iteration we save the test_set index and the shap_values\n",
    "    list_shap_values.append(shap_values)\n",
    "    list_test_sets.append(val_index)\n",
    "#     color_func = lambda i: colors[i % len(shap_values)]\n",
    "#     shap.summary_plot(\n",
    "#         shap_values,\n",
    "#         all_feature_array.columns,\n",
    "#         #class_names=[\"nvla\", \"nvha\", \"hvla\", \"hvha\"],\n",
    "#         #color=color_func,\n",
    "#     )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26349f6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(accuracy)\n",
    "print(np.mean(accuracy))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abb6ad65",
   "metadata": {},
   "outputs": [],
   "source": [
    "#combining results from all iterations\n",
    "test_set = list_test_sets[0]\n",
    "shap_values = np.array(list_shap_values[0])\n",
    "for i in range(1,len(list_test_sets)):\n",
    "    test_set = np.concatenate((test_set,list_test_sets[i]),axis=0)\n",
    "    #shap_values = np.concatenate((shap_values,np.array(list_shap_values[i])),axis=1) # for multi\n",
    "    shap_values = np.concatenate((shap_values,np.array(list_shap_values[i])),axis=0) # for binary\n",
    "#bringing back variable names    \n",
    "X_test = pd.DataFrame(normalized_all_feature_array.iloc[test_set],columns=all_feature_array.columns)\n",
    "#creating explanation plot for the whole experiment, the first dimension from shap_values indicate the class we are predicting (0=0, 1=1)\n",
    "shap.summary_plot(shap_values, X_test)  # for binary\n",
    "#shap.summary_plot(shap_values[1], X_test)  # for multi i = class_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "010d750e",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = STAT_FEATURES\n",
    "marker = EOG.__name__\n",
    "\n",
    "channel_names = dir_to_data[\"../2002\"][\"audio_hvla\"].get_chanlocs(marker)\n",
    "channel_num = 0\n",
    "\"\"\" \n",
    "    extract features from physiological signals\n",
    "\"\"\"\n",
    "# features_to_trials = extract_features_by_channel(marker, dir_to_data, features, channel_num, channel_names[channel_num])\n",
    "# dir_name_to_labels = {}\n",
    "# for dir_name, all_data in dir_to_data.items():\n",
    "#     dir_name_to_labels[dir_name] = get_all_behaviors_labels(all_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad4ebf5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" \n",
    "    extract correlation from physiological signals\n",
    "\"\"\"\n",
    "num_channels = 4\n",
    "num_blocks = 0\n",
    "dir_name_to_ctf = {}\n",
    "for dir_name, all_data in dir_to_data.items():\n",
    "    dir_name_to_ctf[dir_name] = get_all_behaviors_feature_to_pc_by_markers(\n",
    "        all_data, marker, features, num_channels, num_blocks\n",
    "    )\n",
    "\n",
    "avg_condition_to_features = get_all_trials_average_rp_values(\n",
    "    dir_name_to_ctf, features, \"pearson\"\n",
    ")\n",
    "spearman_corr = get_all_trials_average_rp_values(dir_name_to_ctf, features, \"spearman\")\n",
    "for b, feature_to_pc in avg_condition_to_features.items():\n",
    "    for f, pc in feature_to_pc.items():\n",
    "        avg_condition_to_features[b][f] = np.hstack((pc, spearman_corr[b][f]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aa0ab41",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" \n",
    "    concatenate raw signal (x)\n",
    "\"\"\"\n",
    "data_list = []\n",
    "block_names = list(dir_to_data[ALL_DIRS[0]].keys())\n",
    "block_names.sort()\n",
    "\n",
    "for m in [EGG.__name__, EEG.__name__]:  # EOG.__name__, , EMG.__name__, EGG.__name__\n",
    "    all_participants_data, condition_to_labels = concatenate_all_data(dir_to_data, m)\n",
    "    all_epoch_data = np.swapaxes(\n",
    "        all_participants_data, 0, -1\n",
    "    )  # (num_channels, num_data_points, num_epochs) => (num_epochs, num_data_points, num_channels)\n",
    "\n",
    "    data_list.append(all_epoch_data)\n",
    "\n",
    "data_array = np.concatenate(data_list, axis=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "412befc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import utils as np_utils\n",
    "from models import cnn_model, train_with_cnn\n",
    "\n",
    "\"\"\" \n",
    "    prepare labels (y)\n",
    "\"\"\"\n",
    "# to one-hot encoding vector\n",
    "label_array = np_utils.to_categorical(\n",
    "    label_list, num_classes=4\n",
    ")  # nvla, nvha, hvla, hvha\n",
    "# label_array = np.array(label_list['arousal'])\n",
    "\n",
    "print_label_count(label_list)\n",
    "print(data_array.shape, label_array.shape, group_array.shape)\n",
    "\n",
    "\n",
    "num_channel = data_array.shape[2]\n",
    "\n",
    "model = cnn_model(12288, num_channel)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f925ce7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" \n",
    "    with CNN\n",
    "\"\"\"\n",
    "accuracy = train_with_cnn(12288, num_channel, data_array, label_array, group_array)\n",
    "print(accuracy)\n",
    "print(np.mean(accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dcadd95",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" \n",
    "    with logistic regression\n",
    "\"\"\"\n",
    "# from models import train_with_logistic\n",
    "\n",
    "# label_name = \"attention\"\n",
    "# best_model = train_with_logistic(all_features, label_name, condition_to_labels, group_array)\n",
    "# name_to_transformed = get_tranformed_labels(condition_to_labels)\n",
    "\n",
    "# # assume bigger coefficents has more contribution to the model\n",
    "# # but have to be sure that the features has THE SAME SCALE otherwise this assumption is not correct.\n",
    "# importance = best_model[\"classifier\"].coef_[0]\n",
    "\n",
    "# feat_importances = pd.Series(importance, index=get_feature_names(importance))\n",
    "# feat_importances.nlargest(10).plot(\n",
    "#     kind=\"barh\", title=f\"{label_name} Feature Importance\"\n",
    "# )\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10 (v3.8.10:3d8993a744, May  3 2021, 09:09:08) \n[Clang 12.0.5 (clang-1205.0.22.9)]"
  },
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
