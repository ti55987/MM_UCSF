{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "30a3799e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import timeit\n",
    "\n",
    "# from importlib import reload\n",
    "# import feature_extraction\n",
    "# reload(feature_extraction)\n",
    "from biomarkers import (\n",
    "    EEG,\n",
    "    EMG,\n",
    "    BP,\n",
    "    EOG,\n",
    "    ECG,\n",
    "    TREV,\n",
    "    GSR,\n",
    "    Resp,\n",
    "    EGG,\n",
    "    MARKER_TO_CHANNEL_NAMES,\n",
    ")\n",
    "from feature_extraction import (\n",
    "    Feature,\n",
    "    EEG_BANDS,\n",
    "    STAT_FEATURES,\n",
    ")\n",
    "from data_utils import (\n",
    "    extract_labels,\n",
    "    load_data_from_dir,\n",
    "    get_all_behaviors_labels,\n",
    "    extract_features_by_channel,\n",
    ")\n",
    "from calculate_correlation import (\n",
    "    EEG_BANDS_LIST,\n",
    "    get_all_behaviors_feature_to_pc_by_markers,\n",
    "    get_all_trials_average_rp_values,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1c7230fb",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "No objects to concatenate",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[0;32mIn [1]\u001b[0m, in \u001b[0;36m<cell line: 11>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdataframe\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcsv_utils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m      5\u001b[0m     load_data_from_csv,\n\u001b[1;32m      6\u001b[0m     get_labels_from_result,\n\u001b[1;32m      7\u001b[0m     get_features_from_result,\n\u001b[1;32m      8\u001b[0m )\n\u001b[1;32m     10\u001b[0m dir_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mextracted_features_v1\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m---> 11\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mload_data_from_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdir_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     12\u001b[0m all_label_array, label_list \u001b[38;5;241m=\u001b[39m get_labels_from_result(result)\n\u001b[1;32m     13\u001b[0m all_feature_array, feature_names \u001b[38;5;241m=\u001b[39m get_features_from_result(result)\n",
      "File \u001b[0;32m~/Development/volunteer/MM_UCSF/analysis/dataframe/csv_utils.py:19\u001b[0m, in \u001b[0;36mload_data_from_csv\u001b[0;34m(dir_name)\u001b[0m\n\u001b[1;32m     16\u001b[0m         df \u001b[38;5;241m=\u001b[39m df[mask]\n\u001b[1;32m     17\u001b[0m     frames\u001b[38;5;241m.\u001b[39mappend(df)\n\u001b[0;32m---> 19\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconcat\u001b[49m\u001b[43m(\u001b[49m\u001b[43mframes\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/MM/lib/python3.8/site-packages/pandas/util/_decorators.py:311\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    305\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m num_allow_args:\n\u001b[1;32m    306\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m    307\u001b[0m         msg\u001b[38;5;241m.\u001b[39mformat(arguments\u001b[38;5;241m=\u001b[39marguments),\n\u001b[1;32m    308\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[1;32m    309\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mstacklevel,\n\u001b[1;32m    310\u001b[0m     )\n\u001b[0;32m--> 311\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/MM/lib/python3.8/site-packages/pandas/core/reshape/concat.py:346\u001b[0m, in \u001b[0;36mconcat\u001b[0;34m(objs, axis, join, ignore_index, keys, levels, names, verify_integrity, sort, copy)\u001b[0m\n\u001b[1;32m    142\u001b[0m \u001b[38;5;129m@deprecate_nonkeyword_arguments\u001b[39m(version\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, allowed_args\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mobjs\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m    143\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mconcat\u001b[39m(\n\u001b[1;32m    144\u001b[0m     objs: Iterable[NDFrame] \u001b[38;5;241m|\u001b[39m Mapping[Hashable, NDFrame],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    153\u001b[0m     copy: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m    154\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame \u001b[38;5;241m|\u001b[39m Series:\n\u001b[1;32m    155\u001b[0m     \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    156\u001b[0m \u001b[38;5;124;03m    Concatenate pandas objects along a particular axis with optional set logic\u001b[39;00m\n\u001b[1;32m    157\u001b[0m \u001b[38;5;124;03m    along the other axes.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    344\u001b[0m \u001b[38;5;124;03m    ValueError: Indexes have overlapping values: ['a']\u001b[39;00m\n\u001b[1;32m    345\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 346\u001b[0m     op \u001b[38;5;241m=\u001b[39m \u001b[43m_Concatenator\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    347\u001b[0m \u001b[43m        \u001b[49m\u001b[43mobjs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    348\u001b[0m \u001b[43m        \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    349\u001b[0m \u001b[43m        \u001b[49m\u001b[43mignore_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    350\u001b[0m \u001b[43m        \u001b[49m\u001b[43mjoin\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    351\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkeys\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkeys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    352\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlevels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlevels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    353\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnames\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnames\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    354\u001b[0m \u001b[43m        \u001b[49m\u001b[43mverify_integrity\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverify_integrity\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    355\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    356\u001b[0m \u001b[43m        \u001b[49m\u001b[43msort\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msort\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    357\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    359\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m op\u001b[38;5;241m.\u001b[39mget_result()\n",
      "File \u001b[0;32m~/miniconda3/envs/MM/lib/python3.8/site-packages/pandas/core/reshape/concat.py:403\u001b[0m, in \u001b[0;36m_Concatenator.__init__\u001b[0;34m(self, objs, axis, join, keys, levels, names, ignore_index, verify_integrity, copy, sort)\u001b[0m\n\u001b[1;32m    400\u001b[0m     objs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(objs)\n\u001b[1;32m    402\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(objs) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m--> 403\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo objects to concatenate\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    405\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m keys \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    406\u001b[0m     objs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(com\u001b[38;5;241m.\u001b[39mnot_none(\u001b[38;5;241m*\u001b[39mobjs))\n",
      "\u001b[0;31mValueError\u001b[0m: No objects to concatenate"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "    load features from csv\n",
    "\"\"\"\n",
    "from dataframe.csv_utils import (\n",
    "    load_data_from_csv,\n",
    "    get_labels_from_result,\n",
    "    get_features_from_result,\n",
    ")\n",
    "\n",
    "dir_name = \"extracted_features_v1\"\n",
    "result = load_data_from_csv(dir_name)\n",
    "all_label_array, label_list = get_labels_from_result(result)\n",
    "all_feature_array, feature_names = get_features_from_result(result)\n",
    "all_feature_array = all_feature_array.drop([\"index\"], axis=1)\n",
    "feature_names = all_feature_array.columns\n",
    "print(all_feature_array.shape, len(feature_names), len(label_list))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e1f4b9f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading ../CleandDataV2/2011 data...\n",
      "Loading ../CleandDataV2/2012 data...\n",
      "Loading ../CleandDataV2/2013 data...\n"
     ]
    }
   ],
   "source": [
    "all_dirs = []\n",
    "subjects = [\"2011\", '2012', '2013']\n",
    "for subj in subjects:\n",
    "    all_dirs.append(f\"../CleandDataV2/{subj}\")\n",
    "\n",
    "dir_to_data = {}\n",
    "for dir_name in all_dirs:\n",
    "    all_data = load_data_from_dir(dir_name)\n",
    "    dir_to_data[dir_name] = all_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d1ff65df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting PSD features for 0...\n",
      "Extracting PSD features for 1...\n",
      "Extracting PSD features for 2...\n",
      "Extracting PSD features for 3...\n",
      "Extracting PSD features for 4...\n",
      "Extracting PSD features for 5...\n",
      "Extracting PSD features for 6...\n",
      "Extracting PSD features for 7...\n",
      "Extracting PSD features for 8...\n",
      "Extracting PSD features for 9...\n",
      "Extracting PSD features for 10...\n",
      "Extracting PSD features for 11...\n",
      "Extracting PSD features for 12...\n",
      "Extracting PSD features for 13...\n",
      "Extracting PSD features for 14...\n",
      "Extracting PSD features for 15...\n",
      "Extracting PSD features for 16...\n",
      "Extracting PSD features for 17...\n",
      "Extracting PSD features for 18...\n",
      "Extracting PSD features for 19...\n",
      "Extracting PSD features for 20...\n",
      "Extracting PSD features for 21...\n",
      "Extracting PSD features for 22...\n",
      "Extracting PSD features for 23...\n",
      "Extracting PSD features for 24...\n",
      "Extracting PSD features for 25...\n",
      "Extracting PSD features for 26...\n",
      "Extracting PSD features for 27...\n",
      "Extracting PSD features for 28...\n",
      "Extracting PSD features for 29...\n",
      "Extracting PSD features for 30...\n",
      "Extracting PSD features for 31...\n",
      "Extracting PSD features for 32...\n",
      "Extracting PSD features for 33...\n",
      "Extracting PSD features for 34...\n",
      "Extracting PSD features for 35...\n",
      "Extracting PSD features for 36...\n",
      "Extracting PSD features for 37...\n",
      "Extracting PSD features for 38...\n",
      "Extracting PSD features for 39...\n",
      "Extracting PSD features for 40...\n",
      "Extracting PSD features for 41...\n",
      "Extracting PSD features for 42...\n",
      "Extracting PSD features for 43...\n",
      "Extracting PSD features for 44...\n",
      "Extracting PSD features for 45...\n",
      "Extracting PSD features for 46...\n",
      "Extracting PSD features for 47...\n",
      "Extracting PSD features for 48...\n",
      "Extracting PSD features for 49...\n",
      "Extracting PSD features for 50...\n",
      "Extracting PSD features for 51...\n",
      "Extracting PSD features for 52...\n",
      "Extracting PSD features for 53...\n",
      "Extracting PSD features for 54...\n",
      "Extracting PSD features for 55...\n",
      "Extracting PSD features for 56...\n",
      "Extracting PSD features for 57...\n",
      "Extracting PSD features for 58...\n",
      "Extracting PSD features for 59...\n",
      "Extracting PSD features for 60...\n",
      "Extracting PSD features for 61...\n",
      "Extracting PSD features for 62...\n",
      "Extracting PSD features for 63...\n",
      "Extracting PSD features for 64...\n",
      "Extracting PSD features for 65...\n",
      "Extracting PSD features for 66...\n",
      "Extracting PSD features for 67...\n",
      "Extracting PSD features for 68...\n",
      "Extracting PSD features for 69...\n",
      "Extracting PSD features for 70...\n",
      "Extracting PSD features for 71...\n",
      "Extracting PSD features for 72...\n",
      "Extracting PSD features for 73...\n",
      "Extracting PSD features for 74...\n",
      "Extracting PSD features for 75...\n",
      "Extracting PSD features for 76...\n",
      "Extracting PSD features for 77...\n",
      "Extracting PSD features for 78...\n",
      "Extracting PSD features for 79...\n",
      "Extracting PSD features for 80...\n",
      "Extracting PSD features for 81...\n",
      "Extracting PSD features for 82...\n",
      "Extracting PSD features for 83...\n",
      "Extracting PSD features for 84...\n",
      "Extracting PSD features for 85...\n",
      "Extracting PSD features for 86...\n",
      "Extracting PSD features for 87...\n",
      "Extracting PSD features for 88...\n",
      "Extracting PSD features for 89...\n",
      "Extracting PSD features for 90...\n",
      "Extracting PSD features for 91...\n",
      "Extracting PSD features for 92...\n",
      "Extracting PSD features for 93...\n",
      "Extracting PSD features for 94...\n",
      "Extracting PSD features for 95...\n",
      "Extracting PSD features for 96...\n",
      "Extracting PSD features for 97...\n",
      "Extracting PSD features for 98...\n",
      "Extracting PSD features for 99...\n",
      "Extracting PSD features for 100...\n",
      "Extracting PSD features for 101...\n",
      "Extracting PSD features for 102...\n",
      "Extracting PSD features for 103...\n",
      "Extracting PSD features for 104...\n",
      "Extracting PSD features for 105...\n",
      "Extracting PSD features for 106...\n",
      "Extracting PSD features for 107...\n",
      "Extracting PSD features for 108...\n",
      "Extracting PSD features for 109...\n",
      "Extracting PSD features for 110...\n",
      "Extracting PSD features for 111...\n",
      "Extracting PSD features for 112...\n",
      "Extracting PSD features for 113...\n",
      "Extracting PSD features for 114...\n",
      "Extracting PSD features for 115...\n",
      "Extracting PSD features for 116...\n",
      "Extracting PSD features for 117...\n",
      "Extracting PSD features for 118...\n",
      "Extracting PSD features for 119...\n",
      "Extracting PSD features for 120...\n",
      "Extracting PSD features for 121...\n",
      "Extracting PSD features for 122...\n",
      "Extracting PSD features for 123...\n",
      "Extracting PSD features for 124...\n",
      "Extracting PSD features for 125...\n",
      "Extracting PSD features for 126...\n",
      "Extracting PSD features for 127...\n",
      "extracted EEG stats or PSD features\n",
      "The time difference is : 638.6489637510003\n",
      "Extracting PSD features for 0...\n",
      "Extracting PSD features for 1...\n",
      "Extracting PSD features for 2...\n",
      "Extracting PSD features for 3...\n",
      "Extracting PSD features for 4...\n",
      "Extracting PSD features for 5...\n",
      "Extracting PSD features for 6...\n",
      "Extracting PSD features for 7...\n",
      "Extracting PSD features for 8...\n",
      "Extracting PSD features for 9...\n",
      "Extracting PSD features for 10...\n",
      "Extracting PSD features for 11...\n",
      "Extracting PSD features for 12...\n",
      "Extracting PSD features for 13...\n",
      "Extracting PSD features for 14...\n",
      "Extracting PSD features for 15...\n",
      "Extracting PSD features for 16...\n",
      "Extracting PSD features for 17...\n",
      "Extracting PSD features for 18...\n",
      "Extracting PSD features for 19...\n",
      "Extracting PSD features for 20...\n",
      "Extracting PSD features for 21...\n",
      "Extracting PSD features for 22...\n",
      "Extracting PSD features for 23...\n",
      "Extracting PSD features for 24...\n",
      "Extracting PSD features for 25...\n",
      "Extracting PSD features for 26...\n",
      "Extracting PSD features for 27...\n",
      "Extracting PSD features for 28...\n",
      "Extracting PSD features for 29...\n",
      "Extracting PSD features for 30...\n",
      "Extracting PSD features for 31...\n",
      "Extracting PSD features for 32...\n",
      "Extracting PSD features for 33...\n",
      "Extracting PSD features for 34...\n",
      "Extracting PSD features for 35...\n",
      "Extracting PSD features for 36...\n",
      "Extracting PSD features for 37...\n",
      "Extracting PSD features for 38...\n",
      "Extracting PSD features for 39...\n",
      "Extracting PSD features for 40...\n",
      "Extracting PSD features for 41...\n",
      "Extracting PSD features for 42...\n",
      "Extracting PSD features for 43...\n",
      "Extracting PSD features for 44...\n",
      "Extracting PSD features for 45...\n",
      "Extracting PSD features for 46...\n",
      "Extracting PSD features for 47...\n",
      "Extracting PSD features for 48...\n",
      "Extracting PSD features for 49...\n",
      "Extracting PSD features for 50...\n",
      "Extracting PSD features for 51...\n",
      "Extracting PSD features for 52...\n",
      "Extracting PSD features for 53...\n",
      "Extracting PSD features for 54...\n",
      "Extracting PSD features for 55...\n",
      "Extracting PSD features for 56...\n",
      "Extracting PSD features for 57...\n",
      "Extracting PSD features for 58...\n",
      "Extracting PSD features for 59...\n",
      "Extracting PSD features for 60...\n",
      "Extracting PSD features for 61...\n",
      "Extracting PSD features for 62...\n",
      "Extracting PSD features for 63...\n",
      "Extracting PSD features for 64...\n",
      "Extracting PSD features for 65...\n",
      "Extracting PSD features for 66...\n",
      "Extracting PSD features for 67...\n",
      "Extracting PSD features for 68...\n",
      "Extracting PSD features for 69...\n",
      "Extracting PSD features for 70...\n",
      "Extracting PSD features for 71...\n",
      "Extracting PSD features for 72...\n",
      "Extracting PSD features for 73...\n",
      "Extracting PSD features for 74...\n",
      "Extracting PSD features for 75...\n",
      "Extracting PSD features for 76...\n",
      "Extracting PSD features for 77...\n",
      "Extracting PSD features for 78...\n",
      "Extracting PSD features for 79...\n",
      "Extracting PSD features for 80...\n",
      "Extracting PSD features for 81...\n",
      "Extracting PSD features for 82...\n",
      "Extracting PSD features for 83...\n",
      "Extracting PSD features for 84...\n",
      "Extracting PSD features for 85...\n",
      "Extracting PSD features for 86...\n",
      "Extracting PSD features for 87...\n",
      "Extracting PSD features for 88...\n",
      "Extracting PSD features for 89...\n",
      "Extracting PSD features for 90...\n",
      "Extracting PSD features for 91...\n",
      "Extracting PSD features for 92...\n",
      "Extracting PSD features for 93...\n",
      "Extracting PSD features for 94...\n",
      "Extracting PSD features for 95...\n",
      "Extracting PSD features for 96...\n",
      "Extracting PSD features for 97...\n",
      "Extracting PSD features for 98...\n",
      "Extracting PSD features for 99...\n",
      "Extracting PSD features for 100...\n",
      "Extracting PSD features for 101...\n",
      "Extracting PSD features for 102...\n",
      "Extracting PSD features for 103...\n",
      "Extracting PSD features for 104...\n",
      "Extracting PSD features for 105...\n",
      "Extracting PSD features for 106...\n",
      "Extracting PSD features for 107...\n",
      "Extracting PSD features for 108...\n",
      "Extracting PSD features for 109...\n",
      "Extracting PSD features for 110...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting PSD features for 111...\n",
      "Extracting PSD features for 112...\n",
      "Extracting PSD features for 113...\n",
      "Extracting PSD features for 114...\n",
      "Extracting PSD features for 115...\n",
      "Extracting PSD features for 116...\n",
      "Extracting PSD features for 117...\n",
      "Extracting PSD features for 118...\n",
      "Extracting PSD features for 119...\n",
      "Extracting PSD features for 120...\n",
      "Extracting PSD features for 121...\n",
      "Extracting PSD features for 122...\n",
      "Extracting PSD features for 123...\n",
      "Extracting PSD features for 124...\n",
      "Extracting PSD features for 125...\n",
      "Extracting PSD features for 126...\n",
      "Extracting PSD features for 127...\n",
      "extracted EEG stats or PSD features\n",
      "The time difference is : 684.5199775049996\n",
      "Extracting PSD features for 0...\n",
      "Extracting PSD features for 1...\n",
      "Extracting PSD features for 2...\n",
      "Extracting PSD features for 3...\n",
      "Extracting PSD features for 4...\n",
      "Extracting PSD features for 5...\n",
      "Extracting PSD features for 6...\n",
      "Extracting PSD features for 7...\n",
      "Extracting PSD features for 8...\n",
      "Extracting PSD features for 9...\n",
      "Extracting PSD features for 10...\n",
      "Extracting PSD features for 11...\n",
      "Extracting PSD features for 12...\n",
      "Extracting PSD features for 13...\n",
      "Extracting PSD features for 14...\n",
      "Extracting PSD features for 15...\n",
      "Extracting PSD features for 16...\n",
      "Extracting PSD features for 17...\n",
      "Extracting PSD features for 18...\n",
      "Extracting PSD features for 19...\n",
      "Extracting PSD features for 20...\n",
      "Extracting PSD features for 21...\n",
      "Extracting PSD features for 22...\n",
      "Extracting PSD features for 23...\n",
      "Extracting PSD features for 24...\n",
      "Extracting PSD features for 25...\n",
      "Extracting PSD features for 26...\n",
      "Extracting PSD features for 27...\n",
      "Extracting PSD features for 28...\n",
      "Extracting PSD features for 29...\n",
      "Extracting PSD features for 30...\n",
      "Extracting PSD features for 31...\n",
      "Extracting PSD features for 32...\n",
      "Extracting PSD features for 33...\n",
      "Extracting PSD features for 34...\n",
      "Extracting PSD features for 35...\n",
      "Extracting PSD features for 36...\n",
      "Extracting PSD features for 37...\n",
      "Extracting PSD features for 38...\n",
      "Extracting PSD features for 39...\n",
      "Extracting PSD features for 40...\n",
      "Extracting PSD features for 41...\n",
      "Extracting PSD features for 42...\n",
      "Extracting PSD features for 43...\n",
      "Extracting PSD features for 44...\n",
      "Extracting PSD features for 45...\n",
      "Extracting PSD features for 46...\n",
      "Extracting PSD features for 47...\n",
      "Extracting PSD features for 48...\n",
      "Extracting PSD features for 49...\n",
      "Extracting PSD features for 50...\n",
      "Extracting PSD features for 51...\n",
      "Extracting PSD features for 52...\n",
      "Extracting PSD features for 53...\n",
      "Extracting PSD features for 54...\n",
      "Extracting PSD features for 55...\n",
      "Extracting PSD features for 56...\n",
      "Extracting PSD features for 57...\n",
      "Extracting PSD features for 58...\n",
      "Extracting PSD features for 59...\n",
      "Extracting PSD features for 60...\n",
      "Extracting PSD features for 61...\n",
      "Extracting PSD features for 62...\n",
      "Extracting PSD features for 63...\n",
      "Extracting PSD features for 64...\n",
      "Extracting PSD features for 65...\n",
      "Extracting PSD features for 66...\n",
      "Extracting PSD features for 67...\n",
      "Extracting PSD features for 68...\n",
      "Extracting PSD features for 69...\n",
      "Extracting PSD features for 70...\n",
      "Extracting PSD features for 71...\n",
      "Extracting PSD features for 72...\n",
      "Extracting PSD features for 73...\n",
      "Extracting PSD features for 74...\n",
      "Extracting PSD features for 75...\n",
      "Extracting PSD features for 76...\n",
      "Extracting PSD features for 77...\n",
      "Extracting PSD features for 78...\n",
      "Extracting PSD features for 79...\n",
      "Extracting PSD features for 80...\n",
      "Extracting PSD features for 81...\n",
      "Extracting PSD features for 82...\n",
      "Extracting PSD features for 83...\n",
      "Extracting PSD features for 84...\n",
      "Extracting PSD features for 85...\n",
      "Extracting PSD features for 86...\n",
      "Extracting PSD features for 87...\n",
      "Extracting PSD features for 88...\n",
      "Extracting PSD features for 89...\n",
      "Extracting PSD features for 90...\n",
      "Extracting PSD features for 91...\n",
      "Extracting PSD features for 92...\n",
      "Extracting PSD features for 93...\n",
      "Extracting PSD features for 94...\n",
      "Extracting PSD features for 95...\n",
      "Extracting PSD features for 96...\n",
      "Extracting PSD features for 97...\n",
      "Extracting PSD features for 98...\n",
      "Extracting PSD features for 99...\n",
      "Extracting PSD features for 100...\n",
      "Extracting PSD features for 101...\n",
      "Extracting PSD features for 102...\n",
      "Extracting PSD features for 103...\n",
      "Extracting PSD features for 104...\n",
      "Extracting PSD features for 105...\n",
      "Extracting PSD features for 106...\n",
      "Extracting PSD features for 107...\n",
      "Extracting PSD features for 108...\n",
      "Extracting PSD features for 109...\n",
      "Extracting PSD features for 110...\n",
      "Extracting PSD features for 111...\n",
      "Extracting PSD features for 112...\n",
      "Extracting PSD features for 113...\n",
      "Extracting PSD features for 114...\n",
      "Extracting PSD features for 115...\n",
      "Extracting PSD features for 116...\n",
      "Extracting PSD features for 117...\n",
      "Extracting PSD features for 118...\n",
      "Extracting PSD features for 119...\n",
      "Extracting PSD features for 120...\n",
      "Extracting PSD features for 121...\n",
      "Extracting PSD features for 122...\n",
      "Extracting PSD features for 123...\n",
      "Extracting PSD features for 124...\n",
      "Extracting PSD features for 125...\n",
      "Extracting PSD features for 126...\n",
      "Extracting PSD features for 127...\n",
      "extracted EEG stats or PSD features\n",
      "The time difference is : 722.3877146679988\n"
     ]
    }
   ],
   "source": [
    "from dataframe.extraction import (\n",
    "    extract_features_by_markers,\n",
    ")\n",
    "\n",
    "\"\"\"\n",
    "  extract features from physiological signals\n",
    "\"\"\"\n",
    "# (TODO) GSR, Resp, TREV  BP.__name__, EGG.__name__\n",
    "markers = [EEG.__name__]\n",
    "for s in all_dirs:\n",
    "    starttime = timeit.default_timer()\n",
    "    # extract features\n",
    "    df = extract_features_by_markers(markers, dir_to_data, [s])\n",
    "    #     print(s, df.shape)\n",
    "    #     subject_features = result[result[\"Subject\"] == s]\n",
    "    #     subject_features = subject_features.reset_index()\n",
    "\n",
    "    print(\"The time difference is :\", timeit.default_timer() - starttime)\n",
    "    all_features = df  # pd.concat([df, subject_features], axis=1)\n",
    "    # save features to csv\n",
    "    subject_name = s.replace(\"../CleandDataV2/\", \"\")\n",
    "    \"\"\" \n",
    "      extract labels from behavior data\n",
    "    \"\"\"\n",
    "    all_label_array = extract_labels(dir_to_data, all_dir=[s])\n",
    "    all_features[\"Valence\"] = all_label_array[\"valence\"]\n",
    "    all_features[\"Arousal\"] = all_label_array[\"arousal\"]\n",
    "    all_features[\"Attention\"] = all_label_array[\"attention\"]\n",
    "    all_features[\"Subject\"] = [subject_name] * 130\n",
    "    all_features.to_csv(f\"eeg_features2/{subject_name}_features.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b784d869",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "\n",
    "def get_umap(result: pd.DataFrame):\n",
    "    from umap import UMAP\n",
    "    features = result.drop('condition', axis=1)\n",
    "    \n",
    "    # Run UMAP\n",
    "    umap2d = UMAP(n_components=2, init=\"random\", random_state=0)\n",
    "    proj_2d = pd.DataFrame(umap2d.fit_transform(features))\n",
    "\n",
    "    # Concatanate the umap points and original data\n",
    "    proj_2d.columns = [\"C1_2d\", \"C2_2d\"]\n",
    "    result = result.reset_index()\n",
    "    return pd.concat([result, proj_2d], axis=1, join=\"inner\")\n",
    "\n",
    "def get_conditions(condition: str, mode: str):\n",
    "    if mode == 'v':\n",
    "        if 'hv' in condition:\n",
    "            return 'h_valence'\n",
    "        elif 'nv' in condition:\n",
    "            return 'n_valence'\n",
    "    elif mode == 'a':\n",
    "        if 'ha' in condition:\n",
    "            return 'h_arousal'\n",
    "        elif 'la' in condition:\n",
    "            return 'l_arousal'\n",
    "    else:\n",
    "        if 'breath' in condition:\n",
    "            return 'breath'\n",
    "        elif 'audio' in condition:\n",
    "            return 'audio'\n",
    "    return condition\n",
    "        \n",
    "\n",
    "    \n",
    "all_df = pd.DataFrame()\n",
    "marker = 'EMG'\n",
    "for condition, markers in all_data.items():\n",
    "    df = pd.DataFrame(data=np.swapaxes(markers.get_all_data()[marker][0], 0, 1))\n",
    "    condition = get_conditions(condition, 'v')       \n",
    "    df['condition'] = [condition]*data[2].shape[1]\n",
    "    all_df = pd.concat([all_df, df], axis=0)\n",
    "\n",
    "plotX = get_umap(all_df)\n",
    "\n",
    "fig = px.scatter(\n",
    "    plotX,\n",
    "    x=\"C1_2d\",\n",
    "    y=\"C2_2d\",\n",
    "    color=\"condition\",\n",
    ")\n",
    "fig.update_layout(\n",
    "    title_text=f'Subject 2024 {marker}'\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c90267ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    calculate correlation\n",
    "\"\"\"\n",
    "from dataframe.correlation import (\n",
    "    get_feature_to_corr_by_behavior,\n",
    "    get_behavior_to_average_corr,\n",
    ")\n",
    "\n",
    "marker = EEG.__name__\n",
    "behavior_to_rp = {}\n",
    "for b in [\"Valence\", \"Arousal\", \"Attention\"]:\n",
    "    behavior_to_rp[b] = get_feature_to_corr_by_behavior(\n",
    "        result, b, feature_names, marker, \"pearsonr\"\n",
    "    )\n",
    "\n",
    "avg_condition_to_features = get_behavior_to_average_corr(behavior_to_rp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cad5c2ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "from plotting import (\n",
    "    plot_correlation_table_by_channel,\n",
    "    plot_k_chaneels_by_r_value,\n",
    "    plot_eeg_topomap_all_blocks,\n",
    "    plot_time_series_by_epoch,\n",
    ")\n",
    "\n",
    "\"\"\" plot the single channel correlation table\n",
    "\"\"\"\n",
    "# channel = 1\n",
    "# features = STAT_FEATURES\n",
    "# channel_names = MARKER_TO_CHANNEL_NAMES[marker]\n",
    "# for condition, feature_to_pc in avg_condition_to_features.items():\n",
    "#     label = f\"{channel_names[channel]} {condition}\"\n",
    "#     plot_correlation_table_by_channel(\n",
    "#         label,\n",
    "#         feature_to_pc,\n",
    "#         [\"pearson r\", \"pearson p\", \"spearman r\", \"spearman p\"],\n",
    "#         features,\n",
    "#         channel,\n",
    "#         True,\n",
    "#     )\n",
    "\n",
    "\"\"\" plot the top channel correlation table given r values\n",
    "\"\"\"\n",
    "# for condition, feature_to_pc in avg_condition_to_features.items():\n",
    "#     features = feature_to_pc.keys()\n",
    "#     plot_k_chaneels_by_r_value(feature_to_pc, channel_names, features, condition, True, 10)\n",
    "#     plot_k_chaneels_by_r_value(feature_to_pc, channel_names, features, condition, False, 10)\n",
    "\n",
    "\"\"\" \n",
    "    plot the topography for eeg\n",
    "\"\"\"\n",
    "# for condition, feature_to_pc in avg_condition_to_features.items():\n",
    "#     plot_eeg_topomap_all_blocks(condition, feature_to_pc)\n",
    "#     features = feature_to_pc.keys()\n",
    "#     for f in features:\n",
    "#         plot_eeg_topomap_one_block(condition, f, feature_to_pc, all_block_names)\n",
    "\n",
    "\n",
    "\"\"\" plot the top channel correlation table with different blocks\n",
    "\"\"\"\n",
    "# all_block_names = list(all_data.keys())\n",
    "# all_block_names.sort()\n",
    "# for condition, feature_to_pc in avg_condition_to_features.items():\n",
    "#     plot_eeg_pearson_correlation_table(condition, feature_to_pc, all_block_names, 1)\n",
    "\n",
    "\"\"\" plot the series for the top k channels\n",
    "\"\"\"\n",
    "# define number of rows and columns for subplots\n",
    "# nrow = 3\n",
    "# ncol = 2\n",
    "# for condition, feature_to_pc in avg_condition_to_features.items():\n",
    "#     print(f\"{condition}\")\n",
    "#     ser_list = get_eeg_pearson_correlation_series_all_blocks(feature_to_pc, channel_names, k=20)\n",
    "#     plot_series(nrow, ncol, ser_list)\n",
    "\n",
    "\n",
    "\"\"\" \n",
    "    plot the time series given the marker and block\n",
    "\"\"\"\n",
    "# plot_time_series_by_epoch(all_data['audio_hvla'], 'EEG', 'audio_hvla', 0)\n",
    "\n",
    "\"\"\" \n",
    "    plot the scattor for physiological signals\n",
    "\"\"\"\n",
    "# plot_pd_scatter_by_marker(\"LEOG\", result, ['../2007', '../2002', '../2006'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e3f5204",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" \n",
    "    discard high correlated features\n",
    "\"\"\"\n",
    "corr = all_feature_array.corr()\n",
    "updated = corr[(((corr < 0.9) & (corr > -0.9)) | (corr == 1)).all(axis=1)]\n",
    "all_feature_array = all_feature_array[list(updated.index.values)]\n",
    "feature_names = all_feature_array.columns\n",
    "\n",
    "print(all_feature_array.shape, len(feature_names), len(label_list))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac2b93ad",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "\"\"\"\n",
    "    plot the correlation heatmap\n",
    "\"\"\"\n",
    "corr = all_feature_array.corr()\n",
    "sorted_corr = corr.sort_index().sort_index(axis=1)\n",
    "truncated_corr = sorted_corr.truncate(\n",
    "    before=\"D7_ALPHA\", after=\"VEOG_VAR\", axis=\"rows\"\n",
    ").truncate(before=\"D7_ALPHA\", after=\"VEOG_VAR\", axis=\"columns\")\n",
    "\n",
    "plt.figure(figsize=(14, 12))\n",
    "sns.heatmap(truncated_corr, vmin=-1, vmax=1, annot=False, cmap=\"RdBu_r\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "010d750e",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = STAT_FEATURES\n",
    "marker = EOG.__name__\n",
    "\n",
    "channel_names = dir_to_data[\"../2002\"][\"audio_hvla\"].get_chanlocs(marker)\n",
    "channel_num = 0\n",
    "\"\"\" \n",
    "    extract features from physiological signals\n",
    "\"\"\"\n",
    "# features_to_trials = extract_features_by_channel(marker, dir_to_data, features, channel_num, channel_names[channel_num])\n",
    "# dir_name_to_labels = {}\n",
    "# for dir_name, all_data in dir_to_data.items():\n",
    "#     dir_name_to_labels[dir_name] = get_all_behaviors_labels(all_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad4ebf5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" \n",
    "    extract correlation from physiological signals\n",
    "\"\"\"\n",
    "num_channels = 4\n",
    "num_blocks = 0\n",
    "dir_name_to_ctf = {}\n",
    "for dir_name, all_data in dir_to_data.items():\n",
    "    dir_name_to_ctf[dir_name] = get_all_behaviors_feature_to_pc_by_markers(\n",
    "        all_data, marker, features, num_channels, num_blocks\n",
    "    )\n",
    "\n",
    "avg_condition_to_features = get_all_trials_average_rp_values(\n",
    "    dir_name_to_ctf, features, \"pearson\"\n",
    ")\n",
    "spearman_corr = get_all_trials_average_rp_values(dir_name_to_ctf, features, \"spearman\")\n",
    "for b, feature_to_pc in avg_condition_to_features.items():\n",
    "    for f, pc in feature_to_pc.items():\n",
    "        avg_condition_to_features[b][f] = np.hstack((pc, spearman_corr[b][f]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
