{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30a3799e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import mne\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# from importlib import reload\n",
    "# import feature_extraction\n",
    "# reload(feature_extraction)\n",
    "from plotting import (\n",
    "    plot_series,\n",
    "    plot_eeg_topomap_one_block,\n",
    "    plot_eeg_topomap_all_blocks,\n",
    "    plot_k_chaneels_by_r_value,\n",
    "    plot_eeg_pearson_correlation_table,\n",
    "    get_eeg_pearson_correlation_series_all_blocks,\n",
    "    plot_time_series_by_epoch,\n",
    "    plot_scatter_by_marker,\n",
    ")\n",
    "from biomarkers import (\n",
    "    EEG,\n",
    "    EMG,\n",
    "    BP,\n",
    "    EOG,\n",
    "    ECG,\n",
    "    TREV,\n",
    "    GSR,\n",
    "    EGG,\n",
    ")\n",
    "from feature_extraction import (\n",
    "    Feature,\n",
    "    EEG_BANDS,\n",
    "    FEATURE_TO_FUNC,\n",
    ")\n",
    "from data_utils import (\n",
    "    load_data_from_dir,\n",
    "    get_all_behaviors_labels,\n",
    "    get_all_features_by_marker,\n",
    "    extract_labels,\n",
    "    extract_features_by_channel,\n",
    "    concatenate_all_data,\n",
    ")\n",
    "from calculate_correlation import (\n",
    "    STAT_FEATURES,\n",
    "    get_all_behaviors_feature_to_pc_by_markers,\n",
    "    get_all_trials_average_rp_values,\n",
    ")\n",
    "\n",
    "# Train machine learning models\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.model_selection import (\n",
    "    GroupKFold,\n",
    "    GridSearchCV,\n",
    "    cross_val_score,\n",
    "    cross_validate,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1f4b9f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "ALL_DIRS = [\"../2000_CleanData\", \"../2001_CleanData\", \"../1004_CleanData\"]\n",
    "\n",
    "dir_to_data = {}\n",
    "for dir_name in ALL_DIRS:\n",
    "    all_data = load_data_from_dir(dir_name)\n",
    "    dir_to_data[dir_name] = all_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4f557af",
   "metadata": {},
   "outputs": [],
   "source": [
    "from importlib import reload\n",
    "import data_utils\n",
    "reload(data_utils)\n",
    "\n",
    "from data_utils import (\n",
    "    get_all_features_by_marker,\n",
    "    extract_features_by_channel,\n",
    ")\n",
    "\n",
    "def _extract_features_by_channel(marker: str, dir_to_data: dict, features: list, channel_num: int):\n",
    "    dir_name_to_features = {}\n",
    "    for dir_name, all_data in dir_to_data.items():\n",
    "        feature_to_value = get_all_features_by_marker(\n",
    "            all_data, marker, features, channel_num\n",
    "        )\n",
    "\n",
    "        dir_name_to_features[dir_name] = feature_to_value\n",
    "\n",
    "    features_to_trials = defaultdict()\n",
    "    all_data = dir_to_data[\"../2000_CleanData\"]\n",
    "    channel_name = all_data[\"audio_hvla\"].get_chanlocs(marker)[channel_num]\n",
    "\n",
    "    for dir_name, fv in dir_name_to_features.items():\n",
    "        for f, v in fv.items():\n",
    "            key = f'{channel_name}_{f.name}'\n",
    "            if key not in features_to_trials:\n",
    "                features_to_trials[key] = []\n",
    "\n",
    "            features_to_trials[key].append(v)\n",
    "\n",
    "    return features_to_trials\n",
    "\n",
    "features = STAT_FEATURES\n",
    "\n",
    "\"\"\" extract features from physiological signals\n",
    "\"\"\"\n",
    "feature_names = []\n",
    "f_array = np.array([])\n",
    "for m in [EOG.__name__, EMG.__name__]:\n",
    "    features_to_trials = _extract_features_by_channel(m, dir_to_data, features, 0)\n",
    "    f_names = features_to_trials.keys()\n",
    "    for f in f_names:\n",
    "        f_array = (\n",
    "            np.array(features_to_trials[f])\n",
    "            if f_array.ndim == 1\n",
    "            else np.concatenate((f_array, np.array(features_to_trials[f])), axis=-1)\n",
    "        )\n",
    "    feature_names.extend(f_names)\n",
    "\n",
    "f_array = np.swapaxes(f_array, 0, -1)    \n",
    "print(f_array.shape)\n",
    "dir_name_to_labels = extract_labels(dir_to_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c4d6a55",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_friedman1\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "X, y = make_friedman1(n_samples=1200, random_state=0, noise=1.0)\n",
    "print(X.shape, y.shape)\n",
    "X_train, X_test = X[:2], X[2:]\n",
    "y_train, y_test = y[:2], y[2:]\n",
    "\n",
    "est = GradientBoostingRegressor(\n",
    "    n_estimators=100, learning_rate=0.1, max_depth=1, random_state=0,loss='ls').fit(X_train, y_train)\n",
    "mean_squared_error(y_test, est.predict(X_test))\n",
    "est.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a1aa205",
   "metadata": {},
   "outputs": [],
   "source": [
    "def binary_label(all_labels, threshold=0.5):\n",
    "    y_transformed = []\n",
    "    c0, c1 = 0, 0\n",
    "    for label in all_labels:\n",
    "        if label < threshold:\n",
    "            y_transformed.append(0)\n",
    "            c0 += 1\n",
    "        else:\n",
    "            y_transformed.append(1)\n",
    "            c1 += 1\n",
    "\n",
    "    print(f\"0 label: {c0}, 1 label: {c1}\")\n",
    "    return y_transformed\n",
    "\n",
    "\n",
    "def get_tranformed_labels(condition_to_labels: dict):\n",
    "    transformed = dict()\n",
    "    for condition, label in condition_to_labels.items():\n",
    "        transformed[condition] = binary_label(label)\n",
    "    return transformed\n",
    "\n",
    "def get_categorical_labels(condition_to_labels: dict, threshold=0.5):\n",
    "    valence_labels = condition_to_labels['valence']\n",
    "    arousal_labels = condition_to_labels['arousal']\n",
    "    claz = []\n",
    "    for i, v_label in enumerate(valence_labels):\n",
    "       if arousal_labels[i] <= threshold and v_label <= threshold: # nvla\n",
    "         claz.append(0)\n",
    "       elif arousal_labels[i] > threshold and v_label <= threshold: # nvha\n",
    "         claz.append(1)\n",
    "       elif arousal_labels[i] <= threshold and v_label > threshold: # hvla\n",
    "         claz.append(2)\n",
    "       else: # hvha\n",
    "         claz.append(3)            \n",
    "        \n",
    "    return claz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aa0ab41",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import utils as np_utils\n",
    "\n",
    "data_list = []\n",
    "for m in [EEG.__name__,EGG.__name__,EOG.__name__, EMG.__name__]\n",
    "    all_participants_data, condition_to_labels = concatenate_all_data(dir_to_data, m)\n",
    "    all_epoch_data = np.swapaxes(\n",
    "    all_participants_data, 0, -1\n",
    "    )  # (num_channels, num_data_points, num_epochs) => (num_epochs, num_data_points, num_channels)\n",
    "\n",
    "    data_list.append(all_epoch_data)\n",
    "\n",
    "data_array = np.concatenate(data_list, axis=2)\n",
    " \n",
    "# (TODO) combine attention + arousal to 2*2*2 = 8 classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "412befc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Conv1D,BatchNormalization,LeakyReLU,MaxPool1D,\\\n",
    "GlobalAveragePooling1D,Dense,Dropout,AveragePooling1D\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.backend import clear_session\n",
    "\n",
    "def cnn_model():\n",
    "    clear_session()\n",
    "    model = Sequential([\n",
    "        Conv1D(filters=5,kernel_size=3,strides=1,input_shape=(12288, 128)),\n",
    "        BatchNormalization(),\n",
    "        LeakyReLU(),\n",
    "        MaxPool1D(pool_size=2,strides=2),\n",
    "        Conv1D(filters=5,kernel_size=3,strides=1),\n",
    "        LeakyReLU(),\n",
    "        MaxPool1D(pool_size=2,strides=2),\n",
    "        Dropout(0.5),\n",
    "        Conv1D(filters=5,kernel_size=3,strides=1),\n",
    "        LeakyReLU(),\n",
    "        AveragePooling1D(pool_size=2,strides=2),\n",
    "        Dropout(0.5),\n",
    "        Conv1D(filters=5,kernel_size=3,strides=1),\n",
    "        LeakyReLU(),\n",
    "        AveragePooling1D(pool_size=2,strides=2),\n",
    "        Conv1D(filters=5,kernel_size=3,strides=1),\n",
    "        LeakyReLU(),     \n",
    "        GlobalAveragePooling1D(),\n",
    "        Dense(4,activation='sigmoid')\n",
    "    ])\n",
    "    \n",
    "    model.compile('adam',loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "model=cnn_model()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "782e4879",
   "metadata": {},
   "outputs": [],
   "source": [
    "# to one-hot encoding vector\n",
    "label_list = get_categorical_labels(condition_to_labels)\n",
    "groups_list = [[i] for i, j in enumerate(label_list)]\n",
    "group_array = np.hstack(groups_list)\n",
    "print(label_list)\n",
    "label_array = np_utils.to_categorical(label_list, num_classes=4)\n",
    "#label_array = np.array(label_list['arousal'])\n",
    "\n",
    "print(label_array)\n",
    "print(data_array.shape, label_array.shape, group_array.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f925ce7",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy=[]\n",
    "gkf=GroupKFold()\n",
    "for train_index, val_index in gkf.split(data_array, label_array, groups=group_array):\n",
    "    train_features, train_labels=data_array[train_index], label_array[train_index]\n",
    "    val_features, val_labels=data_array[val_index], label_array[val_index]\n",
    "    \n",
    "    scaler=StandardScaler()\n",
    "    train_features = scaler.fit_transform(train_features.reshape(-1, train_features.shape[-1])).reshape(train_features.shape)\n",
    "    val_features = scaler.transform(val_features.reshape(-1, val_features.shape[-1])).reshape(val_features.shape)\n",
    "    model=cnn_model()\n",
    "    model.fit(train_features, train_labels, epochs=13, batch_size=50,validation_data=(val_features,val_labels))\n",
    "    accuracy.append(model.evaluate(val_features, val_labels)[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2152ef4",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = STAT_FEATURES\n",
    "marker = ECG.__name__\n",
    "\n",
    "\"\"\" extract features from physiological signals\n",
    "\"\"\"\n",
    "dir_name_to_features = extract_features_by_channel(marker, dir_to_data, features, 0)\n",
    "dir_name_to_labels = extract_labels(dir_to_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad4ebf5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" extract correlation from physiological signals\n",
    "\"\"\"\n",
    "num_channels = 4\n",
    "num_blocks = 0\n",
    "dir_name_to_ctf = {}\n",
    "for dir_name, all_data in dir_to_data.items():\n",
    "    dir_name_to_ctf[dir_name] = get_all_behaviors_feature_to_pc_by_markers(\n",
    "        all_data, marker, features, num_channels, num_blocks\n",
    "    )\n",
    "    \n",
    "avg_condition_to_features = get_all_trials_average_rp_values(\n",
    "    dir_name_to_ctf, features, \"pearson\"\n",
    ")\n",
    "spearman_corr = get_all_trials_average_rp_values(dir_name_to_ctf, features, \"spearman\")\n",
    "for b, feature_to_pc in avg_condition_to_features.items():\n",
    "    for f, pc in feature_to_pc.items():\n",
    "        avg_condition_to_features[b][f] = np.hstack((pc, spearman_corr[b][f]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cad5c2ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data = dir_to_data[\"../2000_CleanData\"]\n",
    "channel_names = all_data[\"audio_hvla\"].get_chanlocs(marker)\n",
    "\n",
    "\"\"\" plot the time series given the marker and block\n",
    "\"\"\"\n",
    "# plot_time_series_by_epoch(all_data['audio_hvla'], 'EMG', 'audio_hvla', 0)\n",
    "\n",
    "\n",
    "\"\"\" plot the single channel correlation table\n",
    "\"\"\"\n",
    "# channel = 3\n",
    "# for condition, feature_to_pc in avg_condition_to_features.items():\n",
    "#     label = f\"{channel_names[channel]} {condition}\"\n",
    "#     plot_correlation_table_by_channel(\n",
    "#         label, feature_to_pc, [\"pearson r\", \"pearson p\", \"spearman r\", \"spearman p\"], features, channel, True\n",
    "#     )\n",
    "\n",
    "\"\"\" plot the top channel correlation table given r values\n",
    "\"\"\"\n",
    "# for condition, feature_to_pc in avg_condition_to_features.items():\n",
    "#     plot_k_chaneels_by_r_value(feature_to_pc, channel_names, features, condition, True, 2)\n",
    "#     plot_k_chaneels_by_r_value(feature_to_pc, channel_names, features, condition, False, 2)\n",
    "\n",
    "\n",
    "\"\"\" plot the top channel correlation table with different blocks\n",
    "\"\"\"\n",
    "# all_block_names = list(all_data.keys())\n",
    "# all_block_names.sort()\n",
    "# for condition, feature_to_pc in avg_condition_to_features.items():\n",
    "#     plot_eeg_pearson_correlation_table(condition, feature_to_pc, all_block_names, 1)\n",
    "\n",
    "\"\"\" plot the series for the top k channels\n",
    "\"\"\"\n",
    "# define number of rows and columns for subplots\n",
    "# nrow = 3\n",
    "# ncol = 2\n",
    "# for condition, feature_to_pc in avg_condition_to_features.items():\n",
    "#     print(f\"{condition}\")\n",
    "#     ser_list = get_eeg_pearson_correlation_series_all_blocks(feature_to_pc, channel_names, k=20)\n",
    "#     plot_series(nrow, ncol, ser_list)\n",
    "\n",
    "\"\"\" plot the topography for eeg\n",
    "\"\"\"\n",
    "# for condition, feature_to_pc in avg_condition_to_features.items():\n",
    "#     plot_eeg_topomap_all_blocks(condition, feature_to_pc)\n",
    "#     for f in list(EEG_BANDS.keys()):\n",
    "#         plot_eeg_topomap_one_block(condition, f, feature_to_pc, all_block_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "010d750e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" extract features from physiological signals\n",
    "\"\"\"\n",
    "dir_name_to_features = {}\n",
    "dir_name_to_labels = {}\n",
    "channel_num = 1\n",
    "for dir_name, all_data in dir_to_data.items():\n",
    "    feature_to_value = get_all_features_by_marker(\n",
    "        all_data, marker, features, channel_num\n",
    "    )\n",
    "\n",
    "    dir_name_to_features[dir_name] = feature_to_value\n",
    "    dir_name_to_labels[dir_name] = get_all_behaviors_labels(all_data)\n",
    "\n",
    "features_to_trials = defaultdict()\n",
    "for dir_name, fv in dir_name_to_features.items():\n",
    "    for f, v in fv.items():\n",
    "        if f not in features_to_trials:\n",
    "            features_to_trials[f] = defaultdict()\n",
    "        if dir_name not in features_to_trials[f]:\n",
    "            features_to_trials[f][dir_name] = defaultdict()\n",
    "\n",
    "        features_to_trials[f][dir_name] = v\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1cfc36b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" plot the scattor for physiological signals\n",
    "\"\"\"\n",
    "# plot_scatter_by_marker(marker, features_to_trials, dir_name_to_labels, channel_names[channel_num])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51c04220",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert y values to categorical values\n",
    "name_to_transformed = get_tranformed_labels(condition_to_labels)\n",
    "\n",
    "label_name = \"attention\"\n",
    "clf = LogisticRegression(max_iter=200)\n",
    "gkf = GroupKFold(n_splits=5)\n",
    "param_grid = {\"classifier__C\": [1e-5, 1e-4, 1e-3, 1e-2, 1e-1, 1, 10, 100]}\n",
    "pipe = Pipeline([(\"scaler\", StandardScaler()), (\"classifier\", clf)])\n",
    "gscv = GridSearchCV(pipe, param_grid, cv=gkf, n_jobs=16)\n",
    "gscv.fit(all_features,  name_to_transformed[label_name], groups=group_array)\n",
    "\n",
    "best_model = gscv.best_estimator_\n",
    "print(f\"best model: {best_model}\")\n",
    "print(gscv.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a90a695b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# BP feature shape (13, 11)\n",
    "# ECG feature shape (13, 11) 22\n",
    "# EEG feature shape (13, 1408) 1430\n",
    "# EGG feature shape (13, 11) 1441\n",
    "# EMG feature shape (13, 22) 1463\n",
    "# EOG feature shape (13, 22) 1485\n",
    "# GSR feature shape (13, 11) 1496\n",
    "# Resp feature shape (13, 11) 1507\n",
    "# TREV feature shape (13, 11) 1518\n",
    "# features = (mean(data),std(data),ptp(data),var(data),minim(data),maxim(data),\n",
    "#                           mean_square(data),rms(data),abs_diffs_signal(data),\n",
    "#                           skewness(data),kurtosis(data))\n",
    "# EEG spetral features shape (13, 768) 2286-768=\n",
    "\n",
    "\n",
    "def get_stats_name(i) -> str:\n",
    "    pos = i % 11\n",
    "    return STAT_FEATURES[pos]\n",
    "\n",
    "\n",
    "def get_feature_names(features):\n",
    "    index = []\n",
    "    for i, j in enumerate(features):\n",
    "        stat_name = get_stats_name(i)\n",
    "        if i < 11:\n",
    "            name = \"BP\"\n",
    "        elif i < 22:\n",
    "            name = \"ECG\"\n",
    "        elif i < 1430:\n",
    "            channel = int((i - 22) / 11) + 1\n",
    "            name = f\"EEG {channel}\"\n",
    "        elif i < 1441:\n",
    "            name = \"EGG\"\n",
    "        elif i < 1463:\n",
    "            channel = int((i - 1441) / 11) + 1\n",
    "            name = f\"EMG {channel}\"\n",
    "        elif i < 1485:\n",
    "            channel = int((i - 1463) / 11) + 1\n",
    "            name = f\"EOG {channel}\"\n",
    "        elif i < 1496:\n",
    "            name = \"GSR\"\n",
    "        elif i < 1507:\n",
    "            name = \"Resp\"\n",
    "        elif i < 1518:\n",
    "            name = \"TREV\"\n",
    "        else:\n",
    "            channel = int((i - 1518) / 6) + 1\n",
    "            name = f\"EEG {channel}\"\n",
    "            stat_name = EEG_BANDS[(i - 1518) % 6]\n",
    "\n",
    "        index.append(f\"{name} {stat_name}\")\n",
    "    return index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dcadd95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# assume bigger coefficents has more contribution to the model\n",
    "# but have to be sure that the features has THE SAME SCALE otherwise this assumption is not correct.\n",
    "importance = best_model[\"classifier\"].coef_[0]\n",
    "\n",
    "feat_importances = pd.Series(importance, index=get_feature_names(importance))\n",
    "feat_importances.nlargest(10).plot(\n",
    "    kind=\"barh\", title=f\"{label_name} Feature Importance\"\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "a61a162a2d9e3da5a6990904193197d11ef3e5d95aabe700de904d0b7a2b7b7b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
