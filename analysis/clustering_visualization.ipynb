{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "478b42e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from dataframe.csv_utils import (\n",
    "    load_data_from_csv,\n",
    "    get_filtered_data,\n",
    ")\n",
    "\n",
    "# sklearn imports\n",
    "from sklearn.decomposition import PCA  # Principal Component Analysis\n",
    "from sklearn.manifold import TSNE  # T-Distributed Stochastic Neighbor Embedding\n",
    "\n",
    "# plotly imports\n",
    "import plotly.graph_objs as go\n",
    "from plotly.offline import init_notebook_mode\n",
    "\n",
    "SORTED_BLOCK_NAMES = [\n",
    "    \"a_hvha\",\n",
    "    \"a_hvla\",\n",
    "    \"a_nvha\",\n",
    "    \"a_nvla\",\n",
    "    \"b_hvha\",\n",
    "    \"b_hvla\",\n",
    "    \"b_nvha\",\n",
    "    \"b_nvla\",\n",
    "    \"medi\",\n",
    "    \"wandering\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac22c46f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    load features from csv\n",
    "\"\"\"\n",
    "dir_name = \"eeg_features2\"\n",
    "result = load_data_from_csv(dir_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51c8a6ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is needed so we can display plotly plots properly\n",
    "init_notebook_mode(connected=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "003b204a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from umap import UMAP\n",
    "\n",
    "import plotly.express as px\n",
    "from plotly.offline import plot\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "\n",
    "def get_filter_pattern(feature: str = \"ALL\", channel: str = '') -> str:\n",
    "    prefix = ''\n",
    "    if len(channel) > 0:\n",
    "        prefix = f'^{channel}'\n",
    "\n",
    "    # get_other feature_pattern = \".*(?<!GAMMA|BETA2|BETA1|ALPHA|THETA|DELTA)$\"\n",
    "    if feature == \"ALL\":\n",
    "        return f\"{prefix}.*(?<!sdf)$\"\n",
    "    \n",
    "    return f\"{prefix}.*{feature}$\"  # f\"^{feature}.*(?<!BETA2)$\"\n",
    "\n",
    "def get_processed_feature(feature: str, channel: str, result: pd.DataFrame, subjects: list=[]):\n",
    "    pattern = get_filter_pattern(feature, channel)\n",
    "    normalized_eeg_features, filtered_result, label_list = get_filtered_data(\n",
    "        result, subjects, pattern\n",
    "    )\n",
    "    print('filtered', normalized_eeg_features.shape)\n",
    "    return normalized_eeg_features, filtered_result\n",
    "\n",
    "def get_umap(feature: str, channel: str, result: pd.DataFrame, all_blocks: list, subjects: list = []):\n",
    "    pattern = get_filter_pattern(feature, channel)\n",
    "    normalized_eeg_features, filtered_result, label_list = get_filtered_data(\n",
    "        result, subjects, pattern\n",
    "    )\n",
    "    print(normalized_eeg_features.shape)\n",
    "\n",
    "    # Run UMAP\n",
    "    umap2d = UMAP(n_components=2, init=\"random\", random_state=0)\n",
    "    proj_2d = pd.DataFrame(umap2d.fit_transform(normalized_eeg_features))\n",
    "\n",
    "    # Concatanate the umap points and original data\n",
    "    filtered_result = filtered_result.reset_index()\n",
    "    filtered_result[\"condition\"] = all_blocks * len(subjects)\n",
    "    proj_2d.columns = [\"C1_2d\", \"C2_2d\"]\n",
    "    return pd.concat([filtered_result, proj_2d], axis=1, join=\"inner\")\n",
    "\n",
    "def get_pca(feature: str, channel: str, result: pd.DataFrame, subjects: list=[]):\n",
    "    normalized_eeg_features, filtered_result = get_processed_feature(feature, channel, result, subjects)\n",
    "\n",
    "    # Run PCA\n",
    "    pca = PCA(n_components=2)\n",
    "    proj_2d = pd.DataFrame(pca.fit_transform(normalized_eeg_features))\n",
    "\n",
    "    # Concatanate the umap points and original data\n",
    "    filtered_result = filtered_result.reset_index()\n",
    "    proj_2d.columns = [\"C1_2d\", \"C2_2d\"]\n",
    "    return pd.concat([filtered_result['Subject'], proj_2d], axis=1, join=\"inner\")\n",
    "\n",
    "def show_result(feature: str, subjects: list, plotX: pd.DataFrame, conditions: list, to_save: bool=False):\n",
    "    title = f\"EEG {feature} (average spectral power per trial)\"\n",
    "\n",
    "    figures = []\n",
    "    for subj in subjects:\n",
    "        df = plotX[plotX[\"Subject\"] == subj]\n",
    "        figures.append(px.scatter(df, x=\"C1_2d\", y=\"C2_2d\", color=conditions, opacity=0.5))\n",
    "\n",
    "    fig = make_subplots(\n",
    "        rows=int((len(figures) / 2) + (len(figures) % 2)),\n",
    "        cols=2,\n",
    "        subplot_titles=subjects,\n",
    "        horizontal_spacing=0.1,\n",
    "        vertical_spacing=0.05,\n",
    "    )\n",
    "\n",
    "    for i, figure in enumerate(figures):\n",
    "        showlegend = True if i == 0 else False\n",
    "        for trace in range(len(figure[\"data\"])):\n",
    "            figure[\"data\"][trace].update(showlegend=showlegend)\n",
    "            fig.append_trace(\n",
    "                figure[\"data\"][trace], row=int(i / 2 + 1), col=int(i % 2 + 1)\n",
    "            )\n",
    "\n",
    "    fig.update_layout(\n",
    "        height=1000, width=1000, title_text=title, margin=dict(r=0, b=0, l=0)\n",
    "    )\n",
    "\n",
    "    name = \",\".join(str(s) for s in subjects)\n",
    "    filename = f\"results/valence/{feature}_{name}.png\"\n",
    "    if to_save:\n",
    "        fig.write_image(filename)\n",
    "\n",
    "    fig.show()\n",
    "    \n",
    "def show_pca_matrix(\n",
    "    band: str, \n",
    "    channel: str, \n",
    "    subject: int, \n",
    "    result: pd.DataFrame, \n",
    "    all_blocks: list, \n",
    "    n_components: int,\n",
    "    to_save: bool=False,\n",
    "):\n",
    "    normalized_eeg_features, _ = get_processed_feature(band, channel, result, [subject])\n",
    "    pca = PCA(n_components=n_components)\n",
    "    proj_2d = pd.DataFrame(pca.fit_transform(normalized_eeg_features))\n",
    "    labels = {\n",
    "        str(i): f\"PC {i+1} ({var:.1f}%)\"\n",
    "        for i, var in enumerate(pca.explained_variance_ratio_ * 100)\n",
    "    }\n",
    "\n",
    "    identifier = str(subject) + f'_{band}_{channel}_channel'\n",
    "    total_var = pca.explained_variance_ratio_.sum() * 100\n",
    "    fig = px.scatter_matrix(\n",
    "        proj_2d,\n",
    "        labels=labels,\n",
    "        dimensions=range(len(labels)),\n",
    "        color=all_blocks,\n",
    "        opacity=0.5,\n",
    "        title=f'{identifier} Total Explained Variance: {total_var:.2f}%',\n",
    "    )\n",
    "    fig.update_traces(diagonal_visible=False)\n",
    "    fig.update_layout(\n",
    "        height=1000, width=1000, margin=dict(r=0, b=0, l=0)\n",
    "    )\n",
    "\n",
    "    filename = f\"results/{identifier}_PCA_breakdown.png\"\n",
    "    if to_save:\n",
    "        fig.write_image(filename)\n",
    "        \n",
    "    fig.show()\n",
    "\n",
    "#     target = 4\n",
    "#     proj_2d = pd.concat([proj_2d[0], proj_2d[target]], axis=1, join=\"inner\")\n",
    "#     proj_2d.columns = [0, 1]\n",
    "\n",
    "#     target_str = str(target)\n",
    "#     labels = { '0': labels['0'], target_str: labels[target_str]}\n",
    "#     fig = px.scatter_matrix(\n",
    "#         proj_2d,\n",
    "#         labels=labels,\n",
    "#         dimensions=range(len(labels)),\n",
    "#         color=all_blocks * len(subjects),\n",
    "#         opacity=0.5,\n",
    "#         title=f'Total Explained Variance: {total_var:.2f}%',\n",
    "#     )\n",
    "#     fig.update_traces(diagonal_visible=False)\n",
    "#     fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e911ac8",
   "metadata": {},
   "outputs": [],
   "source": [
    "FOUR_CONDITIONS = [\"audio\"] * 4 + [\"breath\"] * 4 + [\"meditation\", \"wandering\"]\n",
    "VALENCE_CONDITIONS = (\n",
    "    [\"h_valence\"] * 2\n",
    "    + [\"n_valence\"] * 2\n",
    "    + [\"h_valence\"] * 2\n",
    "    + [\"n_valence\"] * 2\n",
    "    + [\"meditation\", \"wandering\"]\n",
    ")\n",
    "\n",
    "AROUSAL_CONDITIONS = (\n",
    "    [\"h_arousal\", \"l_arousal\"] * 4\n",
    "    + [\"meditation\", \"wandering\"]\n",
    ")\n",
    "\n",
    "name_to_batch = {\n",
    "    \"f\": [2017, 2018, 2020, 2024, 2025, 2026],\n",
    "    \"s\": [2028, 2029, 2031, 2032, 2033, 2035],\n",
    "    \"t\": [2036, 2039, 2040, 2041, 2042, 2043, 2044, 2045],\n",
    "}\n",
    "\n",
    "subjects = name_to_batch['s']\n",
    "all_blocks = []\n",
    "for b in FOUR_CONDITIONS:\n",
    "    all_blocks.extend([b] * 13)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa7ed303",
   "metadata": {},
   "outputs": [],
   "source": [
    " # https://plotly.com/python/pca-visualization/\n",
    "# ['A', 'B', 'C', 'D']\n",
    "for band in ['ALL', 'DELTA', 'THETA', 'ALPHA', 'BETA1', 'BETA2', 'GAMMA']:\n",
    "    for ch in ['A', 'B', 'C', 'D']: \n",
    "        plotX = get_pca(band, ch ,result, subjects)\n",
    "        feature = f'valence_{band}_{ch}_channel_PCA'\n",
    "        show_result(feature, subjects, plotX, all_blocks, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "801ca2c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_components=6\n",
    "for s in subjects:\n",
    "    show_pca_matrix('THETA', 'C', s, result, all_blocks, n_components, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cf95317",
   "metadata": {},
   "outputs": [],
   "source": [
    "for f in ['ALL', 'DELTA', 'THETA', 'ALPHA', 'BETA1', 'BETA2', 'GAMMA']:\n",
    "    plotX = get_umap(f, result, all_blocks, subjects)\n",
    "    feature = f'{f}_UMAP'\n",
    "    show_result(feature, subjects, plotX, condition)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c72944ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reference https://www.mikulskibartosz.name/pca-how-to-choose-the-number-of-components/\n",
    "reduced_data = PCA(n_components=0.95).fit_transform(normalized_eeg_features)\n",
    "normalized_eeg_features = pd.DataFrame(reduced_data)\n",
    "normalized_eeg_features.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bc646a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.mixture import GaussianMixture\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# gmm = GaussianMixture(n_components=2).fit(normalized_eeg_features)\n",
    "# clusters = gmm.predict(normalized_eeg_features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbe1e793",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import AgglomerativeClustering\n",
    "import time\n",
    "\n",
    "print(\"Compute unstructured hierarchical clustering...\")\n",
    "st = time.time()\n",
    "ward = AgglomerativeClustering(n_clusters=4, linkage=\"ward\").fit(\n",
    "    normalized_eeg_features\n",
    ")\n",
    "elapsed_time = time.time() - st\n",
    "clusters = ward.labels_\n",
    "print(f\"Elapsed time: {elapsed_time:.2f}s\")\n",
    "print(f\"Number of points: {clusters.size}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce78a16a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataframe.visualization import pca_2d\n",
    "\n",
    "# Add the cluster vector to our DataFrame, X\n",
    "normalized_eeg_features[\"Cluster\"] = clusters\n",
    "# normalized_eeg_features['Block'] = all_blocks\n",
    "\n",
    "pca_2d(\n",
    "    normalized_eeg_features,\n",
    "    4,\n",
    "    [\n",
    "        \"rgba(255, 128, 255, 0.8)\",\n",
    "        \"rgba(255, 128, 2, 0.8)\",\n",
    "        \"rgba(0, 255, 200, 0.8)\",\n",
    "        \"rgba(0, 128, 200, 0.8)\",\n",
    "    ],\n",
    "    title,\n",
    "    False,\n",
    "    mode=\"markers\",\n",
    "    textfont=dict(size=10),\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "617386cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clustering\n",
    "# kmeans = KMeans(init=\"k-means++\", n_clusters=4, n_init=2)\n",
    "# kmeans.fit(normalized_eeg_features)\n",
    "# #Find which cluster each data-point belongs to\n",
    "# clusters = kmeans.predict(normalized_eeg_features)\n",
    "\n",
    "\n",
    "# from sklearn.cluster import DBSCAN\n",
    "# from sklearn import metrics\n",
    "\n",
    "# db = DBSCAN(eps=7, min_samples=10).fit(normalized_eeg_features)\n",
    "# clusters = db.labels_\n",
    "\n",
    "# # Number of clusters in labels, ignoring noise if present.\n",
    "# n_clusters_ = len(set(clusters)) - (1 if -1 in clusters else 0)\n",
    "# n_noise_ = list(clusters).count(-1)\n",
    "\n",
    "# print(\"Estimated number of clusters: %d\" % n_clusters_)\n",
    "# print(\"Estimated number of noise points: %d\" % n_noise_)\n",
    "# clusters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89d9945c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualization via t-SNE\n",
    "# Set our perplexity\n",
    "perplexity = 50\n",
    "# T-SNE with one dimension\n",
    "tsne_1d = TSNE(n_components=1, perplexity=perplexity)\n",
    "\n",
    "# T-SNE with two dimensions\n",
    "tsne_2d = TSNE(n_components=2, perplexity=perplexity)\n",
    "\n",
    "# T-SNE with three dimensions\n",
    "tsne_3d = TSNE(n_components=3, perplexity=perplexity)\n",
    "# This DataFrame holds a single dimension,built by T-SNE\n",
    "s_1d = pd.DataFrame(\n",
    "    tsne_1d.fit_transform(normalized_eeg_features.drop([\"Cluster\"], axis=1))\n",
    ")\n",
    "\n",
    "# This DataFrame contains two dimensions, built by T-SNE\n",
    "s_2d = pd.DataFrame(\n",
    "    tsne_2d.fit_transform(normalized_eeg_features.drop([\"Cluster\"], axis=1))\n",
    ")\n",
    "\n",
    "# And this DataFrame contains three dimensions, built by T-SNE\n",
    "s_3d = pd.DataFrame(\n",
    "    tsne_3d.fit_transform(normalized_eeg_features.drop([\"Cluster\"], axis=1))\n",
    ")\n",
    "\n",
    "s_1d.columns = [\"TC1_1d\"]\n",
    "\n",
    "# \"TC1_2d\" means: 'The first component of the components created for 2-D visualization, by T-SNE.'\n",
    "# And \"TC2_2d\" means: 'The second component of the components created for 2-D visualization, by T-SNE.'\n",
    "s_2d.columns = [\"TC1_2d\", \"TC2_2d\"]\n",
    "\n",
    "s_3d.columns = [\"TC1_3d\", \"TC2_3d\", \"TC3_3d\"]\n",
    "method = \"t-SNE\"\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MM",
   "language": "python",
   "name": "mm"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
