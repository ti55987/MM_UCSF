{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "478b42e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from dataframe.csv_utils import (\n",
    "    load_data_from_csv,\n",
    "    get_filtered_data,\n",
    ")\n",
    "from constants import SORTED_BLOCK_NAMES, AUDIO_BLOCKS, COLOR_MAP, V_COLOR_MAP\n",
    "\n",
    "# sklearn imports\n",
    "from sklearn.decomposition import PCA  # Principal Component Analysis\n",
    "\n",
    "# plotly imports\n",
    "import plotly.graph_objs as go\n",
    "from plotly.offline import init_notebook_mode\n",
    "\n",
    "\n",
    "FOUR_CONDITIONS = [\"audio\"] * 4 + [\"breath\"] * 4 + [\"meditation\", \"wandering\"]\n",
    "VALENCE_CONDITIONS = (\n",
    "    [\"h_valence\"] * 2\n",
    "    + [\"n_valence\"] * 2\n",
    "    + [\"h_valence\"] * 2\n",
    "    + [\"n_valence\"] * 2\n",
    "    + [\"meditation\", \"wandering\"]\n",
    ")\n",
    "\n",
    "AROUSAL_CONDITIONS = [\"h_arousal\", \"l_arousal\"] * 4 + [\"meditation\", \"wandering\"]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ee9ab8c0",
   "metadata": {},
   "source": [
    "### Load features from CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac22c46f",
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_name = \"eeg_features2\"\n",
    "result = load_data_from_csv(dir_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51c8a6ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is needed so we can display plotly plots properly\n",
    "init_notebook_mode(connected=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "55cda0f0",
   "metadata": {},
   "source": [
    "\n",
    "### Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa4e29d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from umap import UMAP\n",
    "\n",
    "import plotly.express as px\n",
    "from plotly.offline import plot\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "from sklearn.metrics.cluster import rand_score\n",
    "from collections import defaultdict\n",
    "\n",
    "def get_filter_pattern(feature: str = \"ALL\", channel: str = \"\") -> str:\n",
    "    prefix = \"\"\n",
    "    if len(channel) > 0:\n",
    "        prefix = f\"^{channel}\"\n",
    "\n",
    "    # get_other feature_pattern = \".*(?<!GAMMA|BETA2|BETA1|ALPHA|THETA|DELTA)$\"\n",
    "    if feature == \"ALL\":\n",
    "        return f\"{prefix}.*(?<!sdf)$\"\n",
    "\n",
    "    return f\"{prefix}.*{feature}$\"  # f\"^{feature}.*(?<!BETA2)$\"\n",
    "\n",
    "\n",
    "def get_processed_feature(\n",
    "    feature: str, channel: str, result: pd.DataFrame, subjects: list = []\n",
    "):\n",
    "    pattern = get_filter_pattern(feature, channel)\n",
    "    normalized_eeg_features, filtered_result, label_list = get_filtered_data(\n",
    "        result, subjects, pattern\n",
    "    )\n",
    "    #print(\"filtered\", normalized_eeg_features.shape)\n",
    "    return normalized_eeg_features, filtered_result\n",
    "\n",
    "\n",
    "def get_umap(\n",
    "    feature: str,\n",
    "    channel: str,\n",
    "    result: pd.DataFrame,\n",
    "    all_blocks: list,\n",
    "    subjects: list = [],\n",
    "):\n",
    "    pattern = get_filter_pattern(feature, channel)\n",
    "    normalized_eeg_features, filtered_result, label_list = get_filtered_data(\n",
    "        result, subjects, pattern\n",
    "    )\n",
    "    print(normalized_eeg_features.shape)\n",
    "\n",
    "    # Run UMAP\n",
    "    umap2d = UMAP(n_components=2, init=\"random\", random_state=0)\n",
    "    proj_2d = pd.DataFrame(umap2d.fit_transform(normalized_eeg_features))\n",
    "\n",
    "    # Concatanate the umap points and original data\n",
    "    filtered_result = filtered_result.reset_index()\n",
    "    filtered_result[\"condition\"] = all_blocks * len(subjects)\n",
    "    proj_2d.columns = [\"C1_2d\", \"C2_2d\"]\n",
    "    return pd.concat([filtered_result, proj_2d], axis=1, join=\"inner\")\n",
    "\n",
    "\n",
    "def get_pca(feature: str, channel: str, result: pd.DataFrame, subjects: list = []):\n",
    "    normalized_eeg_features, filtered_result = get_processed_feature(\n",
    "        feature, channel, result, subjects\n",
    "    )\n",
    "\n",
    "    # Run PCA\n",
    "    pca = PCA(n_components=2)\n",
    "    proj_2d = pd.DataFrame(pca.fit_transform(normalized_eeg_features))\n",
    "\n",
    "    # Concatanate the umap points and original data\n",
    "    filtered_result = filtered_result.reset_index()\n",
    "    proj_2d.columns = [\"C1_2d\", \"C2_2d\"]\n",
    "    return pd.concat([filtered_result[\"Subject\"], proj_2d], axis=1, join=\"inner\")\n",
    "\n",
    "\n",
    "def show_result(\n",
    "    feature: str,\n",
    "    subjects: list,\n",
    "    plotX: pd.DataFrame,\n",
    "    conditions: list,\n",
    "    to_save: bool = False,\n",
    "):\n",
    "    title = f\"EEG {feature} (average spectral power per trial)\"\n",
    "\n",
    "    figures = []\n",
    "    for subj in subjects:\n",
    "        df = plotX[plotX[\"Subject\"] == subj]\n",
    "        figures.append(\n",
    "            px.scatter(\n",
    "                df,\n",
    "                x=\"C1_2d\",\n",
    "                y=\"C2_2d\",\n",
    "                color=df[\"condition\"],\n",
    "                color_discrete_map=V_COLOR_MAP,\n",
    "                opacity=0.6,\n",
    "            )\n",
    "        )\n",
    "\n",
    "    fig = make_subplots(\n",
    "        rows=int((len(figures) / 2) + (len(figures) % 2)),\n",
    "        cols=2,\n",
    "        subplot_titles=subjects,\n",
    "        horizontal_spacing=0.1,\n",
    "        vertical_spacing=0.05,\n",
    "    )\n",
    "\n",
    "    for i, figure in enumerate(figures):\n",
    "        for trace in range(len(figure[\"data\"])):\n",
    "            figure[\"data\"][trace].update()\n",
    "            fig.append_trace(\n",
    "                figure[\"data\"][trace], row=int(i / 2 + 1), col=int(i % 2 + 1)\n",
    "            )\n",
    "\n",
    "    # Deduplicate the legends\n",
    "    names = set()\n",
    "    fig.for_each_trace(\n",
    "        lambda trace: trace.update(showlegend=False)\n",
    "        if (trace.name in names)\n",
    "        else names.add(trace.name)\n",
    "    )\n",
    "\n",
    "    fig.update_layout(\n",
    "        height=1000, width=1000, title_text=title, margin=dict(r=0, b=0, l=0)\n",
    "    )\n",
    "\n",
    "    name = \",\".join(str(s) for s in subjects)\n",
    "    filename = f\"results/{feature}_{name}.png\"\n",
    "    if to_save:\n",
    "        fig.write_image(filename)\n",
    "\n",
    "    fig.show()\n",
    "\n",
    "\n",
    "def show_pca_matrix(\n",
    "    band: str,\n",
    "    channel: str,\n",
    "    subject: int,\n",
    "    result: pd.DataFrame,\n",
    "    all_blocks: list,\n",
    "    n_components: int,\n",
    "    to_save: bool = False,\n",
    "    is_user_rating: bool = False,\n",
    "):\n",
    "    normalized_eeg_features, _ = get_processed_feature(band, channel, result, [subject])\n",
    "    pca = PCA(n_components=n_components)\n",
    "    proj_2d = pd.DataFrame(pca.fit_transform(normalized_eeg_features))\n",
    "    labels = {\n",
    "        str(i): f\"PC {i+1} ({var:.1f}%)\"\n",
    "        for i, var in enumerate(pca.explained_variance_ratio_ * 100)\n",
    "    }\n",
    "\n",
    "    identifier = str(subject) + f\"_{band}_{channel}_channel\"\n",
    "    total_var = pca.explained_variance_ratio_.sum() * 100\n",
    "    fig = px.scatter_matrix(\n",
    "        proj_2d,\n",
    "        labels=labels,\n",
    "        dimensions=range(len(labels)),\n",
    "        color=all_blocks,\n",
    "        color_discrete_map=V_COLOR_MAP if is_user_rating else COLOR_MAP,\n",
    "        opacity=0.6,\n",
    "        title=f\"{identifier} Total Explained Variance: {total_var:.2f}%\",\n",
    "    )\n",
    "    fig.update_traces(diagonal_visible=False)\n",
    "\n",
    "    # Deduplicate the legends\n",
    "    names = set()\n",
    "    fig.for_each_trace(\n",
    "        lambda trace: trace.update(showlegend=False)\n",
    "        if (trace.name in names)\n",
    "        else names.add(trace.name)\n",
    "    )\n",
    "\n",
    "    fig.update_layout(height=1000, width=1000, margin=dict(r=0, b=0, l=0))\n",
    "\n",
    "    filename = f\"results/{identifier}_PCA_breakdown.png\"\n",
    "    if to_save:\n",
    "        fig.write_image(filename)\n",
    "\n",
    "    fig.show()\n",
    "\n",
    "def do_hierarchical_clustering(normalized_eeg_features, n_clusters=4):\n",
    "    from sklearn.cluster import AgglomerativeClustering\n",
    "    import time\n",
    "\n",
    "    print(\"Compute unstructured hierarchical clustering...\")\n",
    "    st = time.time()\n",
    "    ward = AgglomerativeClustering(n_clusters=n_clusters, linkage=\"ward\").fit(\n",
    "        normalized_eeg_features\n",
    "    )\n",
    "    elapsed_time = time.time() - st\n",
    "    print(f\"Elapsed time: {elapsed_time:.2f}s\")\n",
    "    #     print(f\"Number of points: {ward.labels_.size}\")\n",
    "    return ward.labels_\n",
    "\n",
    "\n",
    "def do_kmeans(normalized_eeg_features, n_clusters=4):\n",
    "    from sklearn.cluster import KMeans\n",
    "\n",
    "    kmeans = KMeans(init=\"k-means++\", n_clusters=n_clusters, n_init=2)\n",
    "    kmeans.fit(normalized_eeg_features)\n",
    "    # Find which cluster each data-point belongs to\n",
    "    return kmeans.predict(normalized_eeg_features)\n",
    "\n",
    "\n",
    "# reference https://www.mikulskibartosz.name/pca-how-to-choose-the-number-of-components/\n",
    "def get_clustering_result(data, subject, n_clusters, cluster_func, score_func):\n",
    "    heatmap_data = []\n",
    "    s = subject\n",
    "    for ch in [\"A\", \"B\", \"C\", \"D\"]:\n",
    "        scores = defaultdict()\n",
    "        for band in [\"ALL\", \"DELTA\", \"THETA\", \"ALPHA\", \"BETA1\", \"BETA2\", \"GAMMA\"]:\n",
    "            normalized_eeg_features, _ = get_processed_feature(\n",
    "                band, ch, data.drop(\"condition\", axis=1), [s]\n",
    "            )\n",
    "            reduced_data = PCA(n_components=0.95).fit_transform(normalized_eeg_features)\n",
    "            normalized_eeg_features = pd.DataFrame(reduced_data)\n",
    "\n",
    "            true_labels = data[data[\"Subject\"] == s][\"condition\"]\n",
    "            score = score_func(true_labels, cluster_func(normalized_eeg_features, n_clusters))\n",
    "            # print(f'{band}:{ch}:{score}')\n",
    "            scores[band] = score\n",
    "        heatmap_data.append(scores)\n",
    "    \n",
    "    return pd.DataFrame(heatmap_data, index=[\"A\", \"B\", \"C\", \"D\"])\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ba0c53c4",
   "metadata": {},
   "source": [
    "### Filter out data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c142d239",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_blocks = []\n",
    "for b in SORTED_BLOCK_NAMES:\n",
    "    all_blocks.extend([b] * 13)\n",
    "\n",
    "result[\"condition\"] = all_blocks * len(result.Subject.unique())\n",
    "mask = result[\"condition\"].isin(AUDIO_BLOCKS)\n",
    "audio_only = result[mask]\n",
    "all_blocks = list(audio_only['condition'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "aea0d45f",
   "metadata": {},
   "source": [
    "#### (Optional) Update True label as user rating "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "879f65d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# True label as user ratings\n",
    "v_r = audio_only[\"Valence\"].tolist()\n",
    "a_r = audio_only[\"Arousal\"].tolist()\n",
    "all_blocks = []\n",
    "for i in range(audio_only.shape[0]):\n",
    "    valence = \"hv\"\n",
    "    if v_r[i] < 0.4:\n",
    "        valence = \"lv\"\n",
    "    elif v_r[i] < 0.6:\n",
    "        valence = \"nv\"\n",
    "\n",
    "    arousal = \"ha\" if a_r[i] > 0.5 else \"la\"\n",
    "    all_blocks.append(valence + arousal)\n",
    "\n",
    "audio_only['condition'] = all_blocks"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "1820f863",
   "metadata": {},
   "source": [
    "### Select subject to execute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e911ac8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from constants import SUEJECT_BATCHES\n",
    "\n",
    "# Attach the block conditions\n",
    "subjects = SUEJECT_BATCHES[0]\n",
    "audio_only_subjects = audio_only[audio_only.Subject.isin(subjects)]\n",
    "audio_only_subjects.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "bacd491c",
   "metadata": {},
   "source": [
    "### Plot individual PCA with different band and channel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2250d1c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://plotly.com/python/pca-visualization/\n",
    "all_blocks = list(audio_only_subjects['condition'])\n",
    "for band in [\"ALL\", \"DELTA\", \"THETA\", \"ALPHA\", \"BETA1\", \"BETA2\", \"GAMMA\"]:\n",
    "    for ch in [\"A\", \"B\", \"C\", \"D\"]:\n",
    "        plotX = get_pca(band, ch, audio_only_subjects.drop(\"condition\", axis=1), subjects)\n",
    "        feature = f\"rating_audio_{band}_{ch}_channel_PCA\"\n",
    "        plotX[\"condition\"] = all_blocks\n",
    "        show_result(feature, subjects, plotX, all_blocks, False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a1661dea",
   "metadata": {},
   "source": [
    "### Plot PCA components breakdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "492afd1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ipywidgets as widgets\n",
    "\n",
    "channel = widgets.Dropdown(\n",
    "    options=[\"A\", \"B\", \"C\", \"D\"],\n",
    "    value='A',\n",
    "    description='Channel:',\n",
    "    disabled=False,\n",
    ")\n",
    "channel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "072b2f55",
   "metadata": {},
   "outputs": [],
   "source": [
    "band = widgets.Dropdown(\n",
    "    options=[\"DELTA\", \"THETA\", \"ALPHA\", \"BETA1\", \"BETA2\", \"GAMMA\"],\n",
    "    value='DELTA',\n",
    "    description='Spectral:',\n",
    "    disabled=False,\n",
    ")\n",
    "band"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "801ca2c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_components = 6\n",
    "is_user_rating = True\n",
    "\n",
    "for s in subjects: #\n",
    "    conditions = audio_only_subjects[audio_only_subjects[\"Subject\"] == s][\"condition\"]\n",
    "    show_pca_matrix(\n",
    "        band.value,\n",
    "        channel.value,\n",
    "        s,\n",
    "        audio_only_subjects.drop(\"condition\", axis=1),\n",
    "        conditions,\n",
    "        n_components,\n",
    "        False,\n",
    "        is_user_rating,\n",
    "    )\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "598d3c6d",
   "metadata": {},
   "source": [
    "### Plot rand index heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c72944ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "subject_to_heatmap = {}\n",
    "for s in subjects:\n",
    "    subject_to_heatmap[s] = get_clustering_result(audio_only_subjects, s, 6, do_kmeans, rand_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "391b0d35",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "fig, axes = plt.subplots(3, 2, sharex=True, sharey=True, figsize=(14, 10))\n",
    "fig.suptitle('Rand index scroe of Kmeans Clustering with audio only blocks')\n",
    "for s, ax in zip(subject_to_heatmap.keys(), axes.flatten()):\n",
    "    ax.set_title(s)\n",
    "    sns.heatmap(subject_to_heatmap[s], annot=True, fmt=\".3f\", linewidths=0.5, ax=ax, cmap=\"crest\")\n",
    "    \n",
    "\n",
    "identifier = \",\".join(str(s) for s in subjects)\n",
    "filename = f\"results/{identifier}_rand_index_kmeans_audio_blocks.png\"\n",
    "fig.show()\n",
    "plt.savefig(filename)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "647b89ee",
   "metadata": {},
   "source": [
    "### Others"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce78a16a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataframe.visualization import pca_2d\n",
    "\n",
    "# Add the cluster vector to our DataFrame, X\n",
    "normalized_eeg_features[\"Cluster\"] = clusters\n",
    "# normalized_eeg_features['Block'] = all_blocks\n",
    "\n",
    "pca_2d(\n",
    "    normalized_eeg_features,\n",
    "    4,\n",
    "    [\n",
    "        \"rgba(255, 128, 255, 0.8)\",\n",
    "        \"rgba(255, 128, 2, 0.8)\",\n",
    "        \"rgba(0, 255, 200, 0.8)\",\n",
    "        \"rgba(0, 128, 200, 0.8)\",\n",
    "    ],\n",
    "    \"hello\",\n",
    "    False,\n",
    "    mode=\"markers\",\n",
    "    textfont=dict(size=10),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cf95317",
   "metadata": {},
   "outputs": [],
   "source": [
    "for f in [\"ALL\", \"DELTA\", \"THETA\", \"ALPHA\", \"BETA1\", \"BETA2\", \"GAMMA\"]:\n",
    "    plotX = get_umap(f, result, all_blocks, subjects)\n",
    "    feature = f\"{f}_UMAP\"\n",
    "    show_result(feature, subjects, plotX, condition)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bc646a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.mixture import GaussianMixture\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# gmm = GaussianMixture(n_components=2).fit(normalized_eeg_features)\n",
    "# clusters = gmm.predict(normalized_eeg_features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "617386cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.cluster import DBSCAN\n",
    "# from sklearn import metrics\n",
    "\n",
    "# db = DBSCAN(eps=7, min_samples=10).fit(normalized_eeg_features)\n",
    "# clusters = db.labels_\n",
    "\n",
    "# # Number of clusters in labels, ignoring noise if present.\n",
    "# n_clusters_ = len(set(clusters)) - (1 if -1 in clusters else 0)\n",
    "# n_noise_ = list(clusters).count(-1)\n",
    "\n",
    "# print(\"Estimated number of clusters: %d\" % n_clusters_)\n",
    "# print(\"Estimated number of noise points: %d\" % n_noise_)\n",
    "# clusters\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MM",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
