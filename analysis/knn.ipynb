{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import pickle\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "\n",
    "import seaborn as sns\n",
    "import cebra\n",
    "from cebra import CEBRA\n",
    "\n",
    "from dataframe.csv_utils import (\n",
    "    load_data_from_csv,\n",
    ")\n",
    "from data_utils import (\n",
    "    load_data_from_dir,\n",
    ")\n",
    "from labels import get_behavioral_labels\n",
    "from plotting import subplot_confusion_matrix\n",
    "from constants import SUEJECT_BATCHES, AUDIO_BLOCKS\n",
    "from features.constants import Feature, MARKER_TO_FEATURE\n",
    "\n",
    "data_dir = \"../CleandDataV2/\"\n",
    "random.seed(33)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from features.psd import get_psd_by_channel, get_psd\n",
    "from biomarkers import EEG_CHANEL_NAMES\n",
    "from labels import get_raw_labels, get_label_means\n",
    "from feature_extraction import EEG_BANDS\n",
    "from resample.resample import (\n",
    "    get_validation_indexes,\n",
    "    upsample_by_attention,\n",
    "    get_resampled_list_index,\n",
    "    slice_data_by_seconds,\n",
    ")\n",
    "\n",
    "\n",
    "def get_psd_by_channel_band(block_data, channel_type: str, srate: int, feature):\n",
    "    psd_data = []\n",
    "    num_trials = block_data.shape[0]\n",
    "    # loop through all trials: time -> frequency\n",
    "    for t in range(num_trials):\n",
    "        all_channel_psd = []\n",
    "        for i, c in enumerate(EEG_CHANEL_NAMES):\n",
    "            if not c.startswith(channel_type):\n",
    "                continue\n",
    "\n",
    "            psd = get_psd(block_data[t, i, :], srate, EEG_BANDS[feature])\n",
    "            all_channel_psd.append(psd)\n",
    "\n",
    "        all_channel_psd = np.concatenate(all_channel_psd)\n",
    "        psd_data.append(all_channel_psd)\n",
    "\n",
    "    return np.stack(psd_data, axis=0)\n",
    "\n",
    "\n",
    "def get_features(block_data, marker, channel_type: str, srate: int, feature):\n",
    "    if marker == \"EEG\":\n",
    "        return get_psd_by_channel_band(block_data, channel_type, srate, feature)\n",
    "    if feature == Feature.ECG_HF or feature == Feature.EGG_FILTERED:\n",
    "        return block_data[:, 0, :]\n",
    "    elif feature == Feature.ECG_LF or feature == Feature.EGG_PHASE:\n",
    "        return block_data[:, 1, :]\n",
    "    elif feature == Feature.ECG_LFHF or feature == Feature.EGG_AMPLITUDE:\n",
    "        return block_data[:, 2, :]\n",
    "\n",
    "\n",
    "def get_block_features(\n",
    "    blocks, subject_data, marker, channel, feature, with_sliced: bool = False\n",
    "):\n",
    "    features = []\n",
    "\n",
    "    for b in blocks:\n",
    "        block_data = subject_data[b]\n",
    "        if with_sliced:\n",
    "            srate = block_data.get_srate(marker)\n",
    "            sliced_data = slice_data_by_seconds(\n",
    "                block_data.get_all_data()[marker], srate, 4\n",
    "            )\n",
    "            psd_data = get_features(sliced_data, marker, channel, srate, feature)\n",
    "        else:\n",
    "            psd_data = get_psd_by_channel(block_data, marker, channel, feature)\n",
    "\n",
    "        features = np.vstack((psd_data, features)) if len(features) > 0 else psd_data\n",
    "\n",
    "    return features\n",
    "\n",
    "\n",
    "def get_categorical_labels(blocks, subject_data):\n",
    "    behavioral_labels = []\n",
    "\n",
    "    for b in blocks:\n",
    "        block_data = subject_data[b]\n",
    "        v_label = block_data.get_labels()\n",
    "        a_label = block_data.get_labels(\"arousal\")\n",
    "\n",
    "        labels = [\n",
    "            get_behavioral_labels(v_label[i], a_label[i]) for i in range(len(v_label))\n",
    "        ]\n",
    "        behavioral_labels.extend(labels)\n",
    "\n",
    "    return behavioral_labels\n",
    "\n",
    "\n",
    "def get_label_category(labels, label_type, v_thred, a_thred):\n",
    "    threshold = a_thred if label_type == \"arousal\" else v_thred\n",
    "    return [0 if p < threshold else 1 for p in labels]\n",
    "\n",
    "\n",
    "def get_channel_feature_to_data(subject_data, marker: str = \"EEG\"):\n",
    "    sliced_channel_feature_to_data = {\"A\": {}, \"B\": {}, \"C\": {}, \"D\": {}}\n",
    "    for c in sliced_channel_feature_to_data.keys():\n",
    "        for f in EEG_BANDS.keys():\n",
    "            raw_data = get_block_features(\n",
    "                AUDIO_BLOCKS, subject_data, marker, c, f, True\n",
    "            )\n",
    "            sliced_channel_feature_to_data[c][f] = raw_data\n",
    "\n",
    "    return sliced_channel_feature_to_data\n",
    "\n",
    "\n",
    "def get_feature_to_data(subject_data, marker: str = \"EEG\"):\n",
    "    if marker == \"EEG\":\n",
    "        return get_channel_feature_to_data(subject_data, marker)\n",
    "\n",
    "    sliced_feature_to_data = {marker: {f: {} for f in MARKER_TO_FEATURE[marker]}}\n",
    "    for f in sliced_feature_to_data[marker].keys():\n",
    "        raw_data = get_block_features(AUDIO_BLOCKS, subject_data, marker, \"\", f, True)\n",
    "        sliced_feature_to_data[marker][f] = raw_data\n",
    "\n",
    "    return sliced_feature_to_data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data and process features"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Slicing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "marker = \"EEG\"\n",
    "num_slice_per_trial = 5\n",
    "\n",
    "# [2001, 2003, 2017, 2026, 2028, 2033,  2037, 2041]\n",
    "subject_list = []\n",
    "marker_features = []\n",
    "valence_labels, arousal_labels, attention_labels = [], [], []\n",
    "label_thresholds = []\n",
    "for d in os.listdir(data_dir):\n",
    "    dir_name = data_dir + d\n",
    "    if not os.path.isdir(dir_name):\n",
    "        continue\n",
    "\n",
    "    subject_data = load_data_from_dir(dir_name)\n",
    "    features = get_feature_to_data(subject_data, marker)\n",
    "    vl, arl, atl = get_raw_labels(AUDIO_BLOCKS, subject_data, num_slice_per_trial)\n",
    "\n",
    "    subject_list.append(d)\n",
    "    marker_features.append(features)\n",
    "    valence_labels.append(vl)\n",
    "    arousal_labels.append(arl)\n",
    "    attention_labels.append(atl)\n",
    "    label_thresholds.append(get_label_means(subject_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read dictionary pkl file\n",
    "with open('./eeg_features2/all_features.pkl', 'rb') as fp:\n",
    "    marker_features = pickle.load(fp)\n",
    "    print('Person dictionary')\n",
    "marker_features"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### No slicing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "marker = \"EEG\"\n",
    "# [2001, 2003, 2017, 2026, 2028, 2033,  2037, 2041]\n",
    "subj = 2041\n",
    "subject_data = subj_to_data[subj]\n",
    "num_slice_per_trial = 1\n",
    "\n",
    "channel_feature_to_data = {\"A\": {}, \"B\": {}, \"C\": {}, \"D\": {}}\n",
    "for c in [\"A\", \"B\", \"C\", \"D\"]:\n",
    "    for f in EEG_BANDS.keys():\n",
    "        raw_data = get_block_features(AUDIO_BLOCKS, subject_data, marker, c, f)\n",
    "        channel_feature_to_data[c][f] = raw_data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Training"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ipywidgets as widgets\n",
    "from plotting import plot_roc_curve\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import f1_score, accuracy_score\n",
    "# from importlib import reload\n",
    "# import features.constants\n",
    "\n",
    "# reload(features.constants)\n",
    "from features.constants import Feature\n",
    "\n",
    "# CEBRA AND PCA hyper-parameters\n",
    "OUTPUT_DIM = 8\n",
    "MAX_HIDDEN_UNITS = 256\n",
    "\n",
    "\n",
    "def model_fit(\n",
    "    neural_data,\n",
    "    out_dim,\n",
    "    num_hidden_units,\n",
    "    behavioral_labels,\n",
    "    max_iterations: int = 10,\n",
    "    max_adapt_iterations: int = 10,\n",
    "):\n",
    "    single_cebra_model = CEBRA(\n",
    "        # model_architecture = \"offset10-model\",\n",
    "        batch_size=512,\n",
    "        output_dimension=out_dim,\n",
    "        max_iterations=max_iterations,\n",
    "        num_hidden_units=num_hidden_units,\n",
    "        max_adapt_iterations=max_adapt_iterations,\n",
    "    )\n",
    "\n",
    "    if behavioral_labels is None:\n",
    "        single_cebra_model.fit(neural_data)\n",
    "    else:\n",
    "        single_cebra_model.fit(neural_data, behavioral_labels)\n",
    "    # cebra.plot_loss(single_cebra_model)\n",
    "    return single_cebra_model\n",
    "\n",
    "\n",
    "def get_embeddings(\n",
    "    train_data,\n",
    "    val_data,\n",
    "    train_labels,\n",
    "    use_pca: bool = False,\n",
    "    out_dim: int = 16,\n",
    "    num_hidden_units: int = 256,\n",
    "):\n",
    "    if use_pca:\n",
    "        # Run PCA\n",
    "        pca = PCA(n_components=out_dim)\n",
    "        pca = pca.fit(train_data)\n",
    "        return pca.transform(train_data), pca.transform(val_data)\n",
    "\n",
    "    single_cebra_model = model_fit(train_data, out_dim, num_hidden_units, train_labels)\n",
    "\n",
    "    # Calculate embedding\n",
    "    embedding = single_cebra_model.transform(train_data)\n",
    "    val_embedding = single_cebra_model.transform(val_data)\n",
    "    return embedding, val_embedding\n",
    "\n",
    "\n",
    "def _train_test_split(data, labels, attention_labels, val_indexes: list = []):\n",
    "    if len(val_indexes) == 0:\n",
    "        val_indexes = get_validation_indexes()\n",
    "\n",
    "    train_indexes = list(set(range(len(labels))) - set(val_indexes))\n",
    "\n",
    "    resampled_list = get_resampled_list_index(train_indexes, attention_labels)\n",
    "\n",
    "    train_labels = np.array(labels)[train_indexes][resampled_list]\n",
    "    train_data = data[train_indexes][resampled_list]\n",
    "\n",
    "    val_data = data[val_indexes]\n",
    "    val_label = np.array(labels)[val_indexes]\n",
    "    return train_data, train_labels, val_data, val_label\n",
    "\n",
    "\n",
    "# output_dim, max_hidden_units only needed for CEBRA\n",
    "def run_knn_decoder(\n",
    "    dataset,\n",
    "    method,\n",
    "    threshold,\n",
    "    output_dim,\n",
    "    max_hidden_units,\n",
    "):\n",
    "    y_pred, y_pred_cat, all_embeddings = [], [], []\n",
    "    for _, (train_data, train_labels, val_data, _) in enumerate(dataset):\n",
    "        embedding, val_embedding = get_embeddings(\n",
    "            train_data=train_data,\n",
    "            val_data=val_data,\n",
    "            train_labels=train_labels,\n",
    "            use_pca=(method == \"PCA\"),\n",
    "            out_dim=output_dim,\n",
    "            num_hidden_units=max_hidden_units,\n",
    "        )\n",
    "        all_embeddings.append(embedding)\n",
    "        # 4. Train the decoder on training embedding and labels\n",
    "        # train_true_cat = get_label_category(train_labels, label_type)\n",
    "        decoder = cebra.KNNDecoder()\n",
    "        decoder.fit(embedding, np.array(train_labels))\n",
    "\n",
    "        # score = decoder.score(val_embedding, np.array(val_labels))\n",
    "        prediction = decoder.predict(val_embedding)\n",
    "        y_pred.append(prediction)\n",
    "        y_pred_cat.append([0 if p < threshold else 1 for p in prediction])\n",
    "\n",
    "    return y_pred, y_pred_cat, all_embeddings\n",
    "\n",
    "\n",
    "def get_all_spectral_features(\n",
    "    feature_to_data: dict, val_indexes, attention_labels, labels\n",
    "):\n",
    "    all_spetral_psd = [feature_to_data[f] for f in EEG_BANDS.keys()]\n",
    "    all_spetral_psd = np.hstack(all_spetral_psd)\n",
    "    return [\n",
    "        _train_test_split(all_spetral_psd, labels, attention_labels, val_indexes[i])\n",
    "        for i in range(len(val_indexes))\n",
    "    ]\n",
    "\n",
    "\n",
    "def get_all_channel_features(data: dict, val_indexes, attention_labels, labels):\n",
    "    all_spetral_psd = []\n",
    "    for _, feature_to_data in data.items():\n",
    "        spetral_psd = [feature_to_data[f] for f in EEG_BANDS.keys()]\n",
    "        all_spetral_psd.extend(spetral_psd)\n",
    "\n",
    "    all_spetral_psd = np.hstack(all_spetral_psd)\n",
    "    return [\n",
    "        _train_test_split(all_spetral_psd, labels, attention_labels, val_indexes[i])\n",
    "        for i in range(len(val_indexes))\n",
    "    ]\n",
    "\n",
    "\n",
    "def prepare_dataset(\n",
    "    data,\n",
    "    val_indexes,\n",
    "    attention_labels,\n",
    "    labels,\n",
    "    has_all_spectral: bool = False,\n",
    "    filtered_channel: str = \"\",\n",
    "):\n",
    "    if filtered_channel == \"ALL\":\n",
    "        return {\n",
    "            \"ALL\": {\n",
    "                Feature.ALL_SPECTRAL: get_all_channel_features(\n",
    "                    data, val_indexes, attention_labels, labels\n",
    "                )\n",
    "            }\n",
    "        }\n",
    "\n",
    "    dataset_dict = {k: {} for k in data.keys()}\n",
    "    for channel, feature_to_data in data.items():\n",
    "        if len(feature_to_data) == 0 or (\n",
    "            channel != filtered_channel and len(filtered_channel) > 0\n",
    "        ):\n",
    "            continue\n",
    "\n",
    "        if has_all_spectral:\n",
    "            dataset_dict[channel][Feature.ALL_SPECTRAL] = get_all_spectral_features(\n",
    "                feature_to_data, val_indexes, attention_labels, labels\n",
    "            )\n",
    "            continue\n",
    "\n",
    "        for f, neural_data in feature_to_data.items():\n",
    "            # Prepare the data\n",
    "            dataset_dict[channel][f] = [\n",
    "                _train_test_split(neural_data, labels, attention_labels, val_indexes[i])\n",
    "                for i in range(len(val_indexes))\n",
    "            ]\n",
    "    return dataset_dict\n",
    "\n",
    "\n",
    "def set_pane_axis(ax):\n",
    "    ax.xaxis.set_pane_color((1.0, 1.0, 1.0, 0.0))\n",
    "    ax.yaxis.set_pane_color((1.0, 1.0, 1.0, 0.0))\n",
    "    ax.zaxis.set_pane_color((1.0, 1.0, 1.0, 0.0))\n",
    "    ax.xaxis._axinfo[\"grid\"][\"color\"] = (1, 1, 1, 0)\n",
    "    ax.yaxis._axinfo[\"grid\"][\"color\"] = (1, 1, 1, 0)\n",
    "    ax.zaxis._axinfo[\"grid\"][\"color\"] = (1, 1, 1, 0)\n",
    "    ax.xaxis.set_ticks([])\n",
    "    ax.yaxis.set_ticks([])\n",
    "    ax.zaxis.set_ticks([])\n",
    "\n",
    "def decode_marker_data(\n",
    "    dataset_dict,\n",
    "    label_type,\n",
    "    v_thred,\n",
    "    a_thred,\n",
    "    method,\n",
    "    threshold,\n",
    "    plot_roc: bool = False,\n",
    "    plot_embed: bool = False,\n",
    "):\n",
    "    f1_score_data = {k: {} for k in dataset_dict.keys()}\n",
    "    accuracy = {k: {} for k in dataset_dict.keys()}\n",
    "    list_embedding_tuple = []\n",
    "    for channel, feature_to_data in dataset_dict.items():\n",
    "        if len(feature_to_data) == 0:\n",
    "            continue\n",
    "\n",
    "        for f, dataset in feature_to_data.items():\n",
    "            val_true_cat = [\n",
    "                get_label_category(val_labels, label_type, v_thred, a_thred)\n",
    "                for _, (_, _, _, val_labels) in enumerate(dataset)\n",
    "            ]\n",
    "\n",
    "            y_pred, val_pred_cat, all_embeddings = run_knn_decoder(\n",
    "                dataset,\n",
    "                method,\n",
    "                threshold,\n",
    "                OUTPUT_DIM,\n",
    "                MAX_HIDDEN_UNITS,\n",
    "            )\n",
    "\n",
    "            if plot_roc:\n",
    "                plot_roc_curve(y_pred, val_true_cat, method, label_type, channel, f)\n",
    "\n",
    "            score = [\n",
    "                f1_score(y_pred=val_pred_cat[i], y_true=val_true_cat[i])\n",
    "                for i in range(len(val_pred_cat))\n",
    "            ]\n",
    "            ac_scores = [\n",
    "                accuracy_score(y_pred=val_pred_cat[i], y_true=val_true_cat[i])\n",
    "                for i in range(len(val_pred_cat))\n",
    "            ]\n",
    "            if plot_embed:\n",
    "                max_score_index = np.array(ac_scores).argmax(axis=0)\n",
    "                best_acc = round(ac_scores[max_score_index], 2)\n",
    "                list_embedding_tuple.append(\n",
    "                    (\n",
    "                        f\"{channel} {f.name} Acc:{best_acc}\",\n",
    "                        all_embeddings[max_score_index],\n",
    "                        dataset[max_score_index][1],\n",
    "                    )\n",
    "                )\n",
    "\n",
    "            f1_score_data[channel][f] = np.mean(score)\n",
    "            accuracy[channel][f] = np.mean(ac_scores)\n",
    "\n",
    "    if len(list_embedding_tuple) > 0:\n",
    "        n_row, n_col = (2, 3) if len(list_embedding_tuple) == 6 else (1, 4)\n",
    "        fig, axes = plt.subplots(\n",
    "            nrows=n_row,\n",
    "            sharey=True,\n",
    "            ncols=n_col,\n",
    "            figsize=(n_col * 5, n_row * 5),\n",
    "            subplot_kw=dict(projection=\"3d\"),\n",
    "        )\n",
    "        idx1, idx2, idx3 = (0, 1, 2)\n",
    "        for idx, (title, embeddings, embedding_labels) in enumerate(list_embedding_tuple):\n",
    "            y = axes.flat[idx].scatter(\n",
    "                embeddings[:, idx1],\n",
    "                embeddings[:, idx2],\n",
    "                embeddings[:, idx3],\n",
    "                cmap=\"cool\",\n",
    "                c=embedding_labels,\n",
    "                s=5,\n",
    "                vmin=0,\n",
    "                vmax=1,\n",
    "            )\n",
    "            axes.flat[idx].set_title(title)\n",
    "            yc = plt.colorbar(y, fraction=0.03, pad=0.05, ticks=np.linspace(0, 1, 9))\n",
    "            yc.ax.tick_params(labelsize=10)\n",
    "            yc.ax.set_title(\"score\", fontsize=10)    \n",
    "            set_pane_axis(axes.flat[idx])        \n",
    "            \n",
    "        fig.suptitle(f'{method} - {label_type} Latents: (1,2,3)')    \n",
    "       \n",
    "    return f1_score_data, accuracy"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from resample.resample import get_consecutive_validation_indexes\n",
    "\n",
    "n_step_trial = 3\n",
    "val_indexes = [\n",
    "    get_consecutive_validation_indexes(\n",
    "        len(valence_labels[0]), len(AUDIO_BLOCKS), num_slice_per_trial, i, n_step_trial\n",
    "    )\n",
    "    for i in range(1, 13, n_step_trial)\n",
    "]\n",
    "print(len(val_indexes), val_indexes)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get subjects summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_feature_names_and_mean_scores(\n",
    "    dataset_dict, accuracy, marker: str, filtered_channel: str\n",
    "):\n",
    "    if marker != \"EEG\":\n",
    "        return list(dataset_dict[marker].keys()), [\n",
    "            accuracy[marker][f] for f in all_feature_name\n",
    "        ]\n",
    "\n",
    "    if len(filtered_channel) == 0:\n",
    "        all_feature_name = list(dataset_dict.keys())\n",
    "        mean_scores = [accuracy[c][Feature.ALL_SPECTRAL] for c in all_feature_name]\n",
    "    else:\n",
    "        all_feature_name = list(dataset_dict[filtered_channel].keys())\n",
    "        mean_scores = [accuracy[filtered_channel][f] for f in all_feature_name]\n",
    "\n",
    "    return all_feature_name, mean_scores\n",
    "\n",
    "\n",
    "subject_accuracy_summary = {\n",
    "    \"subject\": [],\n",
    "    \"channel\": [],\n",
    "    \"label_type\": [],\n",
    "    \"cv_mean_score\": [],\n",
    "}\n",
    "filtered_channel = \"D\"\n",
    "\n",
    "for idx in range(len(subject_list)):\n",
    "    print('decoding subject...', subject_list[idx])\n",
    "\n",
    "    v_thred, a_thred = label_thresholds[idx]\n",
    "    for lt in [\"valence\", \"arousal\"]:\n",
    "        labels = valence_labels[idx] if lt == \"valence\" else arousal_labels[idx]\n",
    "        thred = v_thred if lt == \"valence\" else a_thred\n",
    "        dataset_dict = prepare_dataset(\n",
    "            marker_features[idx],\n",
    "            val_indexes,\n",
    "            attention_labels[idx],\n",
    "            labels,\n",
    "            False,\n",
    "            filtered_channel,\n",
    "        )\n",
    "\n",
    "        f1_score_data, accuracy = decode_marker_data(\n",
    "            dataset_dict, lt, v_thred, a_thred, \"CEBRA\", thred, False, False\n",
    "        )\n",
    "\n",
    "        all_feature_name, mean_scores = get_feature_names_and_mean_scores(\n",
    "            dataset_dict, accuracy, marker, filtered_channel\n",
    "        )\n",
    "\n",
    "        subject_accuracy_summary[\"subject\"].extend(\n",
    "            [subject_list[idx]] * len(all_feature_name)\n",
    "        )\n",
    "        subject_accuracy_summary[\"channel\"].extend(all_feature_name)\n",
    "        subject_accuracy_summary[\"cv_mean_score\"].extend(mean_scores)\n",
    "        subject_accuracy_summary[\"label_type\"].extend([lt] * len(all_feature_name))\n",
    "\n",
    "subject_accuracy_summary = pd.DataFrame(subject_accuracy_summary)\n",
    "subject_accuracy_summary[\"subject\"] = subject_accuracy_summary[\"subject\"].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subject_accuracy_summary[\"channel\"] = subject_accuracy_summary[\"channel\"].astype(str)\n",
    "subject_accuracy_summary.to_csv('CEBRA_D8_U256_EEG_D_spectral.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = subject_accuracy_summary\n",
    "title = \"EEG D channel - CEBRA\"  #\n",
    "g = sns.swarmplot(\n",
    "    data=data,\n",
    "    x=\"label_type\",\n",
    "    y=\"cv_mean_score\",\n",
    "    hue=\"channel\",\n",
    "    alpha=0.6,\n",
    "    dodge=True,\n",
    "    legend=False,\n",
    ")\n",
    "g.set_ylim((0.35, 1))\n",
    "\n",
    "df_means = (\n",
    "    data.groupby([\"label_type\", \"channel\"])[\"cv_mean_score\"].agg(\"mean\").reset_index()\n",
    ")\n",
    "pp = sns.pointplot(\n",
    "    x=\"label_type\",\n",
    "    y=\"cv_mean_score\",\n",
    "    data=df_means,\n",
    "    hue=\"channel\",\n",
    "    dodge=0.6,\n",
    "    linestyles=\"\",\n",
    "    errorbar=None,\n",
    "    scale=2.5,\n",
    "    markers=\"_\",\n",
    "    hue_order=[\n",
    "        \"Feature.DELTA\",\n",
    "        \"Feature.THETA\",\n",
    "        \"Feature.ALPHA\",\n",
    "        \"Feature.BETA1\",\n",
    "        \"Feature.BETA2\",\n",
    "        \"Feature.GAMMA\",\n",
    "    ],\n",
    "    order=[\"valence\", \"arousal\"],\n",
    ")\n",
    "\n",
    "sns.move_legend(pp, \"upper right\", bbox_to_anchor=(1.4, 1))\n",
    "g.set_title(title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aduio_ari = pd.read_csv('../aduio_ari.csv')\n",
    "print('mean:',aduio_ari['ari'].mean(), 'max:', aduio_ari['ari'].max(), 'min:', aduio_ari['ari'].min())\n",
    "\n",
    "high_c = aduio_ari[aduio_ari['ari'] > aduio_ari['ari'].mean()]\n",
    "low_c = aduio_ari[aduio_ari['ari'] <= aduio_ari['ari'].mean()]\n",
    "print(len(high_c), len(low_c))\n",
    "\n",
    "ari_scores = []\n",
    "for s in list(subject_accuracy_summary['subject']):\n",
    "    score = aduio_ari[aduio_ari['subject'] == int(s)]['ari'].values[0]\n",
    "    ari_scores.append(score)\n",
    "subject_accuracy_summary['ari_scores'] = ari_scores\n",
    "subject_accuracy_summary.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.relplot(\n",
    "    data=subject_accuracy_summary,\n",
    "    x=\"ari_scores\", y=\"cv_mean_score\", hue=\"label_type\", col=\"channel\",\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run for single subject"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Process labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_selector = widgets.Dropdown(\n",
    "    options=[\"valence\", \"hybrid\", \"arousal\"],\n",
    "    value=\"valence\",\n",
    "    description=\"label_type:\",\n",
    "    disabled=False,\n",
    ")\n",
    "label_selector"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Leave last two trials in each block as validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "label_type = label_selector.value\n",
    "validation_list = [10, 11, 12, 23, 24, 25, 36, 37, 38, 49, 50, 51]\n",
    "train_list = [i for i in range(len(valence_labels)) if i not in validation_list]\n",
    "\n",
    "train_attention_labels = np.array(attention_labels)[train_list]\n",
    "resampled_list = upsample_by_attention(train_attention_labels, 52 * 4)\n",
    "train_labels = np.array(labels)[train_list][resampled_list]\n",
    "\n",
    "validation_labels = np.array(labels)[validation_list]\n",
    "\n",
    "train_true_cat = get_label_category(train_labels, label_type, v_thred, a_thred)\n",
    "val_true_cat = get_label_category(validation_labels, label_type, v_thred, a_thred)\n",
    "\n",
    "r2_score_data = {\"A\": {}, \"B\": {}, \"C\": {}, \"D\": {}}\n",
    "for channel, feature_to_data in channel_feature_to_data.items():\n",
    "    if len(feature_to_data) == 0:\n",
    "        continue\n",
    "\n",
    "    nrows = 2\n",
    "    ncols = int(len(feature_to_data) / 2)\n",
    "    fig, axes = plt.subplots(\n",
    "        nrows=nrows,\n",
    "        sharey=True,\n",
    "        ncols=ncols,\n",
    "        figsize=(ncols * 5, nrows * 5),\n",
    "    )\n",
    "\n",
    "    idx = 0\n",
    "    for f, neural_data in feature_to_data.items():\n",
    "        train_data = neural_data[train_list][resampled_list]\n",
    "        val_data = neural_data[validation_list]\n",
    "\n",
    "        # loss_data[channel][f.name] = single_cebra_model.state_dict_[\"loss\"]\n",
    "        embedding, val_embedding = get_embeddings(\n",
    "            train_data=train_data,\n",
    "            val_data=val_data,\n",
    "            train_labels=train_labels,\n",
    "            use_pca=use_pca,\n",
    "            out_dim=OUTPUT_DIM,\n",
    "            num_hidden_units=MAX_HIDDEN_UNITS,\n",
    "        )\n",
    "        # 4. Train the decoder on training embedding and labels\n",
    "        decoder = cebra.KNNDecoder()\n",
    "        decoder.fit(embedding, np.array(train_true_cat))\n",
    "\n",
    "        # 5. Compute the score on validation embedding and labels\n",
    "        score = decoder.score(val_embedding, np.array(val_true_cat))\n",
    "        r2_score_data[channel][f.name] = score\n",
    "        # 5. Get the discrete labels predictions\n",
    "        prediction = decoder.predict(val_embedding)\n",
    "        print(channel, f, score)\n",
    "        # print('pre', prediction)\n",
    "        # print('true', val_true_cat)\n",
    "        # print('--------')\n",
    "        cm = confusion_matrix(val_true_cat, prediction)\n",
    "        subplot_confusion_matrix(\n",
    "            ax=axes.flat[idx],\n",
    "            cf=cm,\n",
    "            categories=[f\"low {label_type}\", f\"high {label_type}\"],\n",
    "            percent=\"by_row\",\n",
    "            vmin=0,\n",
    "            vmax=1,\n",
    "        )\n",
    "        axes.flat[idx].set_title(f\"{channel}:{f.name}\")\n",
    "        idx += 1"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MiSC: Loss/Grid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nrows = 1\n",
    "ncols = len(loss_data)\n",
    "fig, axes = plt.subplots(\n",
    "    nrows=nrows,\n",
    "    ncols=ncols,\n",
    "    sharey=True,\n",
    "    figsize=(ncols * 5, nrows * 5),\n",
    ")\n",
    "\n",
    "fig.suptitle(\n",
    "    f\"Subject {subj}: {marker} {label_type} InfoNCE loss in audio condition\",\n",
    "    fontsize=15,\n",
    ")\n",
    "\n",
    "for c, ax in zip(loss_data.keys(), axes.flatten()):\n",
    "    df = pd.DataFrame(loss_data[c])\n",
    "    sns.lineplot(data=df, ax=ax)\n",
    "    ax.set_title(\"channel:\" + c)\n",
    "    ax.set_ylabel(\"InfoNCE Loss\")\n",
    "    ax.set_xlabel(\"Steps\")\n",
    "# plt.savefig(f\"results/cebra/{label_type}_{subj}_eeg_bands_channel_loss_{channel}_O{output_dim}H{max_hidden_units}.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_dict = {\"InfoNCE Loss\": [], \"band\": [], \"channel\": [], \"Steps\": []}\n",
    "for c, f_to_data in loss_data.items():\n",
    "    for f, data in f_to_data.items():\n",
    "        loss_dict[\"InfoNCE Loss\"].extend(np.array(data))\n",
    "        loss_dict[\"Steps\"].extend(np.arange(0, len(data), dtype=int))\n",
    "        loss_dict[\"band\"].extend([f] * len(data))\n",
    "        loss_dict[\"channel\"].extend([c] * len(data))\n",
    "\n",
    "loss_dict = pd.DataFrame(loss_dict)\n",
    "loss_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.lineplot(data=loss_dict, y=\"InfoNCE Loss\", x=\"Steps\", hue=\"band\", style=\"channel\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Define the parameters, either variable or fixed\n",
    "params_grid = dict(\n",
    "    output_dimension=[6, 8],\n",
    "    learning_rate=[3e-4],\n",
    "    max_iterations=10,\n",
    "    num_hidden_units=[32, 64, 128, 256],\n",
    "    max_adapt_iterations=10,\n",
    "    temperature_mode=\"auto\",\n",
    "    verbose=False,\n",
    ")\n",
    "\n",
    "# 2. Define the datasets to iterate over\n",
    "datasets = {\n",
    "    \"neural_data\": channel_feature_to_data[\"C\"][Feature.THETA],\n",
    "}\n",
    "\n",
    "# 3. Create and fit the grid search to your data\n",
    "grid_search = cebra.grid_search.GridSearch()\n",
    "grid_search = grid_search.fit_models(\n",
    "    datasets=datasets, params=params_grid, models_dir=\"saved_models\"\n",
    ")\n",
    "\n",
    "# 4. Get the results\n",
    "df_results = grid_search.get_df_results(models_dir=\"saved_models\")\n",
    "# 5. Get the best model for a given dataset\n",
    "best_model, best_model_name = grid_search.get_best_model(\n",
    "    dataset_name=\"neural_data\", models_dir=\"saved_models\"\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MM",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
