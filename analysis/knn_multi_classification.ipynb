{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import seaborn as sns\n",
    "import cebra\n",
    "from cebra import CEBRA\n",
    "\n",
    "from data_utils import (\n",
    "    load_data_from_dir,\n",
    ")\n",
    "from labels import get_behavioral_labels\n",
    "from plotting import subplot_confusion_matrix\n",
    "from constants import AUDIO_BLOCKS\n",
    "from features.constants import Feature, MARKER_TO_FEATURE\n",
    "\n",
    "data_dir = \"../CleandDataV2/\"\n",
    "random.seed(33)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from biomarkers import EEG_CHANEL_NAMES\n",
    "from labels import get_raw_labels, get_label_means\n",
    "from feature_extraction import EEG_BANDS\n",
    "from resample.resample import (\n",
    "    get_validation_indexes,\n",
    ")\n",
    "\n",
    "def get_categorical_labels(blocks, subject_data):\n",
    "    behavioral_labels = []\n",
    "\n",
    "    for b in blocks:\n",
    "        block_data = subject_data[b]\n",
    "        v_label = block_data.get_labels()\n",
    "        a_label = block_data.get_labels(\"arousal\")\n",
    "\n",
    "        labels = [\n",
    "            get_behavioral_labels(v_label[i], a_label[i]) for i in range(len(v_label))\n",
    "        ]\n",
    "        behavioral_labels.extend(labels)\n",
    "\n",
    "    return behavioral_labels\n",
    "\n",
    "\n",
    "def get_label_category(labels, label_type, v_thred, a_thred):\n",
    "    threshold = a_thred if label_type == \"arousal\" else v_thred\n",
    "    return [0 if p < threshold else 1 for p in labels]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data and process features"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Slicing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "marker = \"EEG\"\n",
    "num_slice_per_trial = 5\n",
    "\n",
    "subject_list = []\n",
    "valence_labels, arousal_labels, attention_labels = [], [], []\n",
    "label_thresholds = []\n",
    "for d in os.listdir(data_dir):    \n",
    "    dir_name = data_dir + d\n",
    "    if not os.path.isdir(dir_name):\n",
    "        continue\n",
    "\n",
    "    subject_data = load_data_from_dir(dir_name)\n",
    "    vl, arl, atl = get_raw_labels(AUDIO_BLOCKS, subject_data, num_slice_per_trial)\n",
    "    \n",
    "    subject_list.append(d)\n",
    "    valence_labels.append(vl)\n",
    "    arousal_labels.append(arl)\n",
    "    attention_labels.append(atl)\n",
    "    label_thresholds.append((np.mean(vl), np.mean(arl)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# Read dictionary pkl file\n",
    "with open('./eeg_features2/all_features.pkl', 'rb') as fp:\n",
    "    marker_features = pickle.load(fp)\n",
    "len(marker_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IDX_MAP = {\n",
    "    \"hvha\": 0,\n",
    "    \"hvla\": 1,\n",
    "    \"nvha\": 2,\n",
    "    \"nvla\": 3,\n",
    "}\n",
    "target_names = list(IDX_MAP.keys())\n",
    "\n",
    "cat_labels = []\n",
    "for idx, (v_thred, a_thred) in enumerate(label_thresholds):\n",
    "    vc = [ 'hv' if l > v_thred else 'nv' for l in valence_labels[idx]]\n",
    "    ac = [ 'ha' if l > a_thred else 'la' for l in arousal_labels[idx]]\n",
    "    vac = [ IDX_MAP[vc[i]+ac[i]] for i in range(len(vc))]\n",
    "    cat_labels.append(vac)\n",
    "len(cat_labels)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data inspection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_subject = '2041'\n",
    "for i in range(len(subject_list)):\n",
    "    if subject_list[i] == target_subject:\n",
    "        g = sns.histplot(data=[target_names[a]for a in cat_labels[i]], stat='percent') #, color='#fffea3'\n",
    "        g.set_title(target_subject)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nrows = 5\n",
    "ncol = 8\n",
    "fig, axes = plt.subplots(\n",
    "    nrows=nrows,\n",
    "    sharey=True,\n",
    "    ncols=ncol,\n",
    "    figsize=(ncol * 3, nrows * 4),\n",
    ")\n",
    "\n",
    "for i in range(len(axes.flat)):\n",
    "    g = sns.histplot(\n",
    "        data=[target_names[a] for a in cat_labels[i]], #['ha' if 'ha' in target_names[a] else 'la' for a in cat_labels[i]]\n",
    "        stat=\"percent\",\n",
    "        ax=axes.flat[i],\n",
    "        #color=\"#fffea3\",\n",
    "    )\n",
    "    g.set_title(subject_list[i])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Training"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title One Over Rest distribution and ROC\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import RocCurveDisplay\n",
    "\n",
    "# Plots the Probability Distributions and the ROC Curves One vs Rest\n",
    "bins = [i/20 for i in range(20)] + [1]\n",
    "\n",
    "def one_hot(a, num_classes):\n",
    "  return np.squeeze(np.eye(num_classes)[a.reshape(-1)])\n",
    "\n",
    "def _plot_one_over_rest_roc(y_true, y_pred, method, label_type):\n",
    "  from sklearn.metrics import ConfusionMatrixDisplay\n",
    "  title = f'{method}:{label_type}'\n",
    "  # Compuate the confusion matrix\n",
    "  disp = ConfusionMatrixDisplay.from_predictions(\n",
    "      y_true,\n",
    "      np.argmax(y_pred, axis=1),\n",
    "      display_labels=target_names,\n",
    "      cmap=plt.cm.Blues,\n",
    "      normalize='true')\n",
    "  # Set the fixed color bar range\n",
    "  disp.im_.set_clim(0, 1)\n",
    "  disp.ax_.set_title(title)\n",
    "  \n",
    "  y_true_one_hot = one_hot(y_true, len(target_names))\n",
    "\n",
    "  plt.figure(figsize = (12, 8))\n",
    "  roc_auc_ovr = {}\n",
    "  for i in range(len(target_names)):\n",
    "      c = target_names[i]\n",
    "      # Prepares an auxiliar dataframe to help with the plots\n",
    "      df_aux = {}\n",
    "      df_aux['class'] = y_true_one_hot[:, i]\n",
    "      df_aux['prob'] = y_pred[:, i]\n",
    "\n",
    "      # Plots the probability distribution for the class and the rest\n",
    "      ax = plt.subplot(2, len(target_names), i+1)\n",
    "      sns.histplot(x = \"prob\", data = df_aux, hue = 'class', color = 'b', ax = ax, bins = bins)\n",
    "      ax.set_title(c)\n",
    "      ax.legend([f\"Class: {c}\", \"Rest\"])\n",
    "      ax.set_xlabel(f\"P(x = {c})\")\n",
    "\n",
    "      # Calculates the ROC Coordinates and plots the ROC Curves\n",
    "      ax_bottom = plt.subplot(2, len(target_names), i+5)\n",
    "      RocCurveDisplay.from_predictions(\n",
    "          df_aux['class'],\n",
    "          df_aux['prob'],\n",
    "          name=c,\n",
    "          #color=color,\n",
    "          ax=ax_bottom,\n",
    "          #plot_chance_level=(class_id == 2),\n",
    "      )\n",
    "      #tpr, fpr = get_all_roc_coordinates(df_aux['class'], df_aux['prob'])\n",
    "      #plot_roc_curve(tpr, fpr, scatter = False, ax = ax_bottom)\n",
    "      ax_bottom.set_title(f\"ROC Curve OvR for {c}\")\n",
    "\n",
    "      # Calculates the ROC AUC OvR\n",
    "      roc_auc_ovr[c] = roc_auc_score(df_aux['class'], df_aux['prob'])\n",
    "      \n",
    "      plt.tight_layout()\n",
    "  plt.title(title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ipywidgets as widgets\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import f1_score, accuracy_score\n",
    "\n",
    "from model.embedding import get_embeddings\n",
    "\n",
    "# CEBRA AND PCA hyper-parameters\n",
    "OUTPUT_DIM = 8\n",
    "MAX_HIDDEN_UNITS = 256\n",
    "\n",
    "def _train_test_split(data, labels, val_indexes: list = []):\n",
    "    train_indexes = list(set(range(len(labels))) - set(val_indexes))\n",
    "    train_labels = np.array(labels)[train_indexes]\n",
    "    train_data = data[train_indexes]\n",
    "\n",
    "    val_data = data[val_indexes]\n",
    "    val_label = np.array(labels)[val_indexes]\n",
    "    return train_data, train_labels, val_data, val_label\n",
    "\n",
    "# output_dim, max_hidden_units only needed for CEBRA\n",
    "def run_knn_decoder(\n",
    "    dataset,\n",
    "    method,\n",
    "    output_dim,\n",
    "    max_hidden_units,\n",
    "):\n",
    "    from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "    y_pred, all_embeddings = [], []\n",
    "    for _, (train_data, train_labels, val_data, _) in enumerate(dataset):\n",
    "        embedding, val_embedding = get_embeddings(\n",
    "            train_data=train_data,\n",
    "            val_data=val_data,\n",
    "            train_labels=train_labels,\n",
    "            use_pca=(method == \"PCA\"),\n",
    "            out_dim=6 if method == \"PCA\" else output_dim,\n",
    "            num_hidden_units=max_hidden_units,\n",
    "        )\n",
    "        all_embeddings.append((embedding, val_embedding))\n",
    "        # 4. Train the decoder on training embedding and labels\n",
    "        # train_true_cat = get_label_category(train_labels, label_type)\n",
    "        decoder = KNeighborsClassifier(n_neighbors=4)\n",
    "        decoder.fit(embedding, np.array(train_labels))\n",
    "\n",
    "        # score = decoder.score(val_embedding, np.array(val_labels))\n",
    "        prediction = decoder.predict_proba(val_embedding)\n",
    "        y_pred.append(prediction)\n",
    "\n",
    "    return y_pred, all_embeddings\n",
    "\n",
    "\n",
    "def get_all_spectral_features(feature_to_data: dict, val_indexes, labels):\n",
    "    all_spetral_psd = [feature_to_data[f.name] for f in EEG_BANDS.keys()]\n",
    "    all_spetral_psd = np.hstack(all_spetral_psd)\n",
    "    return [\n",
    "        _train_test_split(all_spetral_psd, labels, val_indexes[i])\n",
    "        for i in range(len(val_indexes))\n",
    "    ]\n",
    "\n",
    "def prepare_dataset(\n",
    "    data,\n",
    "    val_indexes,\n",
    "    labels,\n",
    "    all_spectral_only: bool = False,\n",
    "):\n",
    "    dataset_dict = {k: {} for k in data.keys()}\n",
    "    for channel, feature_to_data in data.items():\n",
    "        dataset_dict[channel][Feature.ALL_SPECTRAL.name] = get_all_spectral_features(\n",
    "            feature_to_data, val_indexes, labels\n",
    "        )\n",
    "\n",
    "        if all_spectral_only:\n",
    "            continue\n",
    "        for f, neural_data in feature_to_data.items():\n",
    "            # Prepare the data\n",
    "            dataset_dict[channel][f] = [\n",
    "                _train_test_split(neural_data, labels, val_indexes[i])\n",
    "                for i in range(len(val_indexes))\n",
    "            ]\n",
    "\n",
    "\n",
    "    return dataset_dict\n",
    "\n",
    "\n",
    "def decode_marker_data(\n",
    "    dataset_dict,\n",
    "    method,\n",
    "    filtered_channel: str = \"\",\n",
    "    plot_roc: bool = False,\n",
    "):\n",
    "    accuracy = {k: {} for k in dataset_dict.keys()}\n",
    "    list_embedding_tuple = []\n",
    "    for channel, feature_to_data in dataset_dict.items():\n",
    "        if channel != filtered_channel and len(filtered_channel) > 0:\n",
    "            continue\n",
    "\n",
    "        for f, dataset in feature_to_data.items():\n",
    "            val_true_cat = [\n",
    "                val_labels for _, (_, _, _, val_labels) in enumerate(dataset)\n",
    "            ]\n",
    "\n",
    "            val_pred_cat, all_embeddings = run_knn_decoder(\n",
    "                dataset,\n",
    "                method,\n",
    "                OUTPUT_DIM,\n",
    "                MAX_HIDDEN_UNITS,\n",
    "            )\n",
    "            ac_scores = [\n",
    "                accuracy_score(\n",
    "                    y_pred=np.argmax(val_pred_cat[i], axis=1), y_true=val_true_cat[i]\n",
    "                )\n",
    "                for i in range(len(val_pred_cat))\n",
    "            ]\n",
    "            accuracy[channel][f] = np.mean(ac_scores)\n",
    "\n",
    "            max_score_index = np.array(ac_scores).argmax(axis=0)\n",
    "            mean_acc = round(np.mean(ac_scores), 2) \n",
    "            max_acc = round(ac_scores[max_score_index], 2)\n",
    "            list_embedding_tuple.append(\n",
    "                (\n",
    "                    f\"CV Acc Max: {max_acc} Avg:{mean_acc}\",\n",
    "                    max_score_index,\n",
    "                    all_embeddings[max_score_index],\n",
    "                    (dataset[max_score_index][1], dataset[max_score_index][3]),\n",
    "                )\n",
    "            )\n",
    "\n",
    "            if plot_roc:\n",
    "                y_pred, y_true = [], []\n",
    "                for i in range(len(val_true_cat)):\n",
    "                    y_true.extend(val_true_cat[i])\n",
    "                    y_pred.extend(val_pred_cat[i])\n",
    "\n",
    "                _plot_one_over_rest_roc(\n",
    "                    np.array(y_true), np.array(y_pred), channel, f,\n",
    "                )            \n",
    "\n",
    "    return list_embedding_tuple, accuracy"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from resample.resample import get_consecutive_validation_indexes\n",
    "\n",
    "n_step_trial = 3\n",
    "val_indexes = [\n",
    "    get_consecutive_validation_indexes(\n",
    "        len(valence_labels[0]), len(AUDIO_BLOCKS), num_slice_per_trial, i, n_step_trial\n",
    "    )\n",
    "    for i in range(1, 13, n_step_trial)\n",
    "]\n",
    "print(len(val_indexes), val_indexes)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get subjects summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_feature_names_and_mean_scores(\n",
    "    dataset_dict, accuracy, marker: str, filtered_channel: str\n",
    "):\n",
    "    if marker != \"EEG\":\n",
    "        return list(dataset_dict[marker].keys()), [\n",
    "            accuracy[marker][f] for f in all_feature_name\n",
    "        ]\n",
    "\n",
    "    if len(filtered_channel) == 0:\n",
    "        all_feature_name = list(dataset_dict.keys())\n",
    "        mean_scores = [accuracy[c][Feature.ALL_SPECTRAL] for c in all_feature_name]\n",
    "    else:\n",
    "        all_feature_name = list(dataset_dict[filtered_channel].keys())\n",
    "        mean_scores = [accuracy[filtered_channel][f] for f in all_feature_name]\n",
    "\n",
    "    return all_feature_name, mean_scores\n",
    "\n",
    "\n",
    "subject_accuracy_summary = {\n",
    "    \"subject\": [],\n",
    "    \"channel\": [],\n",
    "    \"cv_mean_score\": [],\n",
    "}\n",
    "###CHANGE ME####\n",
    "method = \"CEBRA\"\n",
    "filtered_channel = \"C\"\n",
    "plot_roc = False\n",
    "all_spectral_only = True\n",
    "###############\n",
    "label_type = \"valence-arousal\"\n",
    "subject_to_embedding = {s: {label_type: []} for s in subject_list}\n",
    "\n",
    "for idx in range(len(subject_list)):\n",
    "    subj = subject_list[idx]\n",
    "    # if subj != '2007':\n",
    "    #     continue\n",
    "    print(\"decoding subject...\", subj)\n",
    "\n",
    "    v_thred, a_thred = label_thresholds[idx]\n",
    "    labels = cat_labels[idx]\n",
    "    dataset_dict = prepare_dataset(\n",
    "        marker_features[idx],\n",
    "        val_indexes,\n",
    "        labels,\n",
    "        all_spectral_only,\n",
    "    )\n",
    "\n",
    "    subject_to_embedding[subj][label_type], accuracy = decode_marker_data(\n",
    "        dataset_dict, method, filtered_channel, plot_roc\n",
    "    )\n",
    "\n",
    "    all_feature_name, mean_scores = get_feature_names_and_mean_scores(\n",
    "        dataset_dict, accuracy, marker, filtered_channel\n",
    "    )\n",
    "    subject_accuracy_summary[\"subject\"].extend(\n",
    "        [subject_list[idx]] * len(all_feature_name)\n",
    "    )\n",
    "    subject_accuracy_summary[\"channel\"].extend(all_feature_name)\n",
    "    subject_accuracy_summary[\"cv_mean_score\"].extend(mean_scores)\n",
    "\n",
    "subject_accuracy_summary = pd.DataFrame(subject_accuracy_summary)\n",
    "subject_accuracy_summary[\"subject\"] = subject_accuracy_summary[\"subject\"].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('results/models/four_cebra_c_channel_embeddings.pkl', 'wb') as handle:\n",
    "    pickle.dump(subject_to_embedding, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subject_accuracy_summary[\"channel\"] = subject_accuracy_summary[\"channel\"].astype(str)\n",
    "subject_accuracy_summary.to_csv(f'results/mean_{method}_valence_arousal_C_spectral.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = subject_accuracy_summary\n",
    "title = f\"EEG C channel - {method}\"  #\n",
    "g = sns.swarmplot(\n",
    "    data=data,\n",
    "    x=\"channel\",\n",
    "    y=\"cv_mean_score\",\n",
    "    hue='subject',\n",
    "    alpha=0.6,\n",
    "    dodge=True,\n",
    "    legend=False,\n",
    ")\n",
    "g.set_ylim((0.2, 1))\n",
    "\n",
    "df_means = data.groupby([\"channel\"])[\"cv_mean_score\"].agg(\"mean\").reset_index()\n",
    "pp = sns.pointplot(\n",
    "    x=\"channel\",\n",
    "    y=\"cv_mean_score\",\n",
    "    data=df_means,\n",
    "    dodge=0.6,\n",
    "    linestyles=\"\",\n",
    "    errorbar=None,\n",
    "    scale=2.5,\n",
    "    markers=\"_\",\n",
    "    order=[\n",
    "        \"DELTA\",\n",
    "        \"THETA\",\n",
    "        \"ALPHA\",\n",
    "        \"BETA1\",\n",
    "        \"BETA2\",\n",
    "        \"GAMMA\",\n",
    "        'ALL_SPECTRAL'\n",
    "    ],\n",
    ")\n",
    "pp.set_xticklabels(['DELTA', 'THETA', 'ALPHA', 'BETA1', 'BETA2', 'GAMMA', 'ALL_SPECTRAL'], rotation=40)\n",
    "\n",
    "g.set_title(title)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MM",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
