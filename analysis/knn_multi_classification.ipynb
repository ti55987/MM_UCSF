{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import seaborn as sns\n",
    "import cebra\n",
    "from cebra import CEBRA\n",
    "import pickle\n",
    "\n",
    "from data_utils import (\n",
    "    load_data_from_dir,\n",
    ")\n",
    "from labels import get_behavioral_labels\n",
    "from plotting import subplot_confusion_matrix\n",
    "from constants import AUDIO_BLOCKS\n",
    "from features.constants import Feature, MARKER_TO_FEATURE\n",
    "\n",
    "data_dir = \"../CleandDataV2/\"\n",
    "random.seed(33)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from feature_extraction import EEG_BANDS\n",
    "\n",
    "def get_categorical_labels(blocks, subject_data):\n",
    "    behavioral_labels = []\n",
    "\n",
    "    for b in blocks:\n",
    "        block_data = subject_data[b]\n",
    "        v_label = block_data.get_labels()\n",
    "        a_label = block_data.get_labels(\"arousal\")\n",
    "\n",
    "        labels = [\n",
    "            get_behavioral_labels(v_label[i], a_label[i]) for i in range(len(v_label))\n",
    "        ]\n",
    "        behavioral_labels.extend(labels)\n",
    "\n",
    "    return behavioral_labels\n",
    "\n",
    "\n",
    "def get_label_category(labels, label_type, v_thred, a_thred):\n",
    "    threshold = a_thred if label_type == \"arousal\" else v_thred\n",
    "    return [0 if p < threshold else 1 for p in labels]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data and process features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Read labels pkl file\n",
    "with open(\"./data/behavioral_labels.pkl\", \"rb\") as fp:\n",
    "    behavioral_labels = pickle.load(fp)\n",
    "\n",
    "valence_labels, arousal_labels, attention_labels = (\n",
    "    behavioral_labels[\"valence_labels\"],\n",
    "    behavioral_labels[\"arousal_labels\"],\n",
    "    behavioral_labels[\"attention_labels\"],\n",
    ")\n",
    "print(len(valence_labels), len(valence_labels[0]))\n",
    "\n",
    "marker = \"EEG\"\n",
    "num_slice_per_trial = 5\n",
    "\n",
    "subject_list = []\n",
    "label_thresholds = []\n",
    "idx = 0\n",
    "for d in os.listdir(data_dir):\n",
    "    dir_name = data_dir + d\n",
    "    if not os.path.isdir(dir_name):\n",
    "        continue\n",
    "\n",
    "    vl, arl = valence_labels[idx], arousal_labels[idx]\n",
    "    subject_list.append(d)\n",
    "    label_thresholds.append((np.mean(vl), np.mean(arl)))\n",
    "    idx += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read dictionary pkl file\n",
    "with open('./eeg_features2/all_features.pkl', 'rb') as fp:\n",
    "    marker_features = pickle.load(fp)\n",
    "len(marker_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IDX_MAP = {\n",
    "    \"hvha\": 0,\n",
    "    \"hvla\": 1,\n",
    "    \"nvha\": 2,\n",
    "    \"nvla\": 3,\n",
    "}\n",
    "target_names = list(IDX_MAP.keys())\n",
    "\n",
    "cat_labels = []\n",
    "for idx, (v_thred, a_thred) in enumerate(label_thresholds):\n",
    "    vc = [ 'hv' if l > v_thred else 'nv' for l in valence_labels[idx]]\n",
    "    ac = [ 'ha' if l > a_thred else 'la' for l in arousal_labels[idx]]\n",
    "    vac = [ IDX_MAP[vc[i]+ac[i]] for i in range(len(vc))]\n",
    "    cat_labels.append(vac)\n",
    "len(cat_labels)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data inspection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_subject = '2041'\n",
    "for i in range(len(subject_list)):\n",
    "    if subject_list[i] == target_subject:\n",
    "        g = sns.histplot(data=[target_names[a]for a in cat_labels[i]], stat='percent') #, color='#fffea3'\n",
    "        g.set_title(target_subject)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nrows = 5\n",
    "ncol = 8\n",
    "fig, axes = plt.subplots(\n",
    "    nrows=nrows,\n",
    "    sharey=True,\n",
    "    ncols=ncol,\n",
    "    figsize=(ncol * 3, nrows * 4),\n",
    ")\n",
    "\n",
    "for i in range(len(axes.flat)):\n",
    "    g = sns.histplot(\n",
    "        data=[target_names[a] for a in cat_labels[i]], #['ha' if 'ha' in target_names[a] else 'la' for a in cat_labels[i]]\n",
    "        stat=\"percent\",\n",
    "        ax=axes.flat[i],\n",
    "        #color=\"#fffea3\",\n",
    "    )\n",
    "    g.set_title(subject_list[i])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Training"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title One Over Rest distribution and ROC\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import RocCurveDisplay\n",
    "\n",
    "# Plots the Probability Distributions and the ROC Curves One vs Rest\n",
    "bins = [i/20 for i in range(20)] + [1]\n",
    "\n",
    "def one_hot(a, num_classes):\n",
    "  return np.squeeze(np.eye(num_classes)[a.reshape(-1)])\n",
    "\n",
    "def _plot_one_over_rest_roc(y_true, y_pred, method, label_type):\n",
    "  from sklearn.metrics import ConfusionMatrixDisplay\n",
    "  title = f'{method}:{label_type}'\n",
    "  # Compuate the confusion matrix\n",
    "  disp = ConfusionMatrixDisplay.from_predictions(\n",
    "      y_true,\n",
    "      np.argmax(y_pred, axis=1),\n",
    "      display_labels=target_names,\n",
    "      cmap=plt.cm.Blues,\n",
    "      normalize='true')\n",
    "  # Set the fixed color bar range\n",
    "  disp.im_.set_clim(0, 1)\n",
    "  disp.ax_.set_title(title)\n",
    "  \n",
    "  y_true_one_hot = one_hot(y_true, len(target_names))\n",
    "\n",
    "  plt.figure(figsize = (12, 8))\n",
    "  roc_auc_ovr = {}\n",
    "  for i in range(len(target_names)):\n",
    "      c = target_names[i]\n",
    "      # Prepares an auxiliar dataframe to help with the plots\n",
    "      df_aux = {}\n",
    "      df_aux['class'] = y_true_one_hot[:, i]\n",
    "      df_aux['prob'] = y_pred[:, i]\n",
    "\n",
    "      # Plots the probability distribution for the class and the rest\n",
    "      ax = plt.subplot(2, len(target_names), i+1)\n",
    "      sns.histplot(x = \"prob\", data = df_aux, hue = 'class', color = 'b', ax = ax, bins = bins)\n",
    "      ax.set_title(c)\n",
    "      ax.legend([f\"Class: {c}\", \"Rest\"])\n",
    "      ax.set_xlabel(f\"P(x = {c})\")\n",
    "\n",
    "      # Calculates the ROC Coordinates and plots the ROC Curves\n",
    "      ax_bottom = plt.subplot(2, len(target_names), i+5)\n",
    "      RocCurveDisplay.from_predictions(\n",
    "          df_aux['class'],\n",
    "          df_aux['prob'],\n",
    "          name=c,\n",
    "          #color=color,\n",
    "          ax=ax_bottom,\n",
    "          #plot_chance_level=(class_id == 2),\n",
    "      )\n",
    "      #tpr, fpr = get_all_roc_coordinates(df_aux['class'], df_aux['prob'])\n",
    "      #plot_roc_curve(tpr, fpr, scatter = False, ax = ax_bottom)\n",
    "      ax_bottom.set_title(f\"ROC Curve OvR for {c}\")\n",
    "\n",
    "      # Calculates the ROC AUC OvR\n",
    "      roc_auc_ovr[c] = roc_auc_score(df_aux['class'], df_aux['prob'])\n",
    "      \n",
    "      plt.tight_layout()\n",
    "  plt.title(title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import shuffle\n",
    "\n",
    "class EEGDataset():\n",
    "    def __init__(self, val_indexes_group: list):\n",
    "        self.val_indexes_group = val_indexes_group        \n",
    "        self.shuffled_val_indexes = []\n",
    "        self.shuffled_train_indexes = []\n",
    "\n",
    "    def get_shuffled_indexes(self, behavioral_labels, enabled_shuffle: bool=True):\n",
    "        for val_indexes in self.val_indexes_group:\n",
    "            train_indexes = list(set(range(len(behavioral_labels))) - set(val_indexes))\n",
    "            if enabled_shuffle:\n",
    "                self.shuffled_train_indexes.append(shuffle(train_indexes, random_state=0))\n",
    "                self.shuffled_val_indexes.append(shuffle(val_indexes, random_state=0))\n",
    "            else:\n",
    "                self.shuffled_train_indexes.append(train_indexes)\n",
    "                self.shuffled_val_indexes.append(val_indexes)                \n",
    "        \n",
    "        return self.shuffled_train_indexes, self.shuffled_val_indexes\n",
    "    \n",
    "    def train_test_split(self, data, behavioral_labels):\n",
    "        dataset = []\n",
    "        for idx, val_indexes in enumerate(self.shuffled_val_indexes):\n",
    "            train_indexes = self.shuffled_train_indexes[idx]\n",
    "            train_labels = np.array(behavioral_labels)[train_indexes]\n",
    "            train_data = data[train_indexes]\n",
    "\n",
    "            val_data = data[val_indexes]\n",
    "            val_label = np.array(behavioral_labels)[val_indexes]\n",
    "            dataset.append((train_data, train_labels, val_data, val_label))\n",
    "        \n",
    "        return dataset   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ipywidgets as widgets\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import f1_score, accuracy_score\n",
    "from model.embedding import get_embeddings\n",
    "\n",
    "# CEBRA AND PCA hyper-parameters\n",
    "OUTPUT_DIM = 8\n",
    "MAX_HIDDEN_UNITS = 256\n",
    "\n",
    "def _train_test_split(data, labels, val_indexes: list = []):\n",
    "    train_indexes = list(set(range(len(labels))) - set(val_indexes))\n",
    "    train_labels = np.array(labels)[train_indexes]\n",
    "    train_data = data[train_indexes]\n",
    "\n",
    "    val_data = data[val_indexes]\n",
    "    val_label = np.array(labels)[val_indexes]\n",
    "    return train_data, train_labels, val_data, val_label\n",
    "\n",
    "# output_dim, max_hidden_units only needed for CEBRA\n",
    "def run_knn_decoder(\n",
    "    dataset,\n",
    "    method,\n",
    "    output_dim,\n",
    "    max_hidden_units,\n",
    "):\n",
    "    from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "    y_pred, all_embeddings = [], []\n",
    "    for _, (train_data, train_labels, val_data, _) in enumerate(dataset):\n",
    "        embedding, val_embedding = get_embeddings(\n",
    "            train_data=train_data,\n",
    "            val_data=val_data,\n",
    "            train_labels=train_labels,\n",
    "            use_pca=(method == \"PCA\"),\n",
    "            out_dim=6 if method == \"PCA\" else output_dim,\n",
    "            num_hidden_units=max_hidden_units,\n",
    "            max_iterations=1000,\n",
    "        )\n",
    "        all_embeddings.append((embedding, val_embedding))\n",
    "        # 4. Train the decoder on training embedding and labels\n",
    "        # train_true_cat = get_label_category(train_labels, label_type)\n",
    "        decoder = KNeighborsClassifier(n_neighbors=4)\n",
    "        decoder.fit(embedding, np.array(train_labels))\n",
    "\n",
    "        # score = decoder.score(val_embedding, np.array(val_labels))\n",
    "        prediction = decoder.predict_proba(val_embedding)\n",
    "        y_pred.append(prediction)\n",
    "\n",
    "    return y_pred, all_embeddings\n",
    "\n",
    "\n",
    "def get_all_spectral_features(feature_to_data: dict, eeg_dataset, labels):\n",
    "    all_spetral_psd = [feature_to_data[f.name] for f in EEG_BANDS.keys()]\n",
    "    all_spetral_psd = np.hstack(all_spetral_psd)\n",
    "    return eeg_dataset.train_test_split(all_spetral_psd, labels)\n",
    "\n",
    "def prepare_dataset(\n",
    "    data,\n",
    "    eeg_dataset,\n",
    "    labels,\n",
    "    all_spectral_only: bool = False,\n",
    "):\n",
    "    dataset_dict = {k: {} for k in data.keys()}\n",
    "    for channel, feature_to_data in data.items():\n",
    "        dataset_dict[channel][Feature.ALL_SPECTRAL.name] = get_all_spectral_features(\n",
    "            feature_to_data, eeg_dataset, labels\n",
    "        )\n",
    "\n",
    "        if all_spectral_only:\n",
    "            continue\n",
    "        for f, neural_data in feature_to_data.items():\n",
    "            # Prepare the data\n",
    "            dataset_dict[channel][f] = eeg_dataset.train_test_split(neural_data, labels)\n",
    "\n",
    "\n",
    "    return dataset_dict\n",
    "\n",
    "\n",
    "def decode_marker_data(\n",
    "    dataset_dict,\n",
    "    method,\n",
    "    filtered_channel: str = \"\",\n",
    "    plot_roc: bool = False,\n",
    "):\n",
    "    accuracy = {k: {} for k in dataset_dict.keys()}\n",
    "    list_embedding_tuple = []\n",
    "    for channel, feature_to_data in dataset_dict.items():\n",
    "        if channel != filtered_channel and len(filtered_channel) > 0:\n",
    "            continue\n",
    "\n",
    "        for f, dataset in feature_to_data.items():\n",
    "            val_true_cat = [\n",
    "                val_labels for _, (_, _, _, val_labels) in enumerate(dataset)\n",
    "            ]\n",
    "\n",
    "            val_pred_cat, all_embeddings = run_knn_decoder(\n",
    "                dataset,\n",
    "                method,\n",
    "                OUTPUT_DIM,\n",
    "                MAX_HIDDEN_UNITS,\n",
    "            )\n",
    "            ac_scores = [\n",
    "                accuracy_score(\n",
    "                    y_pred=np.argmax(val_pred_cat[i], axis=1), y_true=val_true_cat[i]\n",
    "                )\n",
    "                for i in range(len(val_pred_cat))\n",
    "            ]\n",
    "            accuracy[channel][f] = np.mean(ac_scores)\n",
    "\n",
    "            max_score_index = np.array(ac_scores).argmax(axis=0)\n",
    "            mean_acc = round(np.mean(ac_scores), 2) \n",
    "            max_acc = round(ac_scores[max_score_index], 2)\n",
    "            list_embedding_tuple.append(\n",
    "                (\n",
    "                    f\"CV Acc Max: {max_acc} Avg:{mean_acc}\",\n",
    "                    max_score_index,\n",
    "                    all_embeddings[max_score_index],\n",
    "                    (dataset[max_score_index][1], dataset[max_score_index][3]),\n",
    "                )\n",
    "            )\n",
    "\n",
    "            if plot_roc:\n",
    "                y_pred, y_true = [], []\n",
    "                for i in range(len(val_true_cat)):\n",
    "                    y_true.extend(val_true_cat[i])\n",
    "                    y_pred.extend(val_pred_cat[i])\n",
    "\n",
    "                _plot_one_over_rest_roc(\n",
    "                    np.array(y_true), np.array(y_pred), channel, f,\n",
    "                )            \n",
    "\n",
    "    return list_embedding_tuple, accuracy"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from resample.resample import get_consecutive_validation_indexes\n",
    "\n",
    "n_step_trial = 3\n",
    "val_indexes = [\n",
    "    get_consecutive_validation_indexes(\n",
    "        len(valence_labels[0]), len(AUDIO_BLOCKS), num_slice_per_trial, i, n_step_trial\n",
    "    )\n",
    "    for i in range(1, 13, n_step_trial)\n",
    "]\n",
    "print(len(val_indexes), val_indexes)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get subjects summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_feature_names_and_mean_scores(\n",
    "    dataset_dict, accuracy, marker: str, filtered_channel: str\n",
    "):\n",
    "    if marker != \"EEG\":\n",
    "        return list(dataset_dict[marker].keys()), [\n",
    "            accuracy[marker][f] for f in all_feature_name\n",
    "        ]\n",
    "\n",
    "    if len(filtered_channel) == 0:\n",
    "        all_feature_name = list(dataset_dict.keys())\n",
    "        mean_scores = [accuracy[c][Feature.ALL_SPECTRAL] for c in all_feature_name]\n",
    "    else:\n",
    "        all_feature_name = list(dataset_dict[filtered_channel].keys())\n",
    "        mean_scores = [accuracy[filtered_channel][f] for f in all_feature_name]\n",
    "\n",
    "    return all_feature_name, mean_scores\n",
    "\n",
    "\n",
    "subject_accuracy_summary = {\n",
    "    \"subject\": [],\n",
    "    \"channel\": [],\n",
    "    \"cv_mean_score\": [],\n",
    "}\n",
    "###CHANGE ME####\n",
    "method = \"CEBRA\"\n",
    "filtered_channel = \"C\"\n",
    "plot_roc = False\n",
    "all_spectral_only = True\n",
    "###############\n",
    "label_type = \"valence-arousal\"\n",
    "test_subject_list =  subject_list #['2001', '2005', '2031'] #\n",
    "subject_to_embedding = {s: {label_type: []} for s in test_subject_list}\n",
    "subject_to_shuffled_indexes = {s: {label_type: []} for s in test_subject_list}\n",
    "\n",
    "for idx in range(len(test_subject_list)):\n",
    "    subj = test_subject_list[idx]\n",
    "    \n",
    "    print(\"decoding subject...\", subj)\n",
    "\n",
    "    v_thred, a_thred = label_thresholds[idx]\n",
    "    labels = cat_labels[idx]\n",
    "    dataset =  EEGDataset(val_indexes)\n",
    "    subject_to_shuffled_indexes[subj][label_type] = dataset.get_shuffled_indexes(labels, False)\n",
    "\n",
    "    dataset_dict = prepare_dataset(\n",
    "        marker_features[idx],\n",
    "        dataset,\n",
    "        labels,\n",
    "        all_spectral_only,\n",
    "    )\n",
    "\n",
    "    subject_to_embedding[subj][label_type], accuracy = decode_marker_data(\n",
    "        dataset_dict, method, filtered_channel, plot_roc\n",
    "    )\n",
    "    \n",
    "    all_feature_name, mean_scores = get_feature_names_and_mean_scores(\n",
    "        dataset_dict, accuracy, marker, filtered_channel\n",
    "    )\n",
    "    subject_accuracy_summary[\"subject\"].extend(\n",
    "        [test_subject_list[idx]] * len(all_feature_name)\n",
    "    )\n",
    "    subject_accuracy_summary[\"channel\"].extend(all_feature_name)\n",
    "    subject_accuracy_summary[\"cv_mean_score\"].extend(mean_scores)\n",
    "\n",
    "subject_accuracy_summary = pd.DataFrame(subject_accuracy_summary)\n",
    "subject_accuracy_summary[\"subject\"] = subject_accuracy_summary[\"subject\"].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "identifier = 'no_shuffled_test_1000iter_valence_arsoual_c_all_spectral'\n",
    "with open(f'results/models/{identifier}_embeddings.pkl', 'wb') as handle:\n",
    "    pickle.dump(subject_to_embedding, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subject_accuracy_summary[\"channel\"] = subject_accuracy_summary[\"channel\"].astype(str)\n",
    "subject_accuracy_summary.to_csv(f'results/{method}_valence_arousal_C_spectral.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'results/models/{identifier}_indexes.pkl', 'wb') as handle:\n",
    "    pickle.dump(subject_to_shuffled_indexes, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = subject_accuracy_summary\n",
    "title = f\"EEG C channel - {method}\"  #\n",
    "g = sns.swarmplot(\n",
    "    data=data,\n",
    "    x=\"channel\",\n",
    "    y=\"cv_mean_score\",\n",
    "    #hue='subject',\n",
    "    alpha=0.6,\n",
    "    dodge=True,\n",
    "    legend=False,\n",
    ")\n",
    "g.set_ylim((0.2, 1))\n",
    "\n",
    "df_means = data.groupby([\"channel\"])[\"cv_mean_score\"].agg(\"mean\").reset_index()\n",
    "pp = sns.pointplot(\n",
    "    x=\"channel\",\n",
    "    y=\"cv_mean_score\",\n",
    "    data=df_means,\n",
    "    dodge=0.6,\n",
    "    linestyles=\"\",\n",
    "    errorbar=None,\n",
    "    scale=2.5,\n",
    "    markers=\"_\",\n",
    "    # order=[\n",
    "    #     \"DELTA\",\n",
    "    #     \"THETA\",\n",
    "    #     \"ALPHA\",\n",
    "    #     \"BETA1\",\n",
    "    #     \"BETA2\",\n",
    "    #     \"GAMMA\",\n",
    "    #     'ALL_SPECTRAL'\n",
    "    # ],\n",
    ")\n",
    "#pp.set_xticklabels(['DELTA', 'THETA', 'ALPHA', 'BETA1', 'BETA2', 'GAMMA', 'ALL_SPECTRAL'], rotation=40)\n",
    "\n",
    "g.set_title(title)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MM",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
