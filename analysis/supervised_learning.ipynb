{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d653b6bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Basic imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from dataframe.csv_utils import (\n",
    "    load_data_from_csv,\n",
    "    get_labels_from_result,\n",
    "    get_features_from_result,\n",
    ")\n",
    "\n",
    "from labels import get_tranformed_labels, binary_label, print_label_count, get_categorical_labels\n",
    "\n",
    "# For machine learning modeling\n",
    "from sklearn.model_selection import GroupKFold\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import shap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6f6f490",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    load features from csv\n",
    "\"\"\"\n",
    "\n",
    "dir_name = \"extracted_features_v1\"\n",
    "result = load_data_from_csv(dir_name)\n",
    "\n",
    "all_label_array, label_list = get_labels_from_result(result)\n",
    "all_feature_array, feature_names = get_features_from_result(result, False)\n",
    "all_feature_array = all_feature_array.drop([\"index\"], axis=1)\n",
    "feature_names = all_feature_array.columns\n",
    "print(all_feature_array.shape, len(feature_names), len(label_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95037fa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "transformed = get_tranformed_labels(all_label_array)\n",
    "label_list = get_categorical_labels(all_label_array, valence_threshold=0.6)\n",
    "valence_lables = binary_label(all_label_array['valence'], 0.6)\n",
    "is_multi = True\n",
    "\n",
    "#label_list = valence_lables\n",
    "print_label_count(label_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6357fe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "colors = [\"c\", \"y\", \"m\", \"r\"]\n",
    "\n",
    "NUM_LABEL_PER_SUBJECT = 130\n",
    "accuracy = []\n",
    "gkf = GroupKFold()\n",
    "label_array = np.array(label_list)\n",
    "groups_list = [[i/NUM_LABEL_PER_SUBJECT] for i, j in enumerate(label_list)]\n",
    "group_array = np.hstack(groups_list)\n",
    "\n",
    "# normalize\n",
    "scaler = StandardScaler()\n",
    "normalized_all_feature_array = pd.DataFrame(\n",
    "    scaler.fit_transform(all_feature_array), columns=all_feature_array.columns\n",
    ")\n",
    "\n",
    "list_shap_values = list()\n",
    "list_test_sets = list()\n",
    "for train_index, val_index in gkf.split(\n",
    "    normalized_all_feature_array, label_array, groups=group_array\n",
    "):\n",
    "    train_features, train_labels = (\n",
    "        normalized_all_feature_array.iloc[train_index],\n",
    "        label_array[train_index],\n",
    "    )\n",
    "    val_features, val_labels = (\n",
    "        normalized_all_feature_array.iloc[val_index],\n",
    "        label_array[val_index],\n",
    "    )\n",
    "\n",
    "    # create model instance\n",
    "    model = XGBClassifier(n_estimators=2)\n",
    "    # fit model\n",
    "    model.fit(train_features, train_labels)\n",
    "    # Print accuracy.\n",
    "    acc = model.score(val_features, val_labels)\n",
    "    print(\"Accuracy: %.2f%%\" % (acc * 100.0))\n",
    "    accuracy.append(acc)\n",
    "\n",
    "    # Summary plot\n",
    "    shap_values = shap.TreeExplainer(model).shap_values(val_features)\n",
    "     #for each iteration we save the test_set index and the shap_values\n",
    "    list_shap_values.append(shap_values)\n",
    "    list_test_sets.append(val_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74d71c52",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(accuracy)\n",
    "print(np.mean(accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "691a7bca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# combining results from all iterations\n",
    "test_set = list_test_sets[0]\n",
    "shap_values = np.array(list_shap_values[0])\n",
    "for i in range(1,len(list_test_sets)):\n",
    "    test_set = np.concatenate((test_set,list_test_sets[i]),axis=0)\n",
    "    shap_values = np.concatenate((shap_values,np.array(list_shap_values[i])),axis=1) if is_multi else np.concatenate((shap_values,np.array(list_shap_values[i])),axis=0) # for binary\n",
    "\n",
    "# bringing back variable names    \n",
    "X_test = pd.DataFrame(normalized_all_feature_array.iloc[test_set],columns=all_feature_array.columns)\n",
    "\n",
    "# creating explanation plot for the whole experiment, the first dimension from shap_values indicate the class we are predicting (0=0, 1=1)\n",
    "if is_multi:\n",
    "    shap.summary_plot(shap_values[1], X_test)  # for multi i = class_num\n",
    "else:\n",
    "    shap.summary_plot(shap_values, X_test)  # for binary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4beb1a4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_utils import (\n",
    "    load_data_from_dir,\n",
    "    concatenate_all_data,\n",
    ")\n",
    "\n",
    "def get_raw_signal(dir_names, markers):\n",
    "    dir_to_data = {}\n",
    "    for dir_name in dir_names:\n",
    "        all_data = load_data_from_dir(dir_name)\n",
    "        dir_to_data[dir_name] = all_data\n",
    "\n",
    "\n",
    "    \"\"\" \n",
    "        concatenate raw signal (x)\n",
    "    \"\"\"\n",
    "    data_list = []\n",
    "    block_names = list(dir_to_data[dir_names[0]].keys())\n",
    "    block_names.sort()\n",
    "\n",
    "    for m in markers:  # EOG.__name__, , EMG.__name__, EGG.__name__\n",
    "        all_participants_data, condition_to_labels = concatenate_all_data(dir_to_data, m)\n",
    "        all_epoch_data = np.swapaxes(\n",
    "            all_participants_data, 0, -1\n",
    "        )  # (num_channels, num_data_points, num_epochs) => (num_epochs, num_data_points, num_channels)\n",
    "\n",
    "        data_list.append(all_epoch_data)\n",
    "\n",
    "    return np.concatenate(data_list, axis=2), condition_to_labels\n",
    "\n",
    "\n",
    "\n",
    "ALL_DIRS = [\n",
    "    \"../CleandDataV1/2017\",\n",
    "    \"../CleandDataV1/2018\",\n",
    "]\n",
    "\n",
    "data_array, condition_to_labels = get_raw_signal(ALL_DIRS, ['EEG'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4b06a40",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import utils as np_utils\n",
    "from models import train_with_cnn\n",
    "\n",
    "\"\"\" \n",
    "    prepare labels (y)\n",
    "\"\"\"\n",
    "# to one-hot encoding vector\n",
    "# label_array = np_utils.to_categorical(\n",
    "#     label_list, num_classes=4\n",
    "# )  # nvla, nvha, hvla, hvha\n",
    "label_list = binary_label(condition_to_labels['valence'])\n",
    "label_array = np.array(label_list)\n",
    "\n",
    "groups_list = [[i/NUM_LABEL_PER_SUBJECT] for i, j in enumerate(label_list)]\n",
    "group_array = np.hstack(groups_list)\n",
    "\n",
    "print(data_array.shape, label_array.shape, group_array.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8b16a05",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" \n",
    "    with CNN\n",
    "\"\"\"\n",
    "num_channel = data_array.shape[2]\n",
    "accuracy = train_with_cnn(12288, num_channel, data_array, label_array, group_array)\n",
    "print(accuracy)\n",
    "print(np.mean(accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f5b1f5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" \n",
    "    with logistic regression\n",
    "\"\"\"\n",
    "# from models import train_with_logistic\n",
    "\n",
    "# label_name = \"attention\"\n",
    "# best_model = train_with_logistic(all_features, label_name, condition_to_labels, group_array)\n",
    "# name_to_transformed = get_tranformed_labels(condition_to_labels)\n",
    "\n",
    "# # assume bigger coefficents has more contribution to the model\n",
    "# # but have to be sure that the features has THE SAME SCALE otherwise this assumption is not correct.\n",
    "# importance = best_model[\"classifier\"].coef_[0]\n",
    "\n",
    "# feat_importances = pd.Series(importance, index=get_feature_names(importance))\n",
    "# feat_importances.nlargest(10).plot(\n",
    "#     kind=\"barh\", title=f\"{label_name} Feature Importance\"\n",
    "# )\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MM",
   "language": "python",
   "name": "mm"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
