{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d653b6bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tpan/miniconda3/envs/MM/lib/python3.8/site-packages/xgboost/compat.py:36: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  from pandas import MultiIndex, Int64Index\n",
      "2023-03-02 19:57:36.005261: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "# Basic imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from dataframe.csv_utils import (\n",
    "    load_data_from_csv,\n",
    "    get_labels_from_result,\n",
    "    get_features_from_result,\n",
    ")\n",
    "\n",
    "from labels import (\n",
    "    get_tranformed_labels,\n",
    "    binary_label,\n",
    "    print_label_count,\n",
    "    get_categorical_labels,\n",
    ")\n",
    "\n",
    "# For machine learning modeling\n",
    "from sklearn.model_selection import GroupKFold\n",
    "import xgboost as xgb\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import shap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f6f6f490",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2600, 128) 128 2600\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "    load features from csv\n",
    "\"\"\"\n",
    "\n",
    "dir_name = \"eeg_features\"\n",
    "result = load_data_from_csv(dir_name)\n",
    "\n",
    "all_label_array, label_list = get_labels_from_result(result)\n",
    "all_feature_array, feature_names = get_features_from_result(\n",
    "    result, [\"Subject\", \"Valence\", \"Arousal\", \"Attention\"], False\n",
    ")\n",
    "# all_feature_array = all_feature_array.drop([\"index\"], axis=1)\n",
    "\n",
    "filter_pattern = \".*(?<!BETA2)$\"\n",
    "only_specific_feature = \".*GAMMA$\"\n",
    "all_feature_array = all_feature_array.filter(regex=only_specific_feature)\n",
    "feature_names = all_feature_array.columns\n",
    "print(all_feature_array.shape, len(feature_names), len(label_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b4b61b20",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A1 _GAMMA</th>\n",
       "      <th>A2_GAMMA</th>\n",
       "      <th>A3_GAMMA</th>\n",
       "      <th>A4_GAMMA</th>\n",
       "      <th>A5_GAMMA</th>\n",
       "      <th>A6_GAMMA</th>\n",
       "      <th>A7_GAMMA</th>\n",
       "      <th>A8_GAMMA</th>\n",
       "      <th>A9_GAMMA</th>\n",
       "      <th>A10_GAMMA</th>\n",
       "      <th>...</th>\n",
       "      <th>D23_GAMMA</th>\n",
       "      <th>D24_GAMMA</th>\n",
       "      <th>D25_GAMMA</th>\n",
       "      <th>D26_GAMMA</th>\n",
       "      <th>D27_GAMMA</th>\n",
       "      <th>D28_GAMMA</th>\n",
       "      <th>D29_GAMMA</th>\n",
       "      <th>D30_GAMMA</th>\n",
       "      <th>D31_GAMMA</th>\n",
       "      <th>D32_GAMMA</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.479090</td>\n",
       "      <td>-0.311888</td>\n",
       "      <td>-0.492659</td>\n",
       "      <td>-0.347831</td>\n",
       "      <td>-0.116001</td>\n",
       "      <td>-0.291658</td>\n",
       "      <td>-0.126837</td>\n",
       "      <td>-0.478507</td>\n",
       "      <td>-0.538260</td>\n",
       "      <td>-0.564768</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.239421</td>\n",
       "      <td>-0.304126</td>\n",
       "      <td>-0.158946</td>\n",
       "      <td>-0.131946</td>\n",
       "      <td>-0.000331</td>\n",
       "      <td>-0.150412</td>\n",
       "      <td>-0.145069</td>\n",
       "      <td>-0.367127</td>\n",
       "      <td>-0.299080</td>\n",
       "      <td>-0.237976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.505647</td>\n",
       "      <td>-0.286600</td>\n",
       "      <td>-0.428497</td>\n",
       "      <td>-0.299020</td>\n",
       "      <td>-0.128029</td>\n",
       "      <td>-0.296326</td>\n",
       "      <td>-0.117517</td>\n",
       "      <td>-0.429467</td>\n",
       "      <td>-0.540010</td>\n",
       "      <td>-0.558105</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.221309</td>\n",
       "      <td>-0.292674</td>\n",
       "      <td>-0.144726</td>\n",
       "      <td>-0.114893</td>\n",
       "      <td>-0.060822</td>\n",
       "      <td>-0.191325</td>\n",
       "      <td>-0.128049</td>\n",
       "      <td>-0.335660</td>\n",
       "      <td>-0.252869</td>\n",
       "      <td>-0.202727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.401754</td>\n",
       "      <td>-0.221094</td>\n",
       "      <td>-0.426138</td>\n",
       "      <td>-0.322846</td>\n",
       "      <td>-0.102756</td>\n",
       "      <td>-0.291172</td>\n",
       "      <td>-0.085032</td>\n",
       "      <td>-0.326415</td>\n",
       "      <td>-0.354534</td>\n",
       "      <td>-0.413780</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.224512</td>\n",
       "      <td>-0.292734</td>\n",
       "      <td>-0.149627</td>\n",
       "      <td>-0.123155</td>\n",
       "      <td>-0.116123</td>\n",
       "      <td>-0.226912</td>\n",
       "      <td>-0.096278</td>\n",
       "      <td>-0.293091</td>\n",
       "      <td>-0.196464</td>\n",
       "      <td>-0.144948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.357187</td>\n",
       "      <td>-0.182894</td>\n",
       "      <td>-0.378165</td>\n",
       "      <td>-0.267862</td>\n",
       "      <td>-0.058537</td>\n",
       "      <td>-0.217110</td>\n",
       "      <td>0.258177</td>\n",
       "      <td>-0.256747</td>\n",
       "      <td>-0.321044</td>\n",
       "      <td>-0.427033</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.187362</td>\n",
       "      <td>-0.037455</td>\n",
       "      <td>0.389004</td>\n",
       "      <td>-0.092358</td>\n",
       "      <td>-0.045344</td>\n",
       "      <td>-0.211147</td>\n",
       "      <td>1.028505</td>\n",
       "      <td>0.160161</td>\n",
       "      <td>-0.174986</td>\n",
       "      <td>-0.006723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.377578</td>\n",
       "      <td>-0.165979</td>\n",
       "      <td>-0.386596</td>\n",
       "      <td>-0.297554</td>\n",
       "      <td>-0.095457</td>\n",
       "      <td>-0.276595</td>\n",
       "      <td>-0.067011</td>\n",
       "      <td>-0.327632</td>\n",
       "      <td>-0.315442</td>\n",
       "      <td>-0.360763</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.210668</td>\n",
       "      <td>-0.281156</td>\n",
       "      <td>-0.131378</td>\n",
       "      <td>-0.101341</td>\n",
       "      <td>-0.107014</td>\n",
       "      <td>-0.218165</td>\n",
       "      <td>-0.073542</td>\n",
       "      <td>-0.277478</td>\n",
       "      <td>-0.164600</td>\n",
       "      <td>-0.100293</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 128 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   A1 _GAMMA  A2_GAMMA  A3_GAMMA  A4_GAMMA  A5_GAMMA  A6_GAMMA  A7_GAMMA  \\\n",
       "0  -0.479090 -0.311888 -0.492659 -0.347831 -0.116001 -0.291658 -0.126837   \n",
       "1  -0.505647 -0.286600 -0.428497 -0.299020 -0.128029 -0.296326 -0.117517   \n",
       "2  -0.401754 -0.221094 -0.426138 -0.322846 -0.102756 -0.291172 -0.085032   \n",
       "3  -0.357187 -0.182894 -0.378165 -0.267862 -0.058537 -0.217110  0.258177   \n",
       "4  -0.377578 -0.165979 -0.386596 -0.297554 -0.095457 -0.276595 -0.067011   \n",
       "\n",
       "   A8_GAMMA  A9_GAMMA  A10_GAMMA  ...  D23_GAMMA  D24_GAMMA  D25_GAMMA  \\\n",
       "0 -0.478507 -0.538260  -0.564768  ...  -0.239421  -0.304126  -0.158946   \n",
       "1 -0.429467 -0.540010  -0.558105  ...  -0.221309  -0.292674  -0.144726   \n",
       "2 -0.326415 -0.354534  -0.413780  ...  -0.224512  -0.292734  -0.149627   \n",
       "3 -0.256747 -0.321044  -0.427033  ...  -0.187362  -0.037455   0.389004   \n",
       "4 -0.327632 -0.315442  -0.360763  ...  -0.210668  -0.281156  -0.131378   \n",
       "\n",
       "   D26_GAMMA  D27_GAMMA  D28_GAMMA  D29_GAMMA  D30_GAMMA  D31_GAMMA  D32_GAMMA  \n",
       "0  -0.131946  -0.000331  -0.150412  -0.145069  -0.367127  -0.299080  -0.237976  \n",
       "1  -0.114893  -0.060822  -0.191325  -0.128049  -0.335660  -0.252869  -0.202727  \n",
       "2  -0.123155  -0.116123  -0.226912  -0.096278  -0.293091  -0.196464  -0.144948  \n",
       "3  -0.092358  -0.045344  -0.211147   1.028505   0.160161  -0.174986  -0.006723  \n",
       "4  -0.101341  -0.107014  -0.218165  -0.073542  -0.277478  -0.164600  -0.100293  \n",
       "\n",
       "[5 rows x 128 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA  # Principal Component Analysis\n",
    "\n",
    "scaler = StandardScaler()\n",
    "# Scale each column in numer\n",
    "normalized_all_feature_array = pd.DataFrame(\n",
    "    scaler.fit_transform(all_feature_array), columns=all_feature_array.columns\n",
    ")\n",
    "\n",
    "\n",
    "# reduced_data = PCA(n_components=0.95).fit_transform(normalized_all_feature_array)\n",
    "# normalized_all_feature_array = pd.DataFrame(reduced_data)\n",
    "normalized_all_feature_array.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "95037fa7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 label: 188, 1 label: 2412\n",
      "0 label: 1370, 1 label: 1230\n",
      "0 label: 185, 1 label: 2415\n",
      "0 label: 1208, 1 label: 1392\n",
      "{0: 1208, 1: 1392, 2: 0, 3: 0}\n"
     ]
    }
   ],
   "source": [
    "transformed = get_tranformed_labels(all_label_array)\n",
    "label_list = get_categorical_labels(all_label_array, valence_threshold=0.6)\n",
    "valence_lables = binary_label(all_label_array[\"valence\"], 0.65)\n",
    "is_multi = False\n",
    "\n",
    "label_list = valence_lables\n",
    "print_label_count(label_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c63db179",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     eta  best_rmse\n",
      "0  0.001   0.499544\n",
      "1  0.010   0.495831\n",
      "2  0.100   0.472759\n",
      "3  0.200   0.461789\n",
      "4  0.300   0.454020\n",
      "5  0.400   0.454511\n",
      "6  0.500   0.456266\n"
     ]
    }
   ],
   "source": [
    "housing_dmatrix = xgb.DMatrix(data=normalized_all_feature_array, label=np.array(label_list))\n",
    "\n",
    "# Creata the parameter dictionary for each tree: params\n",
    "params = {\"objective\":\"reg:squarederror\", \"max_depth\":3}\n",
    "\n",
    "# Create list of eta values and empty list to store final round rmse per xgboost model\n",
    "eta_vals = [0.001, 0.01, 0.1, 0.2, 0.3, 0.4, 0.5]\n",
    "best_rmse = []\n",
    "\n",
    "# Systematicallyvary the eta\n",
    "for curr_val in eta_vals:\n",
    "    params['eta'] = curr_val\n",
    "    \n",
    "    # Perform cross-validation: cv_results\n",
    "    cv_results = xgb.cv(dtrain=housing_dmatrix, params=params, nfold=3,\n",
    "                        early_stopping_rounds=5, num_boost_round=10, metrics='rmse', seed=123, \n",
    "                       as_pandas=True)\n",
    "    \n",
    "    # Append the final round rmse to best_rmse\n",
    "    best_rmse.append(cv_results['test-rmse-mean'].tail().values[-1])\n",
    "    \n",
    "# Print the result DataFrame\n",
    "print(pd.DataFrame(list(zip(eta_vals, best_rmse)), columns=['eta', 'best_rmse']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9bec1ea4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   max_depth  best_rmse\n",
      "0          2   0.467203\n",
      "1          3   0.458538\n",
      "2          5   0.444916\n",
      "3         10   0.448686\n",
      "4         20   0.458807\n"
     ]
    }
   ],
   "source": [
    "# Create the parameter dictionary\n",
    "params = {\"objective\":\"reg:squarederror\", \"eta\": 0.3}\n",
    "\n",
    "# Create list of max_depth values\n",
    "max_depths = [2,3, 5, 10, 20]\n",
    "best_rmse = []\n",
    "\n",
    "for curr_val in max_depths:\n",
    "    params['max_depth'] = curr_val\n",
    "    \n",
    "    # Perform cross-validation\n",
    "    cv_results = xgb.cv(dtrain=housing_dmatrix, params=params, nfold=2, \n",
    "                       early_stopping_rounds=5, num_boost_round=10, metrics='rmse', seed=123,\n",
    "                        as_pandas=True)\n",
    "    \n",
    "    # Append the final round rmse to best_rmse\n",
    "    best_rmse.append(cv_results['test-rmse-mean'].tail().values[-1])\n",
    "    \n",
    "# Print the result DataFrame\n",
    "print(pd.DataFrame(list(zip(max_depths, best_rmse)), columns=['max_depth', 'best_rmse']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1f4a2010",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   colsample_bytree  best_rmse\n",
      "0               0.3   0.451638\n",
      "1               0.5   0.444846\n",
      "2               0.8   0.444688\n",
      "3               1.0   0.444916\n"
     ]
    }
   ],
   "source": [
    "# Creata the parameter dictionary for each tree: params\n",
    "params = {\"objective\":\"reg:squarederror\", \"max_depth\":5, \"eta\": 0.3}\n",
    "# Create list of hyperparameter values: colsample_bytree_vals\n",
    "colsample_bytree_vals = [0.3, 0.5, 0.8, 1]\n",
    "best_rmse = []\n",
    "\n",
    "# Systematically vary the hyperparameter value \n",
    "for curr_val in colsample_bytree_vals:\n",
    "    params['colsample_bytree'] = curr_val\n",
    "    \n",
    "    # Perform cross-validation\n",
    "    cv_results = xgb.cv(dtrain=housing_dmatrix, params=params, nfold=2,\n",
    "                 num_boost_round=10, early_stopping_rounds=5,\n",
    "                 metrics=\"rmse\", as_pandas=True, seed=123)\n",
    "    \n",
    "    # Append the final round rmse to best_rmse\n",
    "    best_rmse.append(cv_results[\"test-rmse-mean\"].tail().values[-1])\n",
    "\n",
    "# Print the resultant DataFrame\n",
    "print(pd.DataFrame(list(zip(colsample_bytree_vals, best_rmse)), \n",
    "                   columns=[\"colsample_bytree\",\"best_rmse\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "71a5f51d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 6 candidates, totalling 30 fits\n",
      "[CV] END .colsample_bytree=0.3, max_depth=2, n_estimators=50; total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .colsample_bytree=0.3, max_depth=2, n_estimators=50; total time=   0.1s\n",
      "[CV] END .colsample_bytree=0.3, max_depth=2, n_estimators=50; total time=   0.1s\n",
      "[CV] END .colsample_bytree=0.3, max_depth=2, n_estimators=50; total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .colsample_bytree=0.3, max_depth=2, n_estimators=50; total time=   0.1s\n",
      "[CV] END .colsample_bytree=0.3, max_depth=5, n_estimators=50; total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .colsample_bytree=0.3, max_depth=5, n_estimators=50; total time=   0.2s\n",
      "[CV] END .colsample_bytree=0.3, max_depth=5, n_estimators=50; total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .colsample_bytree=0.3, max_depth=5, n_estimators=50; total time=   0.2s\n",
      "[CV] END .colsample_bytree=0.3, max_depth=5, n_estimators=50; total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .colsample_bytree=0.5, max_depth=2, n_estimators=50; total time=   0.1s\n",
      "[CV] END .colsample_bytree=0.5, max_depth=2, n_estimators=50; total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .colsample_bytree=0.5, max_depth=2, n_estimators=50; total time=   0.1s\n",
      "[CV] END .colsample_bytree=0.5, max_depth=2, n_estimators=50; total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .colsample_bytree=0.5, max_depth=2, n_estimators=50; total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .colsample_bytree=0.5, max_depth=5, n_estimators=50; total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .colsample_bytree=0.5, max_depth=5, n_estimators=50; total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .colsample_bytree=0.5, max_depth=5, n_estimators=50; total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .colsample_bytree=0.5, max_depth=5, n_estimators=50; total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .colsample_bytree=0.5, max_depth=5, n_estimators=50; total time=   0.2s\n",
      "[CV] END .colsample_bytree=0.7, max_depth=2, n_estimators=50; total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .colsample_bytree=0.7, max_depth=2, n_estimators=50; total time=   0.1s\n",
      "[CV] END .colsample_bytree=0.7, max_depth=2, n_estimators=50; total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .colsample_bytree=0.7, max_depth=2, n_estimators=50; total time=   0.1s\n",
      "[CV] END .colsample_bytree=0.7, max_depth=2, n_estimators=50; total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .colsample_bytree=0.7, max_depth=5, n_estimators=50; total time=   0.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .colsample_bytree=0.7, max_depth=5, n_estimators=50; total time=   0.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .colsample_bytree=0.7, max_depth=5, n_estimators=50; total time=   0.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .colsample_bytree=0.7, max_depth=5, n_estimators=50; total time=   0.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .colsample_bytree=0.7, max_depth=5, n_estimators=50; total time=   0.3s\n",
      "Best parameters found:  {'colsample_bytree': 0.5, 'max_depth': 2, 'n_estimators': 50}\n",
      "0.4638461538461539\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Create the parameter grid: gbm_param_grid\n",
    "gbm_param_grid = {\n",
    "    'colsample_bytree': [0.3, 0.5, 0.7],\n",
    "    'n_estimators': [50],\n",
    "    'max_depth': [2, 5]\n",
    "}\n",
    "eval_metric = [\"auc\",\"error\"]\n",
    "# Instantiate the regressor: gbm\n",
    "gbm = xgb.XGBClassifier(use_label_encoder=False, objective= 'binary:logistic',eval_metric=eval_metric)\n",
    "\n",
    "# Perform grid search: grid_mse\n",
    "grid_mse = GridSearchCV(param_grid=gbm_param_grid, estimator=gbm, \n",
    "                        scoring='accuracy', cv=5, verbose=2)\n",
    "\n",
    "# Fit grid_mse to the data\n",
    "grid_mse.fit(normalized_all_feature_array, np.array(label_list))\n",
    "\n",
    "# Print the best parameters and lowest RMSE\n",
    "print(\"Best parameters found: \", grid_mse.best_params_)\n",
    "#print(\"Lowest RMSE found: \", np.sqrt(np.abs(grid_mse.best_score_))) neg_mean_squared_error\n",
    "print(grid_mse.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6357fe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "colors = [\"c\", \"y\", \"m\", \"r\"]\n",
    "\n",
    "NUM_LABEL_PER_SUBJECT = 130\n",
    "accuracy = []\n",
    "gkf = GroupKFold()\n",
    "label_array = np.array(label_list)\n",
    "groups_list = [[i / NUM_LABEL_PER_SUBJECT] for i, j in enumerate(label_list)]\n",
    "group_array = np.hstack(groups_list)\n",
    "\n",
    "list_shap_values = list()\n",
    "list_test_sets = list()\n",
    "for train_index, val_index in gkf.split(\n",
    "    normalized_all_feature_array, label_array, groups=group_array\n",
    "):\n",
    "    train_features, train_labels = (\n",
    "        normalized_all_feature_array.iloc[train_index],\n",
    "        label_array[train_index],\n",
    "    )\n",
    "    val_features, val_labels = (\n",
    "        normalized_all_feature_array.iloc[val_index],\n",
    "        label_array[val_index],\n",
    "    )\n",
    "\n",
    "    # create model instance\n",
    "    model = XGBClassifier(n_estimators=2)\n",
    "    # fit model\n",
    "    model.fit(train_features, train_labels)\n",
    "    # Print accuracy.\n",
    "    acc = model.score(val_features, val_labels)\n",
    "    print(\"Accuracy: %.2f%%\" % (acc * 100.0))\n",
    "    accuracy.append(acc)\n",
    "\n",
    "    # Summary plot\n",
    "    shap_values = shap.TreeExplainer(model).shap_values(val_features)\n",
    "    # for each iteration we save the test_set index and the shap_values\n",
    "    list_shap_values.append(shap_values)\n",
    "    list_test_sets.append(val_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74d71c52",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(accuracy)\n",
    "print(np.mean(accuracy))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "691a7bca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# combining results from all iterations\n",
    "test_set = list_test_sets[0]\n",
    "shap_values = np.array(list_shap_values[0])\n",
    "for i in range(1, len(list_test_sets)):\n",
    "    test_set = np.concatenate((test_set, list_test_sets[i]), axis=0)\n",
    "    shap_values = (\n",
    "        np.concatenate((shap_values, np.array(list_shap_values[i])), axis=1)\n",
    "        if is_multi\n",
    "        else np.concatenate((shap_values, np.array(list_shap_values[i])), axis=0)\n",
    "    )  # for binary\n",
    "\n",
    "# bringing back variable names\n",
    "X_test = pd.DataFrame(\n",
    "    normalized_all_feature_array.iloc[test_set], columns=feature_names\n",
    ")\n",
    "\n",
    "# creating explanation plot for the whole experiment, the first dimension from shap_values indicate the class we are predicting (0=0, 1=1)\n",
    "if is_multi:\n",
    "    shap.summary_plot(shap_values[1], X_test)  # for multi i = class_num\n",
    "else:\n",
    "    shap.summary_plot(shap_values, X_test)  # for binary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4beb1a4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_utils import (\n",
    "    load_data_from_dir,\n",
    "    concatenate_all_data,\n",
    ")\n",
    "\n",
    "\n",
    "def get_raw_signal(dir_names, markers):\n",
    "    dir_to_data = {}\n",
    "    for dir_name in dir_names:\n",
    "        all_data = load_data_from_dir(dir_name)\n",
    "        dir_to_data[dir_name] = all_data\n",
    "\n",
    "    \"\"\" \n",
    "        concatenate raw signal (x)\n",
    "    \"\"\"\n",
    "    data_list = []\n",
    "    block_names = list(dir_to_data[dir_names[0]].keys())\n",
    "    block_names.sort()\n",
    "\n",
    "    for m in markers:  # EOG.__name__, , EMG.__name__, EGG.__name__\n",
    "        all_participants_data, condition_to_labels = concatenate_all_data(\n",
    "            dir_to_data, m\n",
    "        )\n",
    "        all_epoch_data = np.swapaxes(\n",
    "            all_participants_data, 0, -1\n",
    "        )  # (num_channels, num_data_points, num_epochs) => (num_epochs, num_data_points, num_channels)\n",
    "\n",
    "        data_list.append(all_epoch_data)\n",
    "\n",
    "    return np.concatenate(data_list, axis=2), condition_to_labels\n",
    "\n",
    "\n",
    "ALL_DIRS = [\n",
    "    \"../CleandDataV1/2017\",\n",
    "    \"../CleandDataV1/2018\",\n",
    "]\n",
    "\n",
    "data_array, condition_to_labels = get_raw_signal(ALL_DIRS, [\"EEG\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4b06a40",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import utils as np_utils\n",
    "from models import train_with_cnn\n",
    "\n",
    "\"\"\" \n",
    "    prepare labels (y)\n",
    "\"\"\"\n",
    "# to one-hot encoding vector\n",
    "# label_array = np_utils.to_categorical(\n",
    "#     label_list, num_classes=4\n",
    "# )  # nvla, nvha, hvla, hvha\n",
    "label_list = binary_label(condition_to_labels[\"valence\"])\n",
    "label_array = np.array(label_list)\n",
    "\n",
    "groups_list = [[i / NUM_LABEL_PER_SUBJECT] for i, j in enumerate(label_list)]\n",
    "group_array = np.hstack(groups_list)\n",
    "\n",
    "print(data_array.shape, label_array.shape, group_array.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8b16a05",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" \n",
    "    with CNN\n",
    "\"\"\"\n",
    "num_channel = data_array.shape[2]\n",
    "accuracy = train_with_cnn(12288, num_channel, data_array, label_array, group_array)\n",
    "print(accuracy)\n",
    "print(np.mean(accuracy))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f5b1f5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" \n",
    "    with logistic regression\n",
    "\"\"\"\n",
    "# from models import train_with_logistic\n",
    "\n",
    "# label_name = \"attention\"\n",
    "# best_model = train_with_logistic(all_features, label_name, condition_to_labels, group_array)\n",
    "# name_to_transformed = get_tranformed_labels(condition_to_labels)\n",
    "\n",
    "# # assume bigger coefficents has more contribution to the model\n",
    "# # but have to be sure that the features has THE SAME SCALE otherwise this assumption is not correct.\n",
    "# importance = best_model[\"classifier\"].coef_[0]\n",
    "\n",
    "# feat_importances = pd.Series(importance, index=get_feature_names(importance))\n",
    "# feat_importances.nlargest(10).plot(\n",
    "#     kind=\"barh\", title=f\"{label_name} Feature Importance\"\n",
    "# )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MM",
   "language": "python",
   "name": "mm"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
